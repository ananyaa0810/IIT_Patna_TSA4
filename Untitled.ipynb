{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860862bd-9990-44f5-b882-17f996f81d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 12:02:17.757452\n",
      "2024-07-02-12-02-17\n",
      "errors_2024-07-02-12-02-17.txt\n",
      "(154962, 18)\n",
      "(81446, 18)\n",
      "(236408, 17)\n",
      "(236408,)\n",
      "(236408, 17)\n",
      "(236408,)\n",
      "******************************\n",
      "Decison Tree Completed :) \n",
      "******************************\n",
      "Linear Regression Completed :) \n",
      "******************************\n",
      "LogisticRegression Completed :) \n",
      "******************************\n",
      "KNN Completed :) \n",
      "******************************\n",
      "Random forest Completed :) \n",
      "******************************\n",
      "MLP Completed :) \n",
      "******************************\n",
      "Bagging Completed :) \n",
      "******************************\n",
      "J48 Completed :) \n",
      "******************************\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "ANN Completed :) \n",
      "******************************\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "DNN Completed :) \n",
      "******************************\n",
      "GradientBoostingClassifier Completed :) \n",
      "******************************\n",
      "XGBClassifier Completed :) \n",
      "******************************\n",
      "Gaussian_Naive_Bayes Completed :) \n",
      "******************************\n",
      "Adaptive Gradient Boosting Completed :) \n",
      "******************************\n",
      "QDA Completed :) \n",
      "******************************\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "SNN Completed :)  \n",
      "******************************\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "RBM Completed :)  \n",
      "******************************\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step\n",
      "lstm Completed :)  \n",
      "******************************\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "reconstruction neural networks, Completed :)  \n",
      "******************************\n",
      "Epoch 1/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 1.2718 - source_classifier_accuracy: 0.5555 - val_loss: 0.8705 - val_source_classifier_accuracy: 0.7189\n",
      "Epoch 2/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.8625 - source_classifier_accuracy: 0.7043 - val_loss: 0.7401 - val_source_classifier_accuracy: 0.7493\n",
      "Epoch 3/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7646 - source_classifier_accuracy: 0.7323 - val_loss: 0.6879 - val_source_classifier_accuracy: 0.7626\n",
      "Epoch 4/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7230 - source_classifier_accuracy: 0.7436 - val_loss: 0.6575 - val_source_classifier_accuracy: 0.7677\n",
      "Epoch 5/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6913 - source_classifier_accuracy: 0.7531 - val_loss: 0.6373 - val_source_classifier_accuracy: 0.7798\n",
      "Epoch 6/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6691 - source_classifier_accuracy: 0.7615 - val_loss: 0.6209 - val_source_classifier_accuracy: 0.7805\n",
      "Epoch 7/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6559 - source_classifier_accuracy: 0.7668 - val_loss: 0.6073 - val_source_classifier_accuracy: 0.7901\n",
      "Epoch 8/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6382 - source_classifier_accuracy: 0.7718 - val_loss: 0.5968 - val_source_classifier_accuracy: 0.7944\n",
      "Epoch 9/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6323 - source_classifier_accuracy: 0.7739 - val_loss: 0.5866 - val_source_classifier_accuracy: 0.7911\n",
      "Epoch 10/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6239 - source_classifier_accuracy: 0.7772 - val_loss: 0.5789 - val_source_classifier_accuracy: 0.7976\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 1.2981 - source_classifier_accuracy: 0.5453 - val_loss: 0.8936 - val_source_classifier_accuracy: 0.7157\n",
      "Epoch 2/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.8758 - source_classifier_accuracy: 0.7052 - val_loss: 0.7402 - val_source_classifier_accuracy: 0.7536\n",
      "Epoch 3/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.7645 - source_classifier_accuracy: 0.7369 - val_loss: 0.6846 - val_source_classifier_accuracy: 0.7609\n",
      "Epoch 4/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.7167 - source_classifier_accuracy: 0.7480 - val_loss: 0.6543 - val_source_classifier_accuracy: 0.7694\n",
      "Epoch 5/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.6846 - source_classifier_accuracy: 0.7564 - val_loss: 0.6326 - val_source_classifier_accuracy: 0.7761\n",
      "Epoch 6/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6691 - source_classifier_accuracy: 0.7634 - val_loss: 0.6172 - val_source_classifier_accuracy: 0.7802\n",
      "Epoch 7/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6516 - source_classifier_accuracy: 0.7679 - val_loss: 0.6011 - val_source_classifier_accuracy: 0.7919\n",
      "Epoch 8/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.6422 - source_classifier_accuracy: 0.7716 - val_loss: 0.5917 - val_source_classifier_accuracy: 0.7922\n",
      "Epoch 9/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.6330 - source_classifier_accuracy: 0.7749 - val_loss: 0.5816 - val_source_classifier_accuracy: 0.7936\n",
      "Epoch 10/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.6214 - source_classifier_accuracy: 0.7774 - val_loss: 0.5754 - val_source_classifier_accuracy: 0.7966\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.2852 - source_classifier_accuracy: 0.5495 - val_loss: 0.8895 - val_source_classifier_accuracy: 0.6886\n",
      "Epoch 2/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8855 - source_classifier_accuracy: 0.6926 - val_loss: 0.7557 - val_source_classifier_accuracy: 0.7527\n",
      "Epoch 3/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7779 - source_classifier_accuracy: 0.7317 - val_loss: 0.6962 - val_source_classifier_accuracy: 0.7644\n",
      "Epoch 4/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7277 - source_classifier_accuracy: 0.7461 - val_loss: 0.6617 - val_source_classifier_accuracy: 0.7746\n",
      "Epoch 5/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6957 - source_classifier_accuracy: 0.7560 - val_loss: 0.6349 - val_source_classifier_accuracy: 0.7879\n",
      "Epoch 6/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6725 - source_classifier_accuracy: 0.7614 - val_loss: 0.6182 - val_source_classifier_accuracy: 0.7860\n",
      "Epoch 7/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6508 - source_classifier_accuracy: 0.7689 - val_loss: 0.6046 - val_source_classifier_accuracy: 0.7932\n",
      "Epoch 8/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6370 - source_classifier_accuracy: 0.7724 - val_loss: 0.5933 - val_source_classifier_accuracy: 0.7956\n",
      "Epoch 9/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.6280 - source_classifier_accuracy: 0.7772 - val_loss: 0.5856 - val_source_classifier_accuracy: 0.8010\n",
      "Epoch 10/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6257 - source_classifier_accuracy: 0.7775 - val_loss: 0.5776 - val_source_classifier_accuracy: 0.7994\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.2826 - source_classifier_accuracy: 0.5484 - val_loss: 0.8822 - val_source_classifier_accuracy: 0.7130\n",
      "Epoch 2/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.8726 - source_classifier_accuracy: 0.7020 - val_loss: 0.7318 - val_source_classifier_accuracy: 0.7518\n",
      "Epoch 3/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.7638 - source_classifier_accuracy: 0.7352 - val_loss: 0.6762 - val_source_classifier_accuracy: 0.7625\n",
      "Epoch 4/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.7123 - source_classifier_accuracy: 0.7526 - val_loss: 0.6429 - val_source_classifier_accuracy: 0.7798\n",
      "Epoch 5/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.6829 - source_classifier_accuracy: 0.7603 - val_loss: 0.6228 - val_source_classifier_accuracy: 0.7785\n",
      "Epoch 6/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6653 - source_classifier_accuracy: 0.7650 - val_loss: 0.6059 - val_source_classifier_accuracy: 0.7911\n",
      "Epoch 7/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6497 - source_classifier_accuracy: 0.7688 - val_loss: 0.5905 - val_source_classifier_accuracy: 0.7931\n",
      "Epoch 8/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.6338 - source_classifier_accuracy: 0.7737 - val_loss: 0.5791 - val_source_classifier_accuracy: 0.7967\n",
      "Epoch 9/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.6254 - source_classifier_accuracy: 0.7778 - val_loss: 0.5730 - val_source_classifier_accuracy: 0.7962\n",
      "Epoch 10/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6181 - source_classifier_accuracy: 0.7793 - val_loss: 0.5629 - val_source_classifier_accuracy: 0.8006\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 1.2836 - source_classifier_accuracy: 0.5493 - val_loss: 0.8889 - val_source_classifier_accuracy: 0.6641\n",
      "Epoch 2/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.8776 - source_classifier_accuracy: 0.6950 - val_loss: 0.7501 - val_source_classifier_accuracy: 0.7444\n",
      "Epoch 3/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7753 - source_classifier_accuracy: 0.7324 - val_loss: 0.6883 - val_source_classifier_accuracy: 0.7685\n",
      "Epoch 4/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.7230 - source_classifier_accuracy: 0.7485 - val_loss: 0.6570 - val_source_classifier_accuracy: 0.7735\n",
      "Epoch 5/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6932 - source_classifier_accuracy: 0.7542 - val_loss: 0.6319 - val_source_classifier_accuracy: 0.7765\n",
      "Epoch 6/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6695 - source_classifier_accuracy: 0.7624 - val_loss: 0.6178 - val_source_classifier_accuracy: 0.7790\n",
      "Epoch 7/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6535 - source_classifier_accuracy: 0.7672 - val_loss: 0.6034 - val_source_classifier_accuracy: 0.7839\n",
      "Epoch 8/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6419 - source_classifier_accuracy: 0.7709 - val_loss: 0.5930 - val_source_classifier_accuracy: 0.7915\n",
      "Epoch 9/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.6279 - source_classifier_accuracy: 0.7770 - val_loss: 0.5829 - val_source_classifier_accuracy: 0.7916\n",
      "Epoch 10/10\n",
      "\u001b[1m2956/2956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.6212 - source_classifier_accuracy: 0.7774 - val_loss: 0.5770 - val_source_classifier_accuracy: 0.8022\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "DANN Completed :)  \n",
      "******************************\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.72, time = 6.70s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.69, time = 6.65s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.69, time = 8.01s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.68, time = 7.82s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.66, time = 7.28s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.92, time = 7.78s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.61, time = 8.77s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -2.15, time = 7.73s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.66, time = 7.59s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.89, time = 7.94s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -2.07, time = 9.00s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -2.19, time = 8.30s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1.59, time = 7.34s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -1.87, time = 7.49s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1.71, time = 8.52s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -1.74, time = 7.81s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -2.22, time = 7.78s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -3.20, time = 7.51s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -1.61, time = 8.01s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -1.71, time = 8.08s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.68, time = 6.61s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.63, time = 8.59s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.62, time = 8.33s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.64, time = 8.87s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.63, time = 7.87s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.55, time = 7.57s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.75, time = 8.54s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.71, time = 8.78s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.70, time = 7.66s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.67, time = 8.52s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -1.93, time = 8.48s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1.65, time = 8.00s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1.71, time = 7.13s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -3.17, time = 7.47s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1.60, time = 8.37s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -1.63, time = 8.64s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -2.78, time = 8.27s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -3.34, time = 7.85s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -7.55, time = 8.47s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -2.64, time = 6.95s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.70, time = 6.70s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.67, time = 8.29s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.63, time = 8.00s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.65, time = 7.91s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.64, time = 7.57s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.70, time = 8.52s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.62, time = 7.50s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.64, time = 8.03s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.75, time = 7.78s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -2.06, time = 7.69s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -2.45, time = 8.29s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1.67, time = 7.96s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1.62, time = 7.45s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -1.61, time = 7.01s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1.82, time = 6.87s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -2.86, time = 5.84s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -3.11, time = 6.22s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -1.55, time = 6.51s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -1.62, time = 8.65s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -1.75, time = 7.03s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.70, time = 6.42s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.66, time = 8.56s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.63, time = 7.43s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.65, time = 7.99s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.74, time = 8.18s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.74, time = 7.82s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -1.87, time = 7.61s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.76, time = 7.89s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.67, time = 6.64s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.84, time = 8.46s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -1.67, time = 8.16s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1.72, time = 7.70s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -1.92, time = 7.83s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -1.74, time = 8.85s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1.70, time = 7.59s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -1.84, time = 8.60s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -2.89, time = 7.30s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -4.04, time = 7.95s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -2.70, time = 6.38s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -2.22, time = 8.37s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -1.71, time = 7.25s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.67, time = 8.50s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.64, time = 8.34s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.65, time = 7.05s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.59, time = 8.31s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -1.86, time = 8.54s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -2.14, time = 8.29s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -1.89, time = 8.68s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -1.69, time = 8.91s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -1.79, time = 7.99s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -1.82, time = 8.35s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -1.93, time = 7.55s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -2.00, time = 7.48s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -1.66, time = 8.40s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -1.69, time = 7.65s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -1.80, time = 8.27s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -1.89, time = 7.12s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -3.38, time = 7.98s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -1.58, time = 8.31s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -1.74, time = 7.84s\n",
      "******************************\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "******************************\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m1478/1478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "******************************\n",
      "******************************\n",
      "******************************\n",
      "Epoch 1/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4656 - loss: 1.5533\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6160 - loss: 1.0531\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6525 - loss: 0.9528\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7199 - loss: 0.8336\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7450 - loss: 0.7585\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.7184\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.6937\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.6697\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 0.6386\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7757 - loss: 0.6406\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4588 - loss: 1.5649\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6077 - loss: 1.0926\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6419 - loss: 0.9767\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6921 - loss: 0.8792\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7342 - loss: 0.8069\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7401 - loss: 0.7660\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7520 - loss: 0.7241\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.7063\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7719 - loss: 0.6748\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7703 - loss: 0.6567\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4796 - loss: 1.5576\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 1.0488\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6506 - loss: 0.9360\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7122 - loss: 0.8517\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.7680\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7511 - loss: 0.7202\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7639 - loss: 0.6879\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7688 - loss: 0.6654\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7768 - loss: 0.6517\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.6272\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4704 - loss: 1.5746\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6106 - loss: 1.0745\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6511 - loss: 0.9696\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.8457\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.7796\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7487 - loss: 0.7317\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7645 - loss: 0.6851\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7670 - loss: 0.6701\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7698 - loss: 0.6592\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7732 - loss: 0.6423\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4707 - loss: 1.5553\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6036 - loss: 1.0800\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6486 - loss: 0.9668\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6884 - loss: 0.8770\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.8006\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7461 - loss: 0.7514\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7576 - loss: 0.7189\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6949\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7698 - loss: 0.6700\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7741 - loss: 0.6699\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "******************************\n",
      "******************************\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "******************************\n",
      "GMM Completed :)  \n",
      "******************************\n",
      "Bernoulli Naive Bayes with k-fold Cross-Validation Completed :)  \n",
      "******************************\n",
      "Learning rate set to 0.091926\n",
      "0:\tlearn: 1.8310139\ttotal: 231ms\tremaining: 3m 50s\n",
      "1:\tlearn: 1.6081578\ttotal: 285ms\tremaining: 2m 22s\n",
      "2:\tlearn: 1.4525273\ttotal: 332ms\tremaining: 1m 50s\n",
      "3:\tlearn: 1.3414500\ttotal: 377ms\tremaining: 1m 33s\n",
      "4:\tlearn: 1.2522985\ttotal: 414ms\tremaining: 1m 22s\n",
      "5:\tlearn: 1.1891796\ttotal: 448ms\tremaining: 1m 14s\n",
      "6:\tlearn: 1.1331360\ttotal: 492ms\tremaining: 1m 9s\n",
      "7:\tlearn: 1.0712424\ttotal: 542ms\tremaining: 1m 7s\n",
      "8:\tlearn: 1.0183137\ttotal: 583ms\tremaining: 1m 4s\n",
      "9:\tlearn: 0.9778296\ttotal: 616ms\tremaining: 1m\n",
      "10:\tlearn: 0.9419958\ttotal: 655ms\tremaining: 58.9s\n",
      "11:\tlearn: 0.9050474\ttotal: 692ms\tremaining: 57s\n",
      "12:\tlearn: 0.8779917\ttotal: 729ms\tremaining: 55.3s\n",
      "13:\tlearn: 0.8488180\ttotal: 763ms\tremaining: 53.8s\n",
      "14:\tlearn: 0.8245574\ttotal: 796ms\tremaining: 52.3s\n",
      "15:\tlearn: 0.7998693\ttotal: 827ms\tremaining: 50.8s\n",
      "16:\tlearn: 0.7791232\ttotal: 858ms\tremaining: 49.6s\n",
      "17:\tlearn: 0.7582489\ttotal: 892ms\tremaining: 48.6s\n",
      "18:\tlearn: 0.7425462\ttotal: 929ms\tremaining: 48s\n",
      "19:\tlearn: 0.7279432\ttotal: 967ms\tremaining: 47.4s\n",
      "20:\tlearn: 0.7072211\ttotal: 1s\tremaining: 46.7s\n",
      "21:\tlearn: 0.6915101\ttotal: 1.03s\tremaining: 46s\n",
      "22:\tlearn: 0.6776275\ttotal: 1.06s\tremaining: 45.2s\n",
      "23:\tlearn: 0.6648894\ttotal: 1.09s\tremaining: 44.5s\n",
      "24:\tlearn: 0.6534370\ttotal: 1.12s\tremaining: 43.9s\n",
      "25:\tlearn: 0.6430120\ttotal: 1.17s\tremaining: 43.7s\n",
      "26:\tlearn: 0.6352654\ttotal: 1.2s\tremaining: 43.2s\n",
      "27:\tlearn: 0.6251278\ttotal: 1.23s\tremaining: 42.6s\n",
      "28:\tlearn: 0.6157063\ttotal: 1.26s\tremaining: 42.2s\n",
      "29:\tlearn: 0.6076448\ttotal: 1.29s\tremaining: 41.8s\n",
      "30:\tlearn: 0.6014016\ttotal: 1.32s\tremaining: 41.4s\n",
      "31:\tlearn: 0.5936662\ttotal: 1.35s\tremaining: 40.9s\n",
      "32:\tlearn: 0.5885339\ttotal: 1.38s\tremaining: 40.6s\n",
      "33:\tlearn: 0.5797344\ttotal: 1.42s\tremaining: 40.4s\n",
      "34:\tlearn: 0.5724115\ttotal: 1.47s\tremaining: 40.7s\n",
      "35:\tlearn: 0.5647007\ttotal: 1.51s\tremaining: 40.5s\n",
      "36:\tlearn: 0.5595260\ttotal: 1.54s\tremaining: 40.2s\n",
      "37:\tlearn: 0.5543708\ttotal: 1.57s\tremaining: 39.9s\n",
      "38:\tlearn: 0.5485489\ttotal: 1.61s\tremaining: 39.6s\n",
      "39:\tlearn: 0.5428596\ttotal: 1.64s\tremaining: 39.4s\n",
      "40:\tlearn: 0.5368296\ttotal: 1.68s\tremaining: 39.2s\n",
      "41:\tlearn: 0.5317401\ttotal: 1.71s\tremaining: 38.9s\n",
      "42:\tlearn: 0.5255270\ttotal: 1.74s\tremaining: 38.6s\n",
      "43:\tlearn: 0.5200143\ttotal: 1.76s\tremaining: 38.4s\n",
      "44:\tlearn: 0.5157146\ttotal: 1.79s\tremaining: 38.1s\n",
      "45:\tlearn: 0.5096687\ttotal: 1.83s\tremaining: 38s\n",
      "46:\tlearn: 0.5052486\ttotal: 1.86s\tremaining: 37.8s\n",
      "47:\tlearn: 0.5003074\ttotal: 1.9s\tremaining: 37.6s\n",
      "48:\tlearn: 0.4959312\ttotal: 1.93s\tremaining: 37.4s\n",
      "49:\tlearn: 0.4914787\ttotal: 1.96s\tremaining: 37.2s\n",
      "50:\tlearn: 0.4870536\ttotal: 1.99s\tremaining: 37s\n",
      "51:\tlearn: 0.4825373\ttotal: 2.02s\tremaining: 36.8s\n",
      "52:\tlearn: 0.4789970\ttotal: 2.06s\tremaining: 36.7s\n",
      "53:\tlearn: 0.4768826\ttotal: 2.09s\tremaining: 36.6s\n",
      "54:\tlearn: 0.4738366\ttotal: 2.12s\tremaining: 36.5s\n",
      "55:\tlearn: 0.4710335\ttotal: 2.15s\tremaining: 36.3s\n",
      "56:\tlearn: 0.4681209\ttotal: 2.18s\tremaining: 36.1s\n",
      "57:\tlearn: 0.4655419\ttotal: 2.21s\tremaining: 35.9s\n",
      "58:\tlearn: 0.4635061\ttotal: 2.24s\tremaining: 35.8s\n",
      "59:\tlearn: 0.4612488\ttotal: 2.27s\tremaining: 35.6s\n",
      "60:\tlearn: 0.4587039\ttotal: 2.31s\tremaining: 35.6s\n",
      "61:\tlearn: 0.4554445\ttotal: 2.37s\tremaining: 35.8s\n",
      "62:\tlearn: 0.4525395\ttotal: 2.4s\tremaining: 35.8s\n",
      "63:\tlearn: 0.4494062\ttotal: 2.44s\tremaining: 35.7s\n",
      "64:\tlearn: 0.4471881\ttotal: 2.47s\tremaining: 35.5s\n",
      "65:\tlearn: 0.4455540\ttotal: 2.5s\tremaining: 35.4s\n",
      "66:\tlearn: 0.4441588\ttotal: 2.54s\tremaining: 35.3s\n",
      "67:\tlearn: 0.4405564\ttotal: 2.57s\tremaining: 35.2s\n",
      "68:\tlearn: 0.4381100\ttotal: 2.6s\tremaining: 35.1s\n",
      "69:\tlearn: 0.4359009\ttotal: 2.63s\tremaining: 35s\n",
      "70:\tlearn: 0.4333522\ttotal: 2.66s\tremaining: 34.8s\n",
      "71:\tlearn: 0.4319653\ttotal: 2.69s\tremaining: 34.7s\n",
      "72:\tlearn: 0.4308330\ttotal: 2.72s\tremaining: 34.6s\n",
      "73:\tlearn: 0.4286289\ttotal: 2.76s\tremaining: 34.5s\n",
      "74:\tlearn: 0.4272019\ttotal: 2.79s\tremaining: 34.4s\n",
      "75:\tlearn: 0.4243292\ttotal: 2.82s\tremaining: 34.3s\n",
      "76:\tlearn: 0.4228223\ttotal: 2.85s\tremaining: 34.2s\n",
      "77:\tlearn: 0.4213091\ttotal: 2.88s\tremaining: 34.1s\n",
      "78:\tlearn: 0.4188480\ttotal: 2.92s\tremaining: 34s\n",
      "79:\tlearn: 0.4165868\ttotal: 2.95s\tremaining: 33.9s\n",
      "80:\tlearn: 0.4151748\ttotal: 2.98s\tremaining: 33.8s\n",
      "81:\tlearn: 0.4133937\ttotal: 3.03s\tremaining: 33.9s\n",
      "82:\tlearn: 0.4119291\ttotal: 3.07s\tremaining: 33.9s\n",
      "83:\tlearn: 0.4101487\ttotal: 3.1s\tremaining: 33.8s\n",
      "84:\tlearn: 0.4080942\ttotal: 3.13s\tremaining: 33.8s\n",
      "85:\tlearn: 0.4072642\ttotal: 3.17s\tremaining: 33.7s\n",
      "86:\tlearn: 0.4059935\ttotal: 3.21s\tremaining: 33.6s\n",
      "87:\tlearn: 0.4045415\ttotal: 3.24s\tremaining: 33.6s\n",
      "88:\tlearn: 0.4035736\ttotal: 3.27s\tremaining: 33.5s\n",
      "89:\tlearn: 0.4026506\ttotal: 3.3s\tremaining: 33.4s\n",
      "90:\tlearn: 0.4017068\ttotal: 3.33s\tremaining: 33.2s\n",
      "91:\tlearn: 0.4006017\ttotal: 3.36s\tremaining: 33.2s\n",
      "92:\tlearn: 0.3991830\ttotal: 3.39s\tremaining: 33.1s\n",
      "93:\tlearn: 0.3973199\ttotal: 3.43s\tremaining: 33.1s\n",
      "94:\tlearn: 0.3955360\ttotal: 3.47s\tremaining: 33s\n",
      "95:\tlearn: 0.3948660\ttotal: 3.5s\tremaining: 32.9s\n",
      "96:\tlearn: 0.3927078\ttotal: 3.53s\tremaining: 32.8s\n",
      "97:\tlearn: 0.3919355\ttotal: 3.56s\tremaining: 32.7s\n",
      "98:\tlearn: 0.3914696\ttotal: 3.58s\tremaining: 32.6s\n",
      "99:\tlearn: 0.3893297\ttotal: 3.62s\tremaining: 32.6s\n",
      "100:\tlearn: 0.3884757\ttotal: 3.65s\tremaining: 32.5s\n",
      "101:\tlearn: 0.3875273\ttotal: 3.71s\tremaining: 32.7s\n",
      "102:\tlearn: 0.3860748\ttotal: 3.74s\tremaining: 32.6s\n",
      "103:\tlearn: 0.3844625\ttotal: 3.77s\tremaining: 32.5s\n",
      "104:\tlearn: 0.3837508\ttotal: 3.8s\tremaining: 32.4s\n",
      "105:\tlearn: 0.3824883\ttotal: 3.84s\tremaining: 32.4s\n",
      "106:\tlearn: 0.3811172\ttotal: 3.88s\tremaining: 32.4s\n",
      "107:\tlearn: 0.3799051\ttotal: 3.91s\tremaining: 32.3s\n",
      "108:\tlearn: 0.3792882\ttotal: 3.94s\tremaining: 32.2s\n",
      "109:\tlearn: 0.3782648\ttotal: 3.97s\tremaining: 32.2s\n",
      "110:\tlearn: 0.3773769\ttotal: 4.01s\tremaining: 32.1s\n",
      "111:\tlearn: 0.3764045\ttotal: 4.04s\tremaining: 32s\n",
      "112:\tlearn: 0.3753862\ttotal: 4.08s\tremaining: 32s\n",
      "113:\tlearn: 0.3746487\ttotal: 4.11s\tremaining: 31.9s\n",
      "114:\tlearn: 0.3736750\ttotal: 4.14s\tremaining: 31.8s\n",
      "115:\tlearn: 0.3721833\ttotal: 4.17s\tremaining: 31.8s\n",
      "116:\tlearn: 0.3718085\ttotal: 4.19s\tremaining: 31.7s\n",
      "117:\tlearn: 0.3709212\ttotal: 4.22s\tremaining: 31.6s\n",
      "118:\tlearn: 0.3691436\ttotal: 4.26s\tremaining: 31.6s\n",
      "119:\tlearn: 0.3682391\ttotal: 4.3s\tremaining: 31.5s\n",
      "120:\tlearn: 0.3673719\ttotal: 4.35s\tremaining: 31.6s\n",
      "121:\tlearn: 0.3668628\ttotal: 4.38s\tremaining: 31.6s\n",
      "122:\tlearn: 0.3660372\ttotal: 4.43s\tremaining: 31.6s\n",
      "123:\tlearn: 0.3653075\ttotal: 4.47s\tremaining: 31.6s\n",
      "124:\tlearn: 0.3642234\ttotal: 4.5s\tremaining: 31.5s\n",
      "125:\tlearn: 0.3634273\ttotal: 4.53s\tremaining: 31.4s\n",
      "126:\tlearn: 0.3621230\ttotal: 4.57s\tremaining: 31.4s\n",
      "127:\tlearn: 0.3617166\ttotal: 4.61s\tremaining: 31.4s\n",
      "128:\tlearn: 0.3611708\ttotal: 4.63s\tremaining: 31.3s\n",
      "129:\tlearn: 0.3604139\ttotal: 4.66s\tremaining: 31.2s\n",
      "130:\tlearn: 0.3599631\ttotal: 4.69s\tremaining: 31.1s\n",
      "131:\tlearn: 0.3587497\ttotal: 4.72s\tremaining: 31.1s\n",
      "132:\tlearn: 0.3579141\ttotal: 4.75s\tremaining: 31s\n",
      "133:\tlearn: 0.3576000\ttotal: 4.78s\tremaining: 30.9s\n",
      "134:\tlearn: 0.3567682\ttotal: 4.82s\tremaining: 30.9s\n",
      "135:\tlearn: 0.3564965\ttotal: 4.84s\tremaining: 30.8s\n",
      "136:\tlearn: 0.3560945\ttotal: 4.87s\tremaining: 30.7s\n",
      "137:\tlearn: 0.3552168\ttotal: 4.9s\tremaining: 30.6s\n",
      "138:\tlearn: 0.3541315\ttotal: 4.93s\tremaining: 30.6s\n",
      "139:\tlearn: 0.3539434\ttotal: 4.96s\tremaining: 30.5s\n",
      "140:\tlearn: 0.3533717\ttotal: 4.99s\tremaining: 30.4s\n",
      "141:\tlearn: 0.3524452\ttotal: 5.03s\tremaining: 30.4s\n",
      "142:\tlearn: 0.3516547\ttotal: 5.08s\tremaining: 30.4s\n",
      "143:\tlearn: 0.3511057\ttotal: 5.12s\tremaining: 30.4s\n",
      "144:\tlearn: 0.3505350\ttotal: 5.15s\tremaining: 30.4s\n",
      "145:\tlearn: 0.3498912\ttotal: 5.18s\tremaining: 30.3s\n",
      "146:\tlearn: 0.3493737\ttotal: 5.22s\tremaining: 30.3s\n",
      "147:\tlearn: 0.3484312\ttotal: 5.25s\tremaining: 30.2s\n",
      "148:\tlearn: 0.3476624\ttotal: 5.28s\tremaining: 30.2s\n",
      "149:\tlearn: 0.3471202\ttotal: 5.31s\tremaining: 30.1s\n",
      "150:\tlearn: 0.3466543\ttotal: 5.34s\tremaining: 30s\n",
      "151:\tlearn: 0.3462149\ttotal: 5.37s\tremaining: 30s\n",
      "152:\tlearn: 0.3456409\ttotal: 5.4s\tremaining: 29.9s\n",
      "153:\tlearn: 0.3450027\ttotal: 5.43s\tremaining: 29.9s\n",
      "154:\tlearn: 0.3446357\ttotal: 5.46s\tremaining: 29.8s\n",
      "155:\tlearn: 0.3437359\ttotal: 5.49s\tremaining: 29.7s\n",
      "156:\tlearn: 0.3433463\ttotal: 5.52s\tremaining: 29.7s\n",
      "157:\tlearn: 0.3422548\ttotal: 5.56s\tremaining: 29.6s\n",
      "158:\tlearn: 0.3411591\ttotal: 5.59s\tremaining: 29.6s\n",
      "159:\tlearn: 0.3406345\ttotal: 5.62s\tremaining: 29.5s\n",
      "160:\tlearn: 0.3403067\ttotal: 5.65s\tremaining: 29.4s\n",
      "161:\tlearn: 0.3396288\ttotal: 5.69s\tremaining: 29.4s\n",
      "162:\tlearn: 0.3392304\ttotal: 5.74s\tremaining: 29.5s\n",
      "163:\tlearn: 0.3387164\ttotal: 5.78s\tremaining: 29.4s\n",
      "164:\tlearn: 0.3379341\ttotal: 5.81s\tremaining: 29.4s\n",
      "165:\tlearn: 0.3375061\ttotal: 5.84s\tremaining: 29.3s\n",
      "166:\tlearn: 0.3372052\ttotal: 5.87s\tremaining: 29.3s\n",
      "167:\tlearn: 0.3367723\ttotal: 5.91s\tremaining: 29.2s\n",
      "168:\tlearn: 0.3363432\ttotal: 5.93s\tremaining: 29.2s\n",
      "169:\tlearn: 0.3358683\ttotal: 5.96s\tremaining: 29.1s\n",
      "170:\tlearn: 0.3348822\ttotal: 6s\tremaining: 29.1s\n",
      "171:\tlearn: 0.3342874\ttotal: 6.03s\tremaining: 29s\n",
      "172:\tlearn: 0.3337037\ttotal: 6.06s\tremaining: 29s\n",
      "173:\tlearn: 0.3332737\ttotal: 6.09s\tremaining: 28.9s\n",
      "174:\tlearn: 0.3324525\ttotal: 6.13s\tremaining: 28.9s\n",
      "175:\tlearn: 0.3318059\ttotal: 6.16s\tremaining: 28.8s\n",
      "176:\tlearn: 0.3315440\ttotal: 6.18s\tremaining: 28.8s\n",
      "177:\tlearn: 0.3311658\ttotal: 6.21s\tremaining: 28.7s\n",
      "178:\tlearn: 0.3303733\ttotal: 6.25s\tremaining: 28.7s\n",
      "179:\tlearn: 0.3298612\ttotal: 6.28s\tremaining: 28.6s\n",
      "180:\tlearn: 0.3295343\ttotal: 6.31s\tremaining: 28.6s\n",
      "181:\tlearn: 0.3293199\ttotal: 6.35s\tremaining: 28.5s\n",
      "182:\tlearn: 0.3288211\ttotal: 6.39s\tremaining: 28.5s\n",
      "183:\tlearn: 0.3284352\ttotal: 6.43s\tremaining: 28.5s\n",
      "184:\tlearn: 0.3277282\ttotal: 6.46s\tremaining: 28.5s\n",
      "185:\tlearn: 0.3272473\ttotal: 6.49s\tremaining: 28.4s\n",
      "186:\tlearn: 0.3266146\ttotal: 6.53s\tremaining: 28.4s\n",
      "187:\tlearn: 0.3263030\ttotal: 6.56s\tremaining: 28.3s\n",
      "188:\tlearn: 0.3257722\ttotal: 6.59s\tremaining: 28.3s\n",
      "189:\tlearn: 0.3252748\ttotal: 6.62s\tremaining: 28.2s\n",
      "190:\tlearn: 0.3247454\ttotal: 6.65s\tremaining: 28.2s\n",
      "191:\tlearn: 0.3245465\ttotal: 6.68s\tremaining: 28.1s\n",
      "192:\tlearn: 0.3238102\ttotal: 6.71s\tremaining: 28.1s\n",
      "193:\tlearn: 0.3233467\ttotal: 6.75s\tremaining: 28.1s\n",
      "194:\tlearn: 0.3227777\ttotal: 6.79s\tremaining: 28s\n",
      "195:\tlearn: 0.3222653\ttotal: 6.82s\tremaining: 28s\n",
      "196:\tlearn: 0.3218640\ttotal: 6.85s\tremaining: 27.9s\n",
      "197:\tlearn: 0.3211702\ttotal: 6.88s\tremaining: 27.9s\n",
      "198:\tlearn: 0.3206045\ttotal: 6.91s\tremaining: 27.8s\n",
      "199:\tlearn: 0.3201409\ttotal: 6.94s\tremaining: 27.8s\n",
      "200:\tlearn: 0.3195425\ttotal: 6.98s\tremaining: 27.7s\n",
      "201:\tlearn: 0.3191624\ttotal: 7.02s\tremaining: 27.7s\n",
      "202:\tlearn: 0.3187246\ttotal: 7.07s\tremaining: 27.7s\n",
      "203:\tlearn: 0.3180193\ttotal: 7.1s\tremaining: 27.7s\n",
      "204:\tlearn: 0.3176385\ttotal: 7.13s\tremaining: 27.7s\n",
      "205:\tlearn: 0.3172065\ttotal: 7.16s\tremaining: 27.6s\n",
      "206:\tlearn: 0.3166533\ttotal: 7.2s\tremaining: 27.6s\n",
      "207:\tlearn: 0.3159380\ttotal: 7.24s\tremaining: 27.5s\n",
      "208:\tlearn: 0.3155707\ttotal: 7.27s\tremaining: 27.5s\n",
      "209:\tlearn: 0.3154358\ttotal: 7.29s\tremaining: 27.4s\n",
      "210:\tlearn: 0.3152608\ttotal: 7.32s\tremaining: 27.4s\n",
      "211:\tlearn: 0.3147045\ttotal: 7.36s\tremaining: 27.3s\n",
      "212:\tlearn: 0.3144735\ttotal: 7.38s\tremaining: 27.3s\n",
      "213:\tlearn: 0.3142184\ttotal: 7.42s\tremaining: 27.3s\n",
      "214:\tlearn: 0.3139175\ttotal: 7.45s\tremaining: 27.2s\n",
      "215:\tlearn: 0.3137753\ttotal: 7.48s\tremaining: 27.1s\n",
      "216:\tlearn: 0.3131807\ttotal: 7.51s\tremaining: 27.1s\n",
      "217:\tlearn: 0.3128879\ttotal: 7.54s\tremaining: 27s\n",
      "218:\tlearn: 0.3123287\ttotal: 7.57s\tremaining: 27s\n",
      "219:\tlearn: 0.3118855\ttotal: 7.6s\tremaining: 27s\n",
      "220:\tlearn: 0.3113649\ttotal: 7.64s\tremaining: 26.9s\n",
      "221:\tlearn: 0.3106372\ttotal: 7.69s\tremaining: 26.9s\n",
      "222:\tlearn: 0.3101549\ttotal: 7.73s\tremaining: 26.9s\n",
      "223:\tlearn: 0.3096343\ttotal: 7.76s\tremaining: 26.9s\n",
      "224:\tlearn: 0.3088935\ttotal: 7.79s\tremaining: 26.8s\n",
      "225:\tlearn: 0.3087635\ttotal: 7.82s\tremaining: 26.8s\n",
      "226:\tlearn: 0.3085626\ttotal: 7.86s\tremaining: 26.8s\n",
      "227:\tlearn: 0.3077845\ttotal: 7.89s\tremaining: 26.7s\n",
      "228:\tlearn: 0.3072725\ttotal: 7.92s\tremaining: 26.7s\n",
      "229:\tlearn: 0.3067012\ttotal: 7.96s\tremaining: 26.6s\n",
      "230:\tlearn: 0.3062514\ttotal: 7.99s\tremaining: 26.6s\n",
      "231:\tlearn: 0.3056776\ttotal: 8.02s\tremaining: 26.5s\n",
      "232:\tlearn: 0.3049815\ttotal: 8.05s\tremaining: 26.5s\n",
      "233:\tlearn: 0.3043310\ttotal: 8.09s\tremaining: 26.5s\n",
      "234:\tlearn: 0.3038456\ttotal: 8.12s\tremaining: 26.4s\n",
      "235:\tlearn: 0.3036605\ttotal: 8.15s\tremaining: 26.4s\n",
      "236:\tlearn: 0.3031562\ttotal: 8.18s\tremaining: 26.3s\n",
      "237:\tlearn: 0.3025237\ttotal: 8.21s\tremaining: 26.3s\n",
      "238:\tlearn: 0.3020175\ttotal: 8.24s\tremaining: 26.2s\n",
      "239:\tlearn: 0.3016588\ttotal: 8.27s\tremaining: 26.2s\n",
      "240:\tlearn: 0.3014159\ttotal: 8.31s\tremaining: 26.2s\n",
      "241:\tlearn: 0.3007239\ttotal: 8.36s\tremaining: 26.2s\n",
      "242:\tlearn: 0.3004551\ttotal: 8.4s\tremaining: 26.2s\n",
      "243:\tlearn: 0.3003777\ttotal: 8.43s\tremaining: 26.1s\n",
      "244:\tlearn: 0.3002446\ttotal: 8.46s\tremaining: 26.1s\n",
      "245:\tlearn: 0.3000213\ttotal: 8.49s\tremaining: 26s\n",
      "246:\tlearn: 0.2998031\ttotal: 8.53s\tremaining: 26s\n",
      "247:\tlearn: 0.2990689\ttotal: 8.56s\tremaining: 26s\n",
      "248:\tlearn: 0.2989095\ttotal: 8.59s\tremaining: 25.9s\n",
      "249:\tlearn: 0.2982001\ttotal: 8.62s\tremaining: 25.9s\n",
      "250:\tlearn: 0.2976726\ttotal: 8.65s\tremaining: 25.8s\n",
      "251:\tlearn: 0.2974608\ttotal: 8.68s\tremaining: 25.8s\n",
      "252:\tlearn: 0.2973185\ttotal: 8.71s\tremaining: 25.7s\n",
      "253:\tlearn: 0.2969709\ttotal: 8.75s\tremaining: 25.7s\n",
      "254:\tlearn: 0.2967481\ttotal: 8.78s\tremaining: 25.7s\n",
      "255:\tlearn: 0.2965367\ttotal: 8.81s\tremaining: 25.6s\n",
      "256:\tlearn: 0.2961976\ttotal: 8.84s\tremaining: 25.6s\n",
      "257:\tlearn: 0.2957711\ttotal: 8.87s\tremaining: 25.5s\n",
      "258:\tlearn: 0.2955350\ttotal: 8.9s\tremaining: 25.5s\n",
      "259:\tlearn: 0.2948782\ttotal: 8.94s\tremaining: 25.4s\n",
      "260:\tlearn: 0.2943830\ttotal: 8.97s\tremaining: 25.4s\n",
      "261:\tlearn: 0.2940584\ttotal: 9.03s\tremaining: 25.4s\n",
      "262:\tlearn: 0.2938744\ttotal: 9.06s\tremaining: 25.4s\n",
      "263:\tlearn: 0.2934163\ttotal: 9.1s\tremaining: 25.4s\n",
      "264:\tlearn: 0.2925303\ttotal: 9.13s\tremaining: 25.3s\n",
      "265:\tlearn: 0.2922775\ttotal: 9.16s\tremaining: 25.3s\n",
      "266:\tlearn: 0.2919214\ttotal: 9.2s\tremaining: 25.3s\n",
      "267:\tlearn: 0.2914839\ttotal: 9.23s\tremaining: 25.2s\n",
      "268:\tlearn: 0.2911443\ttotal: 9.27s\tremaining: 25.2s\n",
      "269:\tlearn: 0.2906940\ttotal: 9.29s\tremaining: 25.1s\n",
      "270:\tlearn: 0.2900695\ttotal: 9.32s\tremaining: 25.1s\n",
      "271:\tlearn: 0.2897799\ttotal: 9.36s\tremaining: 25s\n",
      "272:\tlearn: 0.2892280\ttotal: 9.39s\tremaining: 25s\n",
      "273:\tlearn: 0.2888659\ttotal: 9.42s\tremaining: 25s\n",
      "274:\tlearn: 0.2886482\ttotal: 9.46s\tremaining: 24.9s\n",
      "275:\tlearn: 0.2885165\ttotal: 9.48s\tremaining: 24.9s\n",
      "276:\tlearn: 0.2879146\ttotal: 9.52s\tremaining: 24.8s\n",
      "277:\tlearn: 0.2875469\ttotal: 9.55s\tremaining: 24.8s\n",
      "278:\tlearn: 0.2873476\ttotal: 9.58s\tremaining: 24.8s\n",
      "279:\tlearn: 0.2869542\ttotal: 9.61s\tremaining: 24.7s\n",
      "280:\tlearn: 0.2864974\ttotal: 9.65s\tremaining: 24.7s\n",
      "281:\tlearn: 0.2861496\ttotal: 9.7s\tremaining: 24.7s\n",
      "282:\tlearn: 0.2857456\ttotal: 9.73s\tremaining: 24.7s\n",
      "283:\tlearn: 0.2852169\ttotal: 9.77s\tremaining: 24.6s\n",
      "284:\tlearn: 0.2851020\ttotal: 9.8s\tremaining: 24.6s\n",
      "285:\tlearn: 0.2847758\ttotal: 9.84s\tremaining: 24.6s\n",
      "286:\tlearn: 0.2846379\ttotal: 9.87s\tremaining: 24.5s\n",
      "287:\tlearn: 0.2843738\ttotal: 9.9s\tremaining: 24.5s\n",
      "288:\tlearn: 0.2842255\ttotal: 9.94s\tremaining: 24.4s\n",
      "289:\tlearn: 0.2838979\ttotal: 9.97s\tremaining: 24.4s\n",
      "290:\tlearn: 0.2835544\ttotal: 10s\tremaining: 24.4s\n",
      "291:\tlearn: 0.2830974\ttotal: 10s\tremaining: 24.3s\n",
      "292:\tlearn: 0.2829993\ttotal: 10.1s\tremaining: 24.3s\n",
      "293:\tlearn: 0.2828790\ttotal: 10.1s\tremaining: 24.2s\n",
      "294:\tlearn: 0.2825834\ttotal: 10.1s\tremaining: 24.2s\n",
      "295:\tlearn: 0.2823616\ttotal: 10.2s\tremaining: 24.1s\n",
      "296:\tlearn: 0.2820077\ttotal: 10.2s\tremaining: 24.1s\n",
      "297:\tlearn: 0.2818378\ttotal: 10.2s\tremaining: 24.1s\n",
      "298:\tlearn: 0.2816327\ttotal: 10.2s\tremaining: 24s\n",
      "299:\tlearn: 0.2813509\ttotal: 10.3s\tremaining: 24s\n",
      "300:\tlearn: 0.2812045\ttotal: 10.3s\tremaining: 23.9s\n",
      "301:\tlearn: 0.2809636\ttotal: 10.4s\tremaining: 23.9s\n",
      "302:\tlearn: 0.2808252\ttotal: 10.4s\tremaining: 23.9s\n",
      "303:\tlearn: 0.2804334\ttotal: 10.4s\tremaining: 23.9s\n",
      "304:\tlearn: 0.2799046\ttotal: 10.5s\tremaining: 23.8s\n",
      "305:\tlearn: 0.2797293\ttotal: 10.5s\tremaining: 23.8s\n",
      "306:\tlearn: 0.2794574\ttotal: 10.5s\tremaining: 23.8s\n",
      "307:\tlearn: 0.2792441\ttotal: 10.6s\tremaining: 23.7s\n",
      "308:\tlearn: 0.2790565\ttotal: 10.6s\tremaining: 23.7s\n",
      "309:\tlearn: 0.2788025\ttotal: 10.6s\tremaining: 23.7s\n",
      "310:\tlearn: 0.2784794\ttotal: 10.7s\tremaining: 23.6s\n",
      "311:\tlearn: 0.2780345\ttotal: 10.7s\tremaining: 23.6s\n",
      "312:\tlearn: 0.2778986\ttotal: 10.7s\tremaining: 23.5s\n",
      "313:\tlearn: 0.2773035\ttotal: 10.8s\tremaining: 23.5s\n",
      "314:\tlearn: 0.2770034\ttotal: 10.8s\tremaining: 23.5s\n",
      "315:\tlearn: 0.2768734\ttotal: 10.8s\tremaining: 23.4s\n",
      "316:\tlearn: 0.2765725\ttotal: 10.8s\tremaining: 23.4s\n",
      "317:\tlearn: 0.2763191\ttotal: 10.9s\tremaining: 23.3s\n",
      "318:\tlearn: 0.2761123\ttotal: 10.9s\tremaining: 23.3s\n",
      "319:\tlearn: 0.2758245\ttotal: 10.9s\tremaining: 23.2s\n",
      "320:\tlearn: 0.2756135\ttotal: 11s\tremaining: 23.2s\n",
      "321:\tlearn: 0.2754946\ttotal: 11s\tremaining: 23.2s\n",
      "322:\tlearn: 0.2751300\ttotal: 11.1s\tremaining: 23.2s\n",
      "323:\tlearn: 0.2750573\ttotal: 11.1s\tremaining: 23.2s\n",
      "324:\tlearn: 0.2749921\ttotal: 11.1s\tremaining: 23.1s\n",
      "325:\tlearn: 0.2745029\ttotal: 11.2s\tremaining: 23.1s\n",
      "326:\tlearn: 0.2740315\ttotal: 11.2s\tremaining: 23.1s\n",
      "327:\tlearn: 0.2734691\ttotal: 11.2s\tremaining: 23s\n",
      "328:\tlearn: 0.2730825\ttotal: 11.3s\tremaining: 23s\n",
      "329:\tlearn: 0.2727228\ttotal: 11.3s\tremaining: 22.9s\n",
      "330:\tlearn: 0.2725378\ttotal: 11.3s\tremaining: 22.9s\n",
      "331:\tlearn: 0.2723285\ttotal: 11.4s\tremaining: 22.9s\n",
      "332:\tlearn: 0.2720327\ttotal: 11.4s\tremaining: 22.8s\n",
      "333:\tlearn: 0.2715635\ttotal: 11.4s\tremaining: 22.8s\n",
      "334:\tlearn: 0.2714635\ttotal: 11.5s\tremaining: 22.7s\n",
      "335:\tlearn: 0.2713285\ttotal: 11.5s\tremaining: 22.7s\n",
      "336:\tlearn: 0.2710705\ttotal: 11.5s\tremaining: 22.7s\n",
      "337:\tlearn: 0.2709085\ttotal: 11.5s\tremaining: 22.6s\n",
      "338:\tlearn: 0.2705402\ttotal: 11.6s\tremaining: 22.6s\n",
      "339:\tlearn: 0.2703316\ttotal: 11.6s\tremaining: 22.5s\n",
      "340:\tlearn: 0.2700948\ttotal: 11.7s\tremaining: 22.5s\n",
      "341:\tlearn: 0.2697592\ttotal: 11.7s\tremaining: 22.5s\n",
      "342:\tlearn: 0.2694231\ttotal: 11.7s\tremaining: 22.5s\n",
      "343:\tlearn: 0.2691589\ttotal: 11.8s\tremaining: 22.5s\n",
      "344:\tlearn: 0.2689031\ttotal: 11.8s\tremaining: 22.4s\n",
      "345:\tlearn: 0.2685691\ttotal: 11.8s\tremaining: 22.4s\n",
      "346:\tlearn: 0.2684751\ttotal: 11.9s\tremaining: 22.3s\n",
      "347:\tlearn: 0.2680429\ttotal: 11.9s\tremaining: 22.3s\n",
      "348:\tlearn: 0.2678617\ttotal: 11.9s\tremaining: 22.3s\n",
      "349:\tlearn: 0.2675466\ttotal: 12s\tremaining: 22.2s\n",
      "350:\tlearn: 0.2669188\ttotal: 12s\tremaining: 22.2s\n",
      "351:\tlearn: 0.2667382\ttotal: 12s\tremaining: 22.1s\n",
      "352:\tlearn: 0.2665246\ttotal: 12.1s\tremaining: 22.1s\n",
      "353:\tlearn: 0.2661080\ttotal: 12.1s\tremaining: 22.1s\n",
      "354:\tlearn: 0.2657738\ttotal: 12.1s\tremaining: 22s\n",
      "355:\tlearn: 0.2656396\ttotal: 12.2s\tremaining: 22s\n",
      "356:\tlearn: 0.2653760\ttotal: 12.2s\tremaining: 22s\n",
      "357:\tlearn: 0.2650910\ttotal: 12.2s\tremaining: 22s\n",
      "358:\tlearn: 0.2649159\ttotal: 12.3s\tremaining: 21.9s\n",
      "359:\tlearn: 0.2645678\ttotal: 12.3s\tremaining: 21.9s\n",
      "360:\tlearn: 0.2641937\ttotal: 12.4s\tremaining: 21.9s\n",
      "361:\tlearn: 0.2639604\ttotal: 12.4s\tremaining: 21.8s\n",
      "362:\tlearn: 0.2636682\ttotal: 12.4s\tremaining: 21.8s\n",
      "363:\tlearn: 0.2632952\ttotal: 12.4s\tremaining: 21.7s\n",
      "364:\tlearn: 0.2630843\ttotal: 12.5s\tremaining: 21.7s\n",
      "365:\tlearn: 0.2628146\ttotal: 12.5s\tremaining: 21.7s\n",
      "366:\tlearn: 0.2626010\ttotal: 12.6s\tremaining: 21.6s\n",
      "367:\tlearn: 0.2622721\ttotal: 12.6s\tremaining: 21.6s\n",
      "368:\tlearn: 0.2621043\ttotal: 12.6s\tremaining: 21.6s\n",
      "369:\tlearn: 0.2619057\ttotal: 12.7s\tremaining: 21.6s\n",
      "370:\tlearn: 0.2616926\ttotal: 12.7s\tremaining: 21.6s\n",
      "371:\tlearn: 0.2613978\ttotal: 12.7s\tremaining: 21.5s\n",
      "372:\tlearn: 0.2610673\ttotal: 12.8s\tremaining: 21.5s\n",
      "373:\tlearn: 0.2609644\ttotal: 12.8s\tremaining: 21.5s\n",
      "374:\tlearn: 0.2606589\ttotal: 12.9s\tremaining: 21.4s\n",
      "375:\tlearn: 0.2602973\ttotal: 12.9s\tremaining: 21.4s\n",
      "376:\tlearn: 0.2599166\ttotal: 12.9s\tremaining: 21.3s\n",
      "377:\tlearn: 0.2597850\ttotal: 12.9s\tremaining: 21.3s\n",
      "378:\tlearn: 0.2594081\ttotal: 13s\tremaining: 21.3s\n",
      "379:\tlearn: 0.2591987\ttotal: 13s\tremaining: 21.2s\n",
      "380:\tlearn: 0.2589634\ttotal: 13.1s\tremaining: 21.2s\n",
      "381:\tlearn: 0.2588005\ttotal: 13.1s\tremaining: 21.2s\n",
      "382:\tlearn: 0.2583612\ttotal: 13.1s\tremaining: 21.2s\n",
      "383:\tlearn: 0.2580244\ttotal: 13.2s\tremaining: 21.1s\n",
      "384:\tlearn: 0.2578062\ttotal: 13.2s\tremaining: 21.1s\n",
      "385:\tlearn: 0.2574030\ttotal: 13.2s\tremaining: 21.1s\n",
      "386:\tlearn: 0.2572907\ttotal: 13.3s\tremaining: 21s\n",
      "387:\tlearn: 0.2568271\ttotal: 13.3s\tremaining: 21s\n",
      "388:\tlearn: 0.2564230\ttotal: 13.3s\tremaining: 21s\n",
      "389:\tlearn: 0.2561450\ttotal: 13.4s\tremaining: 20.9s\n",
      "390:\tlearn: 0.2559966\ttotal: 13.4s\tremaining: 20.9s\n",
      "391:\tlearn: 0.2559321\ttotal: 13.4s\tremaining: 20.8s\n",
      "392:\tlearn: 0.2555507\ttotal: 13.5s\tremaining: 20.8s\n",
      "393:\tlearn: 0.2551421\ttotal: 13.5s\tremaining: 20.8s\n",
      "394:\tlearn: 0.2548879\ttotal: 13.6s\tremaining: 20.8s\n",
      "395:\tlearn: 0.2547259\ttotal: 13.6s\tremaining: 20.7s\n",
      "396:\tlearn: 0.2543535\ttotal: 13.6s\tremaining: 20.7s\n",
      "397:\tlearn: 0.2541195\ttotal: 13.7s\tremaining: 20.7s\n",
      "398:\tlearn: 0.2539961\ttotal: 13.7s\tremaining: 20.6s\n",
      "399:\tlearn: 0.2536131\ttotal: 13.7s\tremaining: 20.6s\n",
      "400:\tlearn: 0.2532943\ttotal: 13.8s\tremaining: 20.6s\n",
      "401:\tlearn: 0.2529367\ttotal: 13.8s\tremaining: 20.5s\n",
      "402:\tlearn: 0.2526167\ttotal: 13.8s\tremaining: 20.5s\n",
      "403:\tlearn: 0.2523981\ttotal: 13.9s\tremaining: 20.4s\n",
      "404:\tlearn: 0.2522120\ttotal: 13.9s\tremaining: 20.4s\n",
      "405:\tlearn: 0.2521265\ttotal: 13.9s\tremaining: 20.4s\n",
      "406:\tlearn: 0.2517791\ttotal: 14s\tremaining: 20.3s\n",
      "407:\tlearn: 0.2513653\ttotal: 14s\tremaining: 20.3s\n",
      "408:\tlearn: 0.2511480\ttotal: 14s\tremaining: 20.3s\n",
      "409:\tlearn: 0.2509408\ttotal: 14.1s\tremaining: 20.3s\n",
      "410:\tlearn: 0.2506379\ttotal: 14.1s\tremaining: 20.2s\n",
      "411:\tlearn: 0.2502641\ttotal: 14.1s\tremaining: 20.2s\n",
      "412:\tlearn: 0.2499082\ttotal: 14.2s\tremaining: 20.2s\n",
      "413:\tlearn: 0.2496652\ttotal: 14.2s\tremaining: 20.1s\n",
      "414:\tlearn: 0.2493581\ttotal: 14.2s\tremaining: 20.1s\n",
      "415:\tlearn: 0.2492578\ttotal: 14.3s\tremaining: 20s\n",
      "416:\tlearn: 0.2491298\ttotal: 14.3s\tremaining: 20s\n",
      "417:\tlearn: 0.2488497\ttotal: 14.3s\tremaining: 20s\n",
      "418:\tlearn: 0.2485299\ttotal: 14.4s\tremaining: 19.9s\n",
      "419:\tlearn: 0.2483886\ttotal: 14.4s\tremaining: 19.9s\n",
      "420:\tlearn: 0.2482709\ttotal: 14.4s\tremaining: 19.9s\n",
      "421:\tlearn: 0.2479180\ttotal: 14.5s\tremaining: 19.8s\n",
      "422:\tlearn: 0.2477563\ttotal: 14.5s\tremaining: 19.8s\n",
      "423:\tlearn: 0.2475530\ttotal: 14.6s\tremaining: 19.8s\n",
      "424:\tlearn: 0.2473719\ttotal: 14.6s\tremaining: 19.7s\n",
      "425:\tlearn: 0.2472045\ttotal: 14.6s\tremaining: 19.7s\n",
      "426:\tlearn: 0.2470485\ttotal: 14.7s\tremaining: 19.7s\n",
      "427:\tlearn: 0.2468860\ttotal: 14.7s\tremaining: 19.6s\n",
      "428:\tlearn: 0.2467613\ttotal: 14.7s\tremaining: 19.6s\n",
      "429:\tlearn: 0.2464625\ttotal: 14.8s\tremaining: 19.6s\n",
      "430:\tlearn: 0.2462689\ttotal: 14.8s\tremaining: 19.5s\n",
      "431:\tlearn: 0.2461623\ttotal: 14.8s\tremaining: 19.5s\n",
      "432:\tlearn: 0.2459786\ttotal: 14.9s\tremaining: 19.5s\n",
      "433:\tlearn: 0.2456131\ttotal: 14.9s\tremaining: 19.4s\n",
      "434:\tlearn: 0.2455404\ttotal: 14.9s\tremaining: 19.4s\n",
      "435:\tlearn: 0.2451452\ttotal: 15s\tremaining: 19.4s\n",
      "436:\tlearn: 0.2447822\ttotal: 15s\tremaining: 19.3s\n",
      "437:\tlearn: 0.2446874\ttotal: 15s\tremaining: 19.3s\n",
      "438:\tlearn: 0.2442801\ttotal: 15.1s\tremaining: 19.3s\n",
      "439:\tlearn: 0.2440143\ttotal: 15.1s\tremaining: 19.2s\n",
      "440:\tlearn: 0.2439133\ttotal: 15.1s\tremaining: 19.2s\n",
      "441:\tlearn: 0.2436895\ttotal: 15.2s\tremaining: 19.1s\n",
      "442:\tlearn: 0.2432010\ttotal: 15.2s\tremaining: 19.1s\n",
      "443:\tlearn: 0.2430041\ttotal: 15.2s\tremaining: 19.1s\n",
      "444:\tlearn: 0.2426912\ttotal: 15.3s\tremaining: 19s\n",
      "445:\tlearn: 0.2424610\ttotal: 15.3s\tremaining: 19s\n",
      "446:\tlearn: 0.2422480\ttotal: 15.4s\tremaining: 19s\n",
      "447:\tlearn: 0.2419101\ttotal: 15.4s\tremaining: 19s\n",
      "448:\tlearn: 0.2417474\ttotal: 15.4s\tremaining: 18.9s\n",
      "449:\tlearn: 0.2415495\ttotal: 15.5s\tremaining: 18.9s\n",
      "450:\tlearn: 0.2414567\ttotal: 15.5s\tremaining: 18.9s\n",
      "451:\tlearn: 0.2412628\ttotal: 15.5s\tremaining: 18.8s\n",
      "452:\tlearn: 0.2411291\ttotal: 15.6s\tremaining: 18.8s\n",
      "453:\tlearn: 0.2410114\ttotal: 15.6s\tremaining: 18.7s\n",
      "454:\tlearn: 0.2406915\ttotal: 15.6s\tremaining: 18.7s\n",
      "455:\tlearn: 0.2405882\ttotal: 15.6s\tremaining: 18.7s\n",
      "456:\tlearn: 0.2402239\ttotal: 15.7s\tremaining: 18.6s\n",
      "457:\tlearn: 0.2398769\ttotal: 15.7s\tremaining: 18.6s\n",
      "458:\tlearn: 0.2397912\ttotal: 15.7s\tremaining: 18.6s\n",
      "459:\tlearn: 0.2396358\ttotal: 15.8s\tremaining: 18.5s\n",
      "460:\tlearn: 0.2394441\ttotal: 15.8s\tremaining: 18.5s\n",
      "461:\tlearn: 0.2392243\ttotal: 15.9s\tremaining: 18.5s\n",
      "462:\tlearn: 0.2389716\ttotal: 15.9s\tremaining: 18.5s\n",
      "463:\tlearn: 0.2385506\ttotal: 15.9s\tremaining: 18.4s\n",
      "464:\tlearn: 0.2384933\ttotal: 16s\tremaining: 18.4s\n",
      "465:\tlearn: 0.2382320\ttotal: 16s\tremaining: 18.3s\n",
      "466:\tlearn: 0.2378707\ttotal: 16s\tremaining: 18.3s\n",
      "467:\tlearn: 0.2377992\ttotal: 16.1s\tremaining: 18.3s\n",
      "468:\tlearn: 0.2374833\ttotal: 16.1s\tremaining: 18.2s\n",
      "469:\tlearn: 0.2371949\ttotal: 16.1s\tremaining: 18.2s\n",
      "470:\tlearn: 0.2368256\ttotal: 16.2s\tremaining: 18.2s\n",
      "471:\tlearn: 0.2366926\ttotal: 16.2s\tremaining: 18.1s\n",
      "472:\tlearn: 0.2364397\ttotal: 16.2s\tremaining: 18.1s\n",
      "473:\tlearn: 0.2363407\ttotal: 16.3s\tremaining: 18.1s\n",
      "474:\tlearn: 0.2362152\ttotal: 16.3s\tremaining: 18s\n",
      "475:\tlearn: 0.2359576\ttotal: 16.4s\tremaining: 18s\n",
      "476:\tlearn: 0.2358744\ttotal: 16.4s\tremaining: 18s\n",
      "477:\tlearn: 0.2357558\ttotal: 16.4s\tremaining: 17.9s\n",
      "478:\tlearn: 0.2355754\ttotal: 16.5s\tremaining: 17.9s\n",
      "479:\tlearn: 0.2353850\ttotal: 16.5s\tremaining: 17.9s\n",
      "480:\tlearn: 0.2351886\ttotal: 16.5s\tremaining: 17.8s\n",
      "481:\tlearn: 0.2350716\ttotal: 16.6s\tremaining: 17.8s\n",
      "482:\tlearn: 0.2349888\ttotal: 16.6s\tremaining: 17.7s\n",
      "483:\tlearn: 0.2347947\ttotal: 16.6s\tremaining: 17.7s\n",
      "484:\tlearn: 0.2345065\ttotal: 16.7s\tremaining: 17.7s\n",
      "485:\tlearn: 0.2342813\ttotal: 16.7s\tremaining: 17.7s\n",
      "486:\tlearn: 0.2341142\ttotal: 16.7s\tremaining: 17.6s\n",
      "487:\tlearn: 0.2340356\ttotal: 16.8s\tremaining: 17.6s\n",
      "488:\tlearn: 0.2337945\ttotal: 16.8s\tremaining: 17.6s\n",
      "489:\tlearn: 0.2336415\ttotal: 16.9s\tremaining: 17.5s\n",
      "490:\tlearn: 0.2334287\ttotal: 16.9s\tremaining: 17.5s\n",
      "491:\tlearn: 0.2332540\ttotal: 16.9s\tremaining: 17.5s\n",
      "492:\tlearn: 0.2330408\ttotal: 16.9s\tremaining: 17.4s\n",
      "493:\tlearn: 0.2328297\ttotal: 17s\tremaining: 17.4s\n",
      "494:\tlearn: 0.2326297\ttotal: 17s\tremaining: 17.4s\n",
      "495:\tlearn: 0.2324827\ttotal: 17s\tremaining: 17.3s\n",
      "496:\tlearn: 0.2322732\ttotal: 17.1s\tremaining: 17.3s\n",
      "497:\tlearn: 0.2321002\ttotal: 17.1s\tremaining: 17.2s\n",
      "498:\tlearn: 0.2319727\ttotal: 17.2s\tremaining: 17.2s\n",
      "499:\tlearn: 0.2315553\ttotal: 17.2s\tremaining: 17.2s\n",
      "500:\tlearn: 0.2312235\ttotal: 17.2s\tremaining: 17.2s\n",
      "501:\tlearn: 0.2311847\ttotal: 17.3s\tremaining: 17.1s\n",
      "502:\tlearn: 0.2309765\ttotal: 17.3s\tremaining: 17.1s\n",
      "503:\tlearn: 0.2307731\ttotal: 17.3s\tremaining: 17.1s\n",
      "504:\tlearn: 0.2306994\ttotal: 17.4s\tremaining: 17s\n",
      "505:\tlearn: 0.2304364\ttotal: 17.4s\tremaining: 17s\n",
      "506:\tlearn: 0.2302967\ttotal: 17.4s\tremaining: 16.9s\n",
      "507:\tlearn: 0.2302354\ttotal: 17.5s\tremaining: 16.9s\n",
      "508:\tlearn: 0.2300743\ttotal: 17.5s\tremaining: 16.9s\n",
      "509:\tlearn: 0.2298132\ttotal: 17.5s\tremaining: 16.8s\n",
      "510:\tlearn: 0.2295370\ttotal: 17.6s\tremaining: 16.8s\n",
      "511:\tlearn: 0.2294304\ttotal: 17.6s\tremaining: 16.8s\n",
      "512:\tlearn: 0.2292846\ttotal: 17.6s\tremaining: 16.8s\n",
      "513:\tlearn: 0.2290992\ttotal: 17.7s\tremaining: 16.7s\n",
      "514:\tlearn: 0.2287405\ttotal: 17.7s\tremaining: 16.7s\n",
      "515:\tlearn: 0.2284618\ttotal: 17.8s\tremaining: 16.6s\n",
      "516:\tlearn: 0.2282492\ttotal: 17.8s\tremaining: 16.6s\n",
      "517:\tlearn: 0.2281628\ttotal: 17.8s\tremaining: 16.6s\n",
      "518:\tlearn: 0.2279907\ttotal: 17.9s\tremaining: 16.5s\n",
      "519:\tlearn: 0.2276444\ttotal: 17.9s\tremaining: 16.5s\n",
      "520:\tlearn: 0.2274277\ttotal: 17.9s\tremaining: 16.5s\n",
      "521:\tlearn: 0.2271471\ttotal: 18s\tremaining: 16.4s\n",
      "522:\tlearn: 0.2269434\ttotal: 18s\tremaining: 16.4s\n",
      "523:\tlearn: 0.2267798\ttotal: 18s\tremaining: 16.4s\n",
      "524:\tlearn: 0.2264914\ttotal: 18.1s\tremaining: 16.4s\n",
      "525:\tlearn: 0.2263539\ttotal: 18.1s\tremaining: 16.3s\n",
      "526:\tlearn: 0.2261074\ttotal: 18.1s\tremaining: 16.3s\n",
      "527:\tlearn: 0.2259889\ttotal: 18.2s\tremaining: 16.2s\n",
      "528:\tlearn: 0.2257657\ttotal: 18.2s\tremaining: 16.2s\n",
      "529:\tlearn: 0.2255585\ttotal: 18.2s\tremaining: 16.2s\n",
      "530:\tlearn: 0.2254382\ttotal: 18.3s\tremaining: 16.1s\n",
      "531:\tlearn: 0.2252746\ttotal: 18.3s\tremaining: 16.1s\n",
      "532:\tlearn: 0.2249875\ttotal: 18.3s\tremaining: 16.1s\n",
      "533:\tlearn: 0.2246758\ttotal: 18.4s\tremaining: 16s\n",
      "534:\tlearn: 0.2243292\ttotal: 18.4s\tremaining: 16s\n",
      "535:\tlearn: 0.2242469\ttotal: 18.4s\tremaining: 16s\n",
      "536:\tlearn: 0.2241122\ttotal: 18.5s\tremaining: 15.9s\n",
      "537:\tlearn: 0.2237973\ttotal: 18.5s\tremaining: 15.9s\n",
      "538:\tlearn: 0.2235999\ttotal: 18.6s\tremaining: 15.9s\n",
      "539:\tlearn: 0.2234564\ttotal: 18.6s\tremaining: 15.8s\n",
      "540:\tlearn: 0.2233059\ttotal: 18.6s\tremaining: 15.8s\n",
      "541:\tlearn: 0.2229934\ttotal: 18.7s\tremaining: 15.8s\n",
      "542:\tlearn: 0.2227622\ttotal: 18.7s\tremaining: 15.7s\n",
      "543:\tlearn: 0.2226477\ttotal: 18.7s\tremaining: 15.7s\n",
      "544:\tlearn: 0.2224556\ttotal: 18.8s\tremaining: 15.7s\n",
      "545:\tlearn: 0.2223402\ttotal: 18.8s\tremaining: 15.6s\n",
      "546:\tlearn: 0.2222339\ttotal: 18.8s\tremaining: 15.6s\n",
      "547:\tlearn: 0.2220499\ttotal: 18.9s\tremaining: 15.6s\n",
      "548:\tlearn: 0.2217900\ttotal: 18.9s\tremaining: 15.5s\n",
      "549:\tlearn: 0.2217456\ttotal: 18.9s\tremaining: 15.5s\n",
      "550:\tlearn: 0.2215833\ttotal: 19s\tremaining: 15.5s\n",
      "551:\tlearn: 0.2213636\ttotal: 19s\tremaining: 15.4s\n",
      "552:\tlearn: 0.2210317\ttotal: 19.1s\tremaining: 15.4s\n",
      "553:\tlearn: 0.2208196\ttotal: 19.1s\tremaining: 15.4s\n",
      "554:\tlearn: 0.2206112\ttotal: 19.1s\tremaining: 15.3s\n",
      "555:\tlearn: 0.2204770\ttotal: 19.2s\tremaining: 15.3s\n",
      "556:\tlearn: 0.2203844\ttotal: 19.2s\tremaining: 15.3s\n",
      "557:\tlearn: 0.2200950\ttotal: 19.2s\tremaining: 15.2s\n",
      "558:\tlearn: 0.2199533\ttotal: 19.3s\tremaining: 15.2s\n",
      "559:\tlearn: 0.2198024\ttotal: 19.3s\tremaining: 15.2s\n",
      "560:\tlearn: 0.2197221\ttotal: 19.3s\tremaining: 15.1s\n",
      "561:\tlearn: 0.2196069\ttotal: 19.4s\tremaining: 15.1s\n",
      "562:\tlearn: 0.2193658\ttotal: 19.4s\tremaining: 15.1s\n",
      "563:\tlearn: 0.2192522\ttotal: 19.4s\tremaining: 15s\n",
      "564:\tlearn: 0.2191019\ttotal: 19.5s\tremaining: 15s\n",
      "565:\tlearn: 0.2189407\ttotal: 19.5s\tremaining: 15s\n",
      "566:\tlearn: 0.2185870\ttotal: 19.5s\tremaining: 14.9s\n",
      "567:\tlearn: 0.2184089\ttotal: 19.6s\tremaining: 14.9s\n",
      "568:\tlearn: 0.2181348\ttotal: 19.6s\tremaining: 14.9s\n",
      "569:\tlearn: 0.2180355\ttotal: 19.7s\tremaining: 14.8s\n",
      "570:\tlearn: 0.2178807\ttotal: 19.7s\tremaining: 14.8s\n",
      "571:\tlearn: 0.2177367\ttotal: 19.7s\tremaining: 14.8s\n",
      "572:\tlearn: 0.2176146\ttotal: 19.7s\tremaining: 14.7s\n",
      "573:\tlearn: 0.2175553\ttotal: 19.8s\tremaining: 14.7s\n",
      "574:\tlearn: 0.2175042\ttotal: 19.8s\tremaining: 14.6s\n",
      "575:\tlearn: 0.2173785\ttotal: 19.8s\tremaining: 14.6s\n",
      "576:\tlearn: 0.2170699\ttotal: 19.9s\tremaining: 14.6s\n",
      "577:\tlearn: 0.2168453\ttotal: 19.9s\tremaining: 14.5s\n",
      "578:\tlearn: 0.2166433\ttotal: 20s\tremaining: 14.5s\n",
      "579:\tlearn: 0.2164364\ttotal: 20s\tremaining: 14.5s\n",
      "580:\tlearn: 0.2162149\ttotal: 20s\tremaining: 14.4s\n",
      "581:\tlearn: 0.2161081\ttotal: 20.1s\tremaining: 14.4s\n",
      "582:\tlearn: 0.2159457\ttotal: 20.1s\tremaining: 14.4s\n",
      "583:\tlearn: 0.2157233\ttotal: 20.1s\tremaining: 14.3s\n",
      "584:\tlearn: 0.2155552\ttotal: 20.2s\tremaining: 14.3s\n",
      "585:\tlearn: 0.2154575\ttotal: 20.2s\tremaining: 14.3s\n",
      "586:\tlearn: 0.2152155\ttotal: 20.2s\tremaining: 14.2s\n",
      "587:\tlearn: 0.2150536\ttotal: 20.3s\tremaining: 14.2s\n",
      "588:\tlearn: 0.2148405\ttotal: 20.3s\tremaining: 14.2s\n",
      "589:\tlearn: 0.2145668\ttotal: 20.3s\tremaining: 14.1s\n",
      "590:\tlearn: 0.2144346\ttotal: 20.4s\tremaining: 14.1s\n",
      "591:\tlearn: 0.2143421\ttotal: 20.4s\tremaining: 14.1s\n",
      "592:\tlearn: 0.2141775\ttotal: 20.5s\tremaining: 14s\n",
      "593:\tlearn: 0.2140021\ttotal: 20.5s\tremaining: 14s\n",
      "594:\tlearn: 0.2138655\ttotal: 20.5s\tremaining: 14s\n",
      "595:\tlearn: 0.2138002\ttotal: 20.6s\tremaining: 13.9s\n",
      "596:\tlearn: 0.2136440\ttotal: 20.6s\tremaining: 13.9s\n",
      "597:\tlearn: 0.2135214\ttotal: 20.6s\tremaining: 13.9s\n",
      "598:\tlearn: 0.2132859\ttotal: 20.7s\tremaining: 13.8s\n",
      "599:\tlearn: 0.2131272\ttotal: 20.7s\tremaining: 13.8s\n",
      "600:\tlearn: 0.2129813\ttotal: 20.7s\tremaining: 13.8s\n",
      "601:\tlearn: 0.2127674\ttotal: 20.8s\tremaining: 13.7s\n",
      "602:\tlearn: 0.2126125\ttotal: 20.8s\tremaining: 13.7s\n",
      "603:\tlearn: 0.2123377\ttotal: 20.8s\tremaining: 13.7s\n",
      "604:\tlearn: 0.2122659\ttotal: 20.9s\tremaining: 13.6s\n",
      "605:\tlearn: 0.2121367\ttotal: 20.9s\tremaining: 13.6s\n",
      "606:\tlearn: 0.2119348\ttotal: 21s\tremaining: 13.6s\n",
      "607:\tlearn: 0.2118709\ttotal: 21s\tremaining: 13.5s\n",
      "608:\tlearn: 0.2117367\ttotal: 21s\tremaining: 13.5s\n",
      "609:\tlearn: 0.2116280\ttotal: 21s\tremaining: 13.5s\n",
      "610:\tlearn: 0.2114529\ttotal: 21.1s\tremaining: 13.4s\n",
      "611:\tlearn: 0.2112818\ttotal: 21.1s\tremaining: 13.4s\n",
      "612:\tlearn: 0.2111996\ttotal: 21.1s\tremaining: 13.3s\n",
      "613:\tlearn: 0.2111230\ttotal: 21.2s\tremaining: 13.3s\n",
      "614:\tlearn: 0.2109851\ttotal: 21.2s\tremaining: 13.3s\n",
      "615:\tlearn: 0.2108381\ttotal: 21.3s\tremaining: 13.3s\n",
      "616:\tlearn: 0.2107310\ttotal: 21.3s\tremaining: 13.2s\n",
      "617:\tlearn: 0.2105287\ttotal: 21.3s\tremaining: 13.2s\n",
      "618:\tlearn: 0.2104896\ttotal: 21.4s\tremaining: 13.1s\n",
      "619:\tlearn: 0.2103069\ttotal: 21.4s\tremaining: 13.1s\n",
      "620:\tlearn: 0.2102066\ttotal: 21.4s\tremaining: 13.1s\n",
      "621:\tlearn: 0.2101259\ttotal: 21.5s\tremaining: 13s\n",
      "622:\tlearn: 0.2100656\ttotal: 21.5s\tremaining: 13s\n",
      "623:\tlearn: 0.2099333\ttotal: 21.5s\tremaining: 13s\n",
      "624:\tlearn: 0.2097924\ttotal: 21.6s\tremaining: 12.9s\n",
      "625:\tlearn: 0.2097173\ttotal: 21.6s\tremaining: 12.9s\n",
      "626:\tlearn: 0.2096172\ttotal: 21.6s\tremaining: 12.9s\n",
      "627:\tlearn: 0.2094570\ttotal: 21.7s\tremaining: 12.8s\n",
      "628:\tlearn: 0.2092860\ttotal: 21.7s\tremaining: 12.8s\n",
      "629:\tlearn: 0.2090119\ttotal: 21.8s\tremaining: 12.8s\n",
      "630:\tlearn: 0.2088281\ttotal: 21.8s\tremaining: 12.7s\n",
      "631:\tlearn: 0.2087327\ttotal: 21.8s\tremaining: 12.7s\n",
      "632:\tlearn: 0.2085534\ttotal: 21.9s\tremaining: 12.7s\n",
      "633:\tlearn: 0.2084083\ttotal: 21.9s\tremaining: 12.6s\n",
      "634:\tlearn: 0.2083574\ttotal: 21.9s\tremaining: 12.6s\n",
      "635:\tlearn: 0.2081600\ttotal: 21.9s\tremaining: 12.6s\n",
      "636:\tlearn: 0.2079086\ttotal: 22s\tremaining: 12.5s\n",
      "637:\tlearn: 0.2077927\ttotal: 22s\tremaining: 12.5s\n",
      "638:\tlearn: 0.2077026\ttotal: 22.1s\tremaining: 12.5s\n",
      "639:\tlearn: 0.2074657\ttotal: 22.1s\tremaining: 12.4s\n",
      "640:\tlearn: 0.2072520\ttotal: 22.1s\tremaining: 12.4s\n",
      "641:\tlearn: 0.2071166\ttotal: 22.2s\tremaining: 12.4s\n",
      "642:\tlearn: 0.2069077\ttotal: 22.2s\tremaining: 12.3s\n",
      "643:\tlearn: 0.2067991\ttotal: 22.2s\tremaining: 12.3s\n",
      "644:\tlearn: 0.2066049\ttotal: 22.3s\tremaining: 12.3s\n",
      "645:\tlearn: 0.2064848\ttotal: 22.3s\tremaining: 12.2s\n",
      "646:\tlearn: 0.2063782\ttotal: 22.3s\tremaining: 12.2s\n",
      "647:\tlearn: 0.2061872\ttotal: 22.4s\tremaining: 12.2s\n",
      "648:\tlearn: 0.2060206\ttotal: 22.4s\tremaining: 12.1s\n",
      "649:\tlearn: 0.2059587\ttotal: 22.4s\tremaining: 12.1s\n",
      "650:\tlearn: 0.2057866\ttotal: 22.5s\tremaining: 12s\n",
      "651:\tlearn: 0.2057361\ttotal: 22.5s\tremaining: 12s\n",
      "652:\tlearn: 0.2055759\ttotal: 22.5s\tremaining: 12s\n",
      "653:\tlearn: 0.2054126\ttotal: 22.6s\tremaining: 12s\n",
      "654:\tlearn: 0.2052478\ttotal: 22.6s\tremaining: 11.9s\n",
      "655:\tlearn: 0.2051199\ttotal: 22.7s\tremaining: 11.9s\n",
      "656:\tlearn: 0.2050702\ttotal: 22.7s\tremaining: 11.8s\n",
      "657:\tlearn: 0.2048506\ttotal: 22.7s\tremaining: 11.8s\n",
      "658:\tlearn: 0.2046303\ttotal: 22.8s\tremaining: 11.8s\n",
      "659:\tlearn: 0.2044454\ttotal: 22.8s\tremaining: 11.7s\n",
      "660:\tlearn: 0.2041163\ttotal: 22.8s\tremaining: 11.7s\n",
      "661:\tlearn: 0.2039992\ttotal: 22.9s\tremaining: 11.7s\n",
      "662:\tlearn: 0.2038148\ttotal: 22.9s\tremaining: 11.6s\n",
      "663:\tlearn: 0.2037323\ttotal: 22.9s\tremaining: 11.6s\n",
      "664:\tlearn: 0.2035885\ttotal: 23s\tremaining: 11.6s\n",
      "665:\tlearn: 0.2034487\ttotal: 23s\tremaining: 11.5s\n",
      "666:\tlearn: 0.2034167\ttotal: 23s\tremaining: 11.5s\n",
      "667:\tlearn: 0.2033414\ttotal: 23.1s\tremaining: 11.5s\n",
      "668:\tlearn: 0.2031304\ttotal: 23.1s\tremaining: 11.4s\n",
      "669:\tlearn: 0.2030224\ttotal: 23.1s\tremaining: 11.4s\n",
      "670:\tlearn: 0.2027577\ttotal: 23.2s\tremaining: 11.4s\n",
      "671:\tlearn: 0.2025567\ttotal: 23.2s\tremaining: 11.3s\n",
      "672:\tlearn: 0.2024363\ttotal: 23.3s\tremaining: 11.3s\n",
      "673:\tlearn: 0.2022855\ttotal: 23.3s\tremaining: 11.3s\n",
      "674:\tlearn: 0.2022340\ttotal: 23.3s\tremaining: 11.2s\n",
      "675:\tlearn: 0.2020950\ttotal: 23.3s\tremaining: 11.2s\n",
      "676:\tlearn: 0.2019375\ttotal: 23.4s\tremaining: 11.2s\n",
      "677:\tlearn: 0.2017595\ttotal: 23.4s\tremaining: 11.1s\n",
      "678:\tlearn: 0.2016321\ttotal: 23.5s\tremaining: 11.1s\n",
      "679:\tlearn: 0.2014829\ttotal: 23.5s\tremaining: 11.1s\n",
      "680:\tlearn: 0.2012760\ttotal: 23.5s\tremaining: 11s\n",
      "681:\tlearn: 0.2012191\ttotal: 23.6s\tremaining: 11s\n",
      "682:\tlearn: 0.2010307\ttotal: 23.6s\tremaining: 11s\n",
      "683:\tlearn: 0.2008946\ttotal: 23.6s\tremaining: 10.9s\n",
      "684:\tlearn: 0.2005950\ttotal: 23.7s\tremaining: 10.9s\n",
      "685:\tlearn: 0.2005436\ttotal: 23.7s\tremaining: 10.8s\n",
      "686:\tlearn: 0.2004269\ttotal: 23.7s\tremaining: 10.8s\n",
      "687:\tlearn: 0.2002416\ttotal: 23.8s\tremaining: 10.8s\n",
      "688:\tlearn: 0.2001695\ttotal: 23.8s\tremaining: 10.7s\n",
      "689:\tlearn: 0.2000754\ttotal: 23.8s\tremaining: 10.7s\n",
      "690:\tlearn: 0.2000134\ttotal: 23.9s\tremaining: 10.7s\n",
      "691:\tlearn: 0.1998872\ttotal: 23.9s\tremaining: 10.6s\n",
      "692:\tlearn: 0.1996943\ttotal: 23.9s\tremaining: 10.6s\n",
      "693:\tlearn: 0.1995609\ttotal: 24s\tremaining: 10.6s\n",
      "694:\tlearn: 0.1994920\ttotal: 24s\tremaining: 10.5s\n",
      "695:\tlearn: 0.1993051\ttotal: 24.1s\tremaining: 10.5s\n",
      "696:\tlearn: 0.1991506\ttotal: 24.1s\tremaining: 10.5s\n",
      "697:\tlearn: 0.1990056\ttotal: 24.1s\tremaining: 10.4s\n",
      "698:\tlearn: 0.1989044\ttotal: 24.2s\tremaining: 10.4s\n",
      "699:\tlearn: 0.1987383\ttotal: 24.2s\tremaining: 10.4s\n",
      "700:\tlearn: 0.1986047\ttotal: 24.2s\tremaining: 10.3s\n",
      "701:\tlearn: 0.1985009\ttotal: 24.3s\tremaining: 10.3s\n",
      "702:\tlearn: 0.1982318\ttotal: 24.3s\tremaining: 10.3s\n",
      "703:\tlearn: 0.1981634\ttotal: 24.3s\tremaining: 10.2s\n",
      "704:\tlearn: 0.1980386\ttotal: 24.4s\tremaining: 10.2s\n",
      "705:\tlearn: 0.1979859\ttotal: 24.4s\tremaining: 10.2s\n",
      "706:\tlearn: 0.1979051\ttotal: 24.4s\tremaining: 10.1s\n",
      "707:\tlearn: 0.1977838\ttotal: 24.5s\tremaining: 10.1s\n",
      "708:\tlearn: 0.1975502\ttotal: 24.5s\tremaining: 10.1s\n",
      "709:\tlearn: 0.1972281\ttotal: 24.5s\tremaining: 10s\n",
      "710:\tlearn: 0.1971287\ttotal: 24.6s\tremaining: 9.99s\n",
      "711:\tlearn: 0.1970074\ttotal: 24.6s\tremaining: 9.96s\n",
      "712:\tlearn: 0.1967413\ttotal: 24.7s\tremaining: 9.92s\n",
      "713:\tlearn: 0.1966785\ttotal: 24.7s\tremaining: 9.89s\n",
      "714:\tlearn: 0.1964975\ttotal: 24.7s\tremaining: 9.85s\n",
      "715:\tlearn: 0.1962968\ttotal: 24.8s\tremaining: 9.82s\n",
      "716:\tlearn: 0.1962247\ttotal: 24.8s\tremaining: 9.78s\n",
      "717:\tlearn: 0.1960851\ttotal: 24.8s\tremaining: 9.75s\n",
      "718:\tlearn: 0.1959434\ttotal: 24.9s\tremaining: 9.72s\n",
      "719:\tlearn: 0.1957932\ttotal: 24.9s\tremaining: 9.69s\n",
      "720:\tlearn: 0.1956592\ttotal: 24.9s\tremaining: 9.65s\n",
      "721:\tlearn: 0.1954873\ttotal: 25s\tremaining: 9.62s\n",
      "722:\tlearn: 0.1954401\ttotal: 25s\tremaining: 9.58s\n",
      "723:\tlearn: 0.1952706\ttotal: 25s\tremaining: 9.55s\n",
      "724:\tlearn: 0.1950878\ttotal: 25.1s\tremaining: 9.51s\n",
      "725:\tlearn: 0.1950591\ttotal: 25.1s\tremaining: 9.48s\n",
      "726:\tlearn: 0.1949925\ttotal: 25.1s\tremaining: 9.44s\n",
      "727:\tlearn: 0.1949345\ttotal: 25.2s\tremaining: 9.4s\n",
      "728:\tlearn: 0.1948878\ttotal: 25.2s\tremaining: 9.37s\n",
      "729:\tlearn: 0.1947475\ttotal: 25.2s\tremaining: 9.33s\n",
      "730:\tlearn: 0.1945746\ttotal: 25.3s\tremaining: 9.3s\n",
      "731:\tlearn: 0.1944138\ttotal: 25.3s\tremaining: 9.27s\n",
      "732:\tlearn: 0.1943325\ttotal: 25.4s\tremaining: 9.24s\n",
      "733:\tlearn: 0.1942584\ttotal: 25.4s\tremaining: 9.2s\n",
      "734:\tlearn: 0.1941159\ttotal: 25.4s\tremaining: 9.17s\n",
      "735:\tlearn: 0.1939277\ttotal: 25.5s\tremaining: 9.14s\n",
      "736:\tlearn: 0.1938044\ttotal: 25.5s\tremaining: 9.1s\n",
      "737:\tlearn: 0.1936432\ttotal: 25.5s\tremaining: 9.07s\n",
      "738:\tlearn: 0.1935281\ttotal: 25.6s\tremaining: 9.03s\n",
      "739:\tlearn: 0.1934060\ttotal: 25.6s\tremaining: 8.99s\n",
      "740:\tlearn: 0.1931628\ttotal: 25.6s\tremaining: 8.96s\n",
      "741:\tlearn: 0.1930266\ttotal: 25.7s\tremaining: 8.92s\n",
      "742:\tlearn: 0.1928697\ttotal: 25.7s\tremaining: 8.89s\n",
      "743:\tlearn: 0.1928003\ttotal: 25.7s\tremaining: 8.85s\n",
      "744:\tlearn: 0.1926435\ttotal: 25.8s\tremaining: 8.82s\n",
      "745:\tlearn: 0.1925943\ttotal: 25.8s\tremaining: 8.79s\n",
      "746:\tlearn: 0.1923843\ttotal: 25.9s\tremaining: 8.76s\n",
      "747:\tlearn: 0.1921900\ttotal: 25.9s\tremaining: 8.72s\n",
      "748:\tlearn: 0.1920339\ttotal: 25.9s\tremaining: 8.69s\n",
      "749:\tlearn: 0.1918209\ttotal: 26s\tremaining: 8.65s\n",
      "750:\tlearn: 0.1917766\ttotal: 26s\tremaining: 8.62s\n",
      "751:\tlearn: 0.1916895\ttotal: 26s\tremaining: 8.58s\n",
      "752:\tlearn: 0.1915359\ttotal: 26.1s\tremaining: 8.55s\n",
      "753:\tlearn: 0.1914711\ttotal: 26.1s\tremaining: 8.51s\n",
      "754:\tlearn: 0.1912942\ttotal: 26.1s\tremaining: 8.47s\n",
      "755:\tlearn: 0.1912085\ttotal: 26.2s\tremaining: 8.44s\n",
      "756:\tlearn: 0.1909711\ttotal: 26.2s\tremaining: 8.41s\n",
      "757:\tlearn: 0.1908510\ttotal: 26.2s\tremaining: 8.38s\n",
      "758:\tlearn: 0.1907944\ttotal: 26.3s\tremaining: 8.35s\n",
      "759:\tlearn: 0.1907601\ttotal: 26.3s\tremaining: 8.31s\n",
      "760:\tlearn: 0.1906548\ttotal: 26.4s\tremaining: 8.28s\n",
      "761:\tlearn: 0.1905777\ttotal: 26.4s\tremaining: 8.24s\n",
      "762:\tlearn: 0.1904595\ttotal: 26.4s\tremaining: 8.21s\n",
      "763:\tlearn: 0.1903316\ttotal: 26.5s\tremaining: 8.17s\n",
      "764:\tlearn: 0.1902130\ttotal: 26.5s\tremaining: 8.14s\n",
      "765:\tlearn: 0.1900695\ttotal: 26.5s\tremaining: 8.1s\n",
      "766:\tlearn: 0.1899423\ttotal: 26.5s\tremaining: 8.06s\n",
      "767:\tlearn: 0.1898614\ttotal: 26.6s\tremaining: 8.03s\n",
      "768:\tlearn: 0.1897669\ttotal: 26.6s\tremaining: 8s\n",
      "769:\tlearn: 0.1897230\ttotal: 26.7s\tremaining: 7.96s\n",
      "770:\tlearn: 0.1896584\ttotal: 26.7s\tremaining: 7.93s\n",
      "771:\tlearn: 0.1896081\ttotal: 26.7s\tremaining: 7.9s\n",
      "772:\tlearn: 0.1895410\ttotal: 26.8s\tremaining: 7.86s\n",
      "773:\tlearn: 0.1893832\ttotal: 26.8s\tremaining: 7.83s\n",
      "774:\tlearn: 0.1892746\ttotal: 26.8s\tremaining: 7.79s\n",
      "775:\tlearn: 0.1891476\ttotal: 26.9s\tremaining: 7.76s\n",
      "776:\tlearn: 0.1889644\ttotal: 26.9s\tremaining: 7.72s\n",
      "777:\tlearn: 0.1887659\ttotal: 26.9s\tremaining: 7.69s\n",
      "778:\tlearn: 0.1885845\ttotal: 27s\tremaining: 7.65s\n",
      "779:\tlearn: 0.1884823\ttotal: 27s\tremaining: 7.62s\n",
      "780:\tlearn: 0.1882984\ttotal: 27.1s\tremaining: 7.59s\n",
      "781:\tlearn: 0.1881559\ttotal: 27.1s\tremaining: 7.55s\n",
      "782:\tlearn: 0.1880379\ttotal: 27.1s\tremaining: 7.52s\n",
      "783:\tlearn: 0.1878536\ttotal: 27.2s\tremaining: 7.49s\n",
      "784:\tlearn: 0.1877761\ttotal: 27.2s\tremaining: 7.45s\n",
      "785:\tlearn: 0.1876616\ttotal: 27.3s\tremaining: 7.42s\n",
      "786:\tlearn: 0.1875974\ttotal: 27.3s\tremaining: 7.39s\n",
      "787:\tlearn: 0.1874941\ttotal: 27.3s\tremaining: 7.35s\n",
      "788:\tlearn: 0.1874131\ttotal: 27.4s\tremaining: 7.32s\n",
      "789:\tlearn: 0.1873623\ttotal: 27.4s\tremaining: 7.28s\n",
      "790:\tlearn: 0.1872472\ttotal: 27.4s\tremaining: 7.24s\n",
      "791:\tlearn: 0.1871377\ttotal: 27.5s\tremaining: 7.21s\n",
      "792:\tlearn: 0.1870674\ttotal: 27.5s\tremaining: 7.18s\n",
      "793:\tlearn: 0.1869433\ttotal: 27.5s\tremaining: 7.14s\n",
      "794:\tlearn: 0.1868161\ttotal: 27.6s\tremaining: 7.11s\n",
      "795:\tlearn: 0.1867060\ttotal: 27.6s\tremaining: 7.08s\n",
      "796:\tlearn: 0.1866101\ttotal: 27.6s\tremaining: 7.04s\n",
      "797:\tlearn: 0.1864419\ttotal: 27.7s\tremaining: 7s\n",
      "798:\tlearn: 0.1863481\ttotal: 27.7s\tremaining: 6.97s\n",
      "799:\tlearn: 0.1863042\ttotal: 27.7s\tremaining: 6.93s\n",
      "800:\tlearn: 0.1861476\ttotal: 27.8s\tremaining: 6.9s\n",
      "801:\tlearn: 0.1860801\ttotal: 27.8s\tremaining: 6.87s\n",
      "802:\tlearn: 0.1859924\ttotal: 27.8s\tremaining: 6.83s\n",
      "803:\tlearn: 0.1858241\ttotal: 27.9s\tremaining: 6.79s\n",
      "804:\tlearn: 0.1857084\ttotal: 27.9s\tremaining: 6.76s\n",
      "805:\tlearn: 0.1856071\ttotal: 27.9s\tremaining: 6.72s\n",
      "806:\tlearn: 0.1854552\ttotal: 28s\tremaining: 6.69s\n",
      "807:\tlearn: 0.1852794\ttotal: 28s\tremaining: 6.66s\n",
      "808:\tlearn: 0.1850673\ttotal: 28.1s\tremaining: 6.63s\n",
      "809:\tlearn: 0.1848732\ttotal: 28.1s\tremaining: 6.59s\n",
      "810:\tlearn: 0.1846407\ttotal: 28.1s\tremaining: 6.56s\n",
      "811:\tlearn: 0.1845011\ttotal: 28.2s\tremaining: 6.53s\n",
      "812:\tlearn: 0.1844223\ttotal: 28.2s\tremaining: 6.49s\n",
      "813:\tlearn: 0.1842378\ttotal: 28.3s\tremaining: 6.46s\n",
      "814:\tlearn: 0.1840718\ttotal: 28.3s\tremaining: 6.42s\n",
      "815:\tlearn: 0.1838806\ttotal: 28.3s\tremaining: 6.38s\n",
      "816:\tlearn: 0.1837348\ttotal: 28.3s\tremaining: 6.35s\n",
      "817:\tlearn: 0.1836243\ttotal: 28.4s\tremaining: 6.31s\n",
      "818:\tlearn: 0.1835480\ttotal: 28.4s\tremaining: 6.28s\n",
      "819:\tlearn: 0.1834380\ttotal: 28.5s\tremaining: 6.25s\n",
      "820:\tlearn: 0.1833308\ttotal: 28.5s\tremaining: 6.21s\n",
      "821:\tlearn: 0.1831713\ttotal: 28.5s\tremaining: 6.18s\n",
      "822:\tlearn: 0.1829948\ttotal: 28.6s\tremaining: 6.14s\n",
      "823:\tlearn: 0.1828329\ttotal: 28.6s\tremaining: 6.11s\n",
      "824:\tlearn: 0.1826760\ttotal: 28.6s\tremaining: 6.08s\n",
      "825:\tlearn: 0.1825535\ttotal: 28.7s\tremaining: 6.04s\n",
      "826:\tlearn: 0.1824536\ttotal: 28.7s\tremaining: 6.01s\n",
      "827:\tlearn: 0.1821832\ttotal: 28.7s\tremaining: 5.97s\n",
      "828:\tlearn: 0.1821174\ttotal: 28.8s\tremaining: 5.93s\n",
      "829:\tlearn: 0.1820248\ttotal: 28.8s\tremaining: 5.9s\n",
      "830:\tlearn: 0.1818348\ttotal: 28.9s\tremaining: 5.87s\n",
      "831:\tlearn: 0.1817140\ttotal: 28.9s\tremaining: 5.83s\n",
      "832:\tlearn: 0.1816192\ttotal: 28.9s\tremaining: 5.8s\n",
      "833:\tlearn: 0.1813973\ttotal: 29s\tremaining: 5.77s\n",
      "834:\tlearn: 0.1812625\ttotal: 29s\tremaining: 5.73s\n",
      "835:\tlearn: 0.1811906\ttotal: 29.1s\tremaining: 5.7s\n",
      "836:\tlearn: 0.1809876\ttotal: 29.1s\tremaining: 5.67s\n",
      "837:\tlearn: 0.1807628\ttotal: 29.1s\tremaining: 5.63s\n",
      "838:\tlearn: 0.1806298\ttotal: 29.2s\tremaining: 5.59s\n",
      "839:\tlearn: 0.1804966\ttotal: 29.2s\tremaining: 5.56s\n",
      "840:\tlearn: 0.1803363\ttotal: 29.2s\tremaining: 5.52s\n",
      "841:\tlearn: 0.1802281\ttotal: 29.2s\tremaining: 5.49s\n",
      "842:\tlearn: 0.1801006\ttotal: 29.3s\tremaining: 5.45s\n",
      "843:\tlearn: 0.1800486\ttotal: 29.3s\tremaining: 5.42s\n",
      "844:\tlearn: 0.1798736\ttotal: 29.4s\tremaining: 5.39s\n",
      "845:\tlearn: 0.1798221\ttotal: 29.4s\tremaining: 5.36s\n",
      "846:\tlearn: 0.1797739\ttotal: 29.5s\tremaining: 5.32s\n",
      "847:\tlearn: 0.1797109\ttotal: 29.5s\tremaining: 5.29s\n",
      "848:\tlearn: 0.1796632\ttotal: 29.5s\tremaining: 5.25s\n",
      "849:\tlearn: 0.1795174\ttotal: 29.6s\tremaining: 5.21s\n",
      "850:\tlearn: 0.1793143\ttotal: 29.6s\tremaining: 5.18s\n",
      "851:\tlearn: 0.1792427\ttotal: 29.6s\tremaining: 5.14s\n",
      "852:\tlearn: 0.1791475\ttotal: 29.7s\tremaining: 5.11s\n",
      "853:\tlearn: 0.1790806\ttotal: 29.7s\tremaining: 5.07s\n",
      "854:\tlearn: 0.1789925\ttotal: 29.7s\tremaining: 5.04s\n",
      "855:\tlearn: 0.1789345\ttotal: 29.7s\tremaining: 5s\n",
      "856:\tlearn: 0.1788506\ttotal: 29.8s\tremaining: 4.97s\n",
      "857:\tlearn: 0.1787415\ttotal: 29.8s\tremaining: 4.94s\n",
      "858:\tlearn: 0.1786311\ttotal: 29.9s\tremaining: 4.9s\n",
      "859:\tlearn: 0.1784477\ttotal: 29.9s\tremaining: 4.87s\n",
      "860:\tlearn: 0.1783235\ttotal: 29.9s\tremaining: 4.83s\n",
      "861:\tlearn: 0.1782305\ttotal: 30s\tremaining: 4.8s\n",
      "862:\tlearn: 0.1781198\ttotal: 30s\tremaining: 4.76s\n",
      "863:\tlearn: 0.1780843\ttotal: 30.1s\tremaining: 4.73s\n",
      "864:\tlearn: 0.1780171\ttotal: 30.1s\tremaining: 4.7s\n",
      "865:\tlearn: 0.1779117\ttotal: 30.1s\tremaining: 4.66s\n",
      "866:\tlearn: 0.1778446\ttotal: 30.1s\tremaining: 4.62s\n",
      "867:\tlearn: 0.1776070\ttotal: 30.2s\tremaining: 4.59s\n",
      "868:\tlearn: 0.1775270\ttotal: 30.2s\tremaining: 4.55s\n",
      "869:\tlearn: 0.1774958\ttotal: 30.3s\tremaining: 4.52s\n",
      "870:\tlearn: 0.1774078\ttotal: 30.3s\tremaining: 4.49s\n",
      "871:\tlearn: 0.1773176\ttotal: 30.3s\tremaining: 4.45s\n",
      "872:\tlearn: 0.1772845\ttotal: 30.4s\tremaining: 4.42s\n",
      "873:\tlearn: 0.1771854\ttotal: 30.4s\tremaining: 4.38s\n",
      "874:\tlearn: 0.1770880\ttotal: 30.5s\tremaining: 4.35s\n",
      "875:\tlearn: 0.1769396\ttotal: 30.5s\tremaining: 4.31s\n",
      "876:\tlearn: 0.1769003\ttotal: 30.5s\tremaining: 4.28s\n",
      "877:\tlearn: 0.1767848\ttotal: 30.5s\tremaining: 4.24s\n",
      "878:\tlearn: 0.1767099\ttotal: 30.6s\tremaining: 4.21s\n",
      "879:\tlearn: 0.1765764\ttotal: 30.6s\tremaining: 4.17s\n",
      "880:\tlearn: 0.1764808\ttotal: 30.6s\tremaining: 4.14s\n",
      "881:\tlearn: 0.1764036\ttotal: 30.7s\tremaining: 4.1s\n",
      "882:\tlearn: 0.1763219\ttotal: 30.7s\tremaining: 4.07s\n",
      "883:\tlearn: 0.1762415\ttotal: 30.8s\tremaining: 4.04s\n",
      "884:\tlearn: 0.1761677\ttotal: 30.8s\tremaining: 4s\n",
      "885:\tlearn: 0.1760845\ttotal: 30.8s\tremaining: 3.97s\n",
      "886:\tlearn: 0.1760326\ttotal: 30.9s\tremaining: 3.93s\n",
      "887:\tlearn: 0.1759027\ttotal: 30.9s\tremaining: 3.9s\n",
      "888:\tlearn: 0.1758138\ttotal: 30.9s\tremaining: 3.86s\n",
      "889:\tlearn: 0.1756188\ttotal: 31s\tremaining: 3.83s\n",
      "890:\tlearn: 0.1755199\ttotal: 31s\tremaining: 3.79s\n",
      "891:\tlearn: 0.1754816\ttotal: 31s\tremaining: 3.76s\n",
      "892:\tlearn: 0.1754234\ttotal: 31.1s\tremaining: 3.72s\n",
      "893:\tlearn: 0.1753193\ttotal: 31.1s\tremaining: 3.69s\n",
      "894:\tlearn: 0.1751158\ttotal: 31.1s\tremaining: 3.65s\n",
      "895:\tlearn: 0.1750560\ttotal: 31.2s\tremaining: 3.62s\n",
      "896:\tlearn: 0.1750139\ttotal: 31.2s\tremaining: 3.58s\n",
      "897:\tlearn: 0.1749388\ttotal: 31.2s\tremaining: 3.55s\n",
      "898:\tlearn: 0.1748425\ttotal: 31.3s\tremaining: 3.51s\n",
      "899:\tlearn: 0.1748113\ttotal: 31.3s\tremaining: 3.48s\n",
      "900:\tlearn: 0.1745451\ttotal: 31.3s\tremaining: 3.44s\n",
      "901:\tlearn: 0.1744812\ttotal: 31.4s\tremaining: 3.41s\n",
      "902:\tlearn: 0.1743990\ttotal: 31.4s\tremaining: 3.37s\n",
      "903:\tlearn: 0.1742224\ttotal: 31.4s\tremaining: 3.34s\n",
      "904:\tlearn: 0.1741086\ttotal: 31.5s\tremaining: 3.3s\n",
      "905:\tlearn: 0.1740730\ttotal: 31.5s\tremaining: 3.27s\n",
      "906:\tlearn: 0.1739982\ttotal: 31.5s\tremaining: 3.23s\n",
      "907:\tlearn: 0.1739516\ttotal: 31.6s\tremaining: 3.2s\n",
      "908:\tlearn: 0.1738979\ttotal: 31.6s\tremaining: 3.17s\n",
      "909:\tlearn: 0.1738706\ttotal: 31.7s\tremaining: 3.13s\n",
      "910:\tlearn: 0.1737919\ttotal: 31.7s\tremaining: 3.1s\n",
      "911:\tlearn: 0.1736087\ttotal: 31.7s\tremaining: 3.06s\n",
      "912:\tlearn: 0.1735549\ttotal: 31.8s\tremaining: 3.03s\n",
      "913:\tlearn: 0.1734691\ttotal: 31.8s\tremaining: 2.99s\n",
      "914:\tlearn: 0.1733272\ttotal: 31.8s\tremaining: 2.96s\n",
      "915:\tlearn: 0.1731910\ttotal: 31.9s\tremaining: 2.92s\n",
      "916:\tlearn: 0.1730933\ttotal: 31.9s\tremaining: 2.89s\n",
      "917:\tlearn: 0.1729643\ttotal: 31.9s\tremaining: 2.85s\n",
      "918:\tlearn: 0.1728829\ttotal: 32s\tremaining: 2.82s\n",
      "919:\tlearn: 0.1728487\ttotal: 32s\tremaining: 2.78s\n",
      "920:\tlearn: 0.1726605\ttotal: 32s\tremaining: 2.75s\n",
      "921:\tlearn: 0.1725719\ttotal: 32.1s\tremaining: 2.71s\n",
      "922:\tlearn: 0.1724740\ttotal: 32.1s\tremaining: 2.68s\n",
      "923:\tlearn: 0.1724124\ttotal: 32.1s\tremaining: 2.64s\n",
      "924:\tlearn: 0.1722435\ttotal: 32.2s\tremaining: 2.61s\n",
      "925:\tlearn: 0.1721985\ttotal: 32.2s\tremaining: 2.57s\n",
      "926:\tlearn: 0.1720072\ttotal: 32.3s\tremaining: 2.54s\n",
      "927:\tlearn: 0.1719017\ttotal: 32.3s\tremaining: 2.5s\n",
      "928:\tlearn: 0.1717882\ttotal: 32.3s\tremaining: 2.47s\n",
      "929:\tlearn: 0.1717468\ttotal: 32.4s\tremaining: 2.44s\n",
      "930:\tlearn: 0.1716696\ttotal: 32.4s\tremaining: 2.4s\n",
      "931:\tlearn: 0.1716185\ttotal: 32.4s\tremaining: 2.37s\n",
      "932:\tlearn: 0.1715049\ttotal: 32.4s\tremaining: 2.33s\n",
      "933:\tlearn: 0.1713975\ttotal: 32.5s\tremaining: 2.29s\n",
      "934:\tlearn: 0.1713038\ttotal: 32.5s\tremaining: 2.26s\n",
      "935:\tlearn: 0.1712406\ttotal: 32.6s\tremaining: 2.23s\n",
      "936:\tlearn: 0.1711161\ttotal: 32.6s\tremaining: 2.19s\n",
      "937:\tlearn: 0.1709958\ttotal: 32.6s\tremaining: 2.16s\n",
      "938:\tlearn: 0.1709012\ttotal: 32.7s\tremaining: 2.12s\n",
      "939:\tlearn: 0.1707609\ttotal: 32.7s\tremaining: 2.09s\n",
      "940:\tlearn: 0.1707044\ttotal: 32.7s\tremaining: 2.05s\n",
      "941:\tlearn: 0.1705946\ttotal: 32.8s\tremaining: 2.02s\n",
      "942:\tlearn: 0.1705518\ttotal: 32.8s\tremaining: 1.98s\n",
      "943:\tlearn: 0.1704930\ttotal: 32.9s\tremaining: 1.95s\n",
      "944:\tlearn: 0.1704181\ttotal: 32.9s\tremaining: 1.91s\n",
      "945:\tlearn: 0.1703017\ttotal: 32.9s\tremaining: 1.88s\n",
      "946:\tlearn: 0.1701808\ttotal: 33s\tremaining: 1.84s\n",
      "947:\tlearn: 0.1701087\ttotal: 33s\tremaining: 1.81s\n",
      "948:\tlearn: 0.1700251\ttotal: 33s\tremaining: 1.78s\n",
      "949:\tlearn: 0.1699239\ttotal: 33.1s\tremaining: 1.74s\n",
      "950:\tlearn: 0.1698458\ttotal: 33.1s\tremaining: 1.71s\n",
      "951:\tlearn: 0.1697783\ttotal: 33.1s\tremaining: 1.67s\n",
      "952:\tlearn: 0.1696384\ttotal: 33.2s\tremaining: 1.64s\n",
      "953:\tlearn: 0.1694841\ttotal: 33.2s\tremaining: 1.6s\n",
      "954:\tlearn: 0.1694037\ttotal: 33.3s\tremaining: 1.57s\n",
      "955:\tlearn: 0.1693097\ttotal: 33.3s\tremaining: 1.53s\n",
      "956:\tlearn: 0.1692405\ttotal: 33.3s\tremaining: 1.5s\n",
      "957:\tlearn: 0.1691645\ttotal: 33.4s\tremaining: 1.46s\n",
      "958:\tlearn: 0.1690429\ttotal: 33.4s\tremaining: 1.43s\n",
      "959:\tlearn: 0.1689458\ttotal: 33.4s\tremaining: 1.39s\n",
      "960:\tlearn: 0.1687781\ttotal: 33.5s\tremaining: 1.36s\n",
      "961:\tlearn: 0.1686908\ttotal: 33.5s\tremaining: 1.32s\n",
      "962:\tlearn: 0.1685713\ttotal: 33.6s\tremaining: 1.29s\n",
      "963:\tlearn: 0.1684896\ttotal: 33.6s\tremaining: 1.25s\n",
      "964:\tlearn: 0.1683387\ttotal: 33.6s\tremaining: 1.22s\n",
      "965:\tlearn: 0.1682414\ttotal: 33.7s\tremaining: 1.18s\n",
      "966:\tlearn: 0.1681647\ttotal: 33.7s\tremaining: 1.15s\n",
      "967:\tlearn: 0.1681046\ttotal: 33.7s\tremaining: 1.11s\n",
      "968:\tlearn: 0.1680266\ttotal: 33.8s\tremaining: 1.08s\n",
      "969:\tlearn: 0.1679347\ttotal: 33.8s\tremaining: 1.05s\n",
      "970:\tlearn: 0.1679007\ttotal: 33.9s\tremaining: 1.01s\n",
      "971:\tlearn: 0.1678330\ttotal: 33.9s\tremaining: 977ms\n",
      "972:\tlearn: 0.1677443\ttotal: 33.9s\tremaining: 942ms\n",
      "973:\tlearn: 0.1676671\ttotal: 34s\tremaining: 907ms\n",
      "974:\tlearn: 0.1675797\ttotal: 34s\tremaining: 872ms\n",
      "975:\tlearn: 0.1675355\ttotal: 34.1s\tremaining: 838ms\n",
      "976:\tlearn: 0.1674105\ttotal: 34.1s\tremaining: 803ms\n",
      "977:\tlearn: 0.1673618\ttotal: 34.1s\tremaining: 768ms\n",
      "978:\tlearn: 0.1671747\ttotal: 34.2s\tremaining: 733ms\n",
      "979:\tlearn: 0.1670221\ttotal: 34.2s\tremaining: 698ms\n",
      "980:\tlearn: 0.1668825\ttotal: 34.2s\tremaining: 663ms\n",
      "981:\tlearn: 0.1668277\ttotal: 34.3s\tremaining: 629ms\n",
      "982:\tlearn: 0.1667591\ttotal: 34.3s\tremaining: 594ms\n",
      "983:\tlearn: 0.1666875\ttotal: 34.4s\tremaining: 559ms\n",
      "984:\tlearn: 0.1666385\ttotal: 34.4s\tremaining: 524ms\n",
      "985:\tlearn: 0.1665720\ttotal: 34.4s\tremaining: 489ms\n",
      "986:\tlearn: 0.1664234\ttotal: 34.5s\tremaining: 454ms\n",
      "987:\tlearn: 0.1663483\ttotal: 34.5s\tremaining: 419ms\n",
      "988:\tlearn: 0.1662342\ttotal: 34.5s\tremaining: 384ms\n",
      "989:\tlearn: 0.1661928\ttotal: 34.6s\tremaining: 349ms\n",
      "990:\tlearn: 0.1660952\ttotal: 34.6s\tremaining: 314ms\n",
      "991:\tlearn: 0.1660204\ttotal: 34.6s\tremaining: 279ms\n",
      "992:\tlearn: 0.1659499\ttotal: 34.7s\tremaining: 244ms\n",
      "993:\tlearn: 0.1658407\ttotal: 34.7s\tremaining: 209ms\n",
      "994:\tlearn: 0.1657557\ttotal: 34.7s\tremaining: 174ms\n",
      "995:\tlearn: 0.1656919\ttotal: 34.8s\tremaining: 140ms\n",
      "996:\tlearn: 0.1656007\ttotal: 34.8s\tremaining: 105ms\n",
      "997:\tlearn: 0.1655390\ttotal: 34.8s\tremaining: 69.8ms\n",
      "998:\tlearn: 0.1654388\ttotal: 34.9s\tremaining: 34.9ms\n",
      "999:\tlearn: 0.1653293\ttotal: 34.9s\tremaining: 0us\n",
      "Learning rate set to 0.091926\n",
      "0:\tlearn: 1.8367304\ttotal: 39.6ms\tremaining: 39.6s\n",
      "1:\tlearn: 1.6347392\ttotal: 75.4ms\tremaining: 37.6s\n",
      "2:\tlearn: 1.4822107\ttotal: 111ms\tremaining: 36.9s\n",
      "3:\tlearn: 1.3676734\ttotal: 145ms\tremaining: 36.2s\n",
      "4:\tlearn: 1.2736777\ttotal: 178ms\tremaining: 35.4s\n",
      "5:\tlearn: 1.1998806\ttotal: 210ms\tremaining: 34.8s\n",
      "6:\tlearn: 1.1432298\ttotal: 248ms\tremaining: 35.1s\n",
      "7:\tlearn: 1.0935283\ttotal: 284ms\tremaining: 35.3s\n",
      "8:\tlearn: 1.0400274\ttotal: 321ms\tremaining: 35.4s\n",
      "9:\tlearn: 1.0004632\ttotal: 357ms\tremaining: 35.4s\n",
      "10:\tlearn: 0.9566447\ttotal: 391ms\tremaining: 35.2s\n",
      "11:\tlearn: 0.9230431\ttotal: 423ms\tremaining: 34.9s\n",
      "12:\tlearn: 0.8977073\ttotal: 461ms\tremaining: 35s\n",
      "13:\tlearn: 0.8679190\ttotal: 502ms\tremaining: 35.4s\n",
      "14:\tlearn: 0.8434134\ttotal: 546ms\tremaining: 35.9s\n",
      "15:\tlearn: 0.8182978\ttotal: 585ms\tremaining: 36s\n",
      "16:\tlearn: 0.7964651\ttotal: 624ms\tremaining: 36.1s\n",
      "17:\tlearn: 0.7750422\ttotal: 661ms\tremaining: 36s\n",
      "18:\tlearn: 0.7523547\ttotal: 696ms\tremaining: 35.9s\n",
      "19:\tlearn: 0.7335945\ttotal: 729ms\tremaining: 35.7s\n",
      "20:\tlearn: 0.7214943\ttotal: 764ms\tremaining: 35.6s\n",
      "21:\tlearn: 0.7071111\ttotal: 812ms\tremaining: 36.1s\n",
      "22:\tlearn: 0.6912393\ttotal: 854ms\tremaining: 36.3s\n",
      "23:\tlearn: 0.6814489\ttotal: 889ms\tremaining: 36.2s\n",
      "24:\tlearn: 0.6679168\ttotal: 928ms\tremaining: 36.2s\n",
      "25:\tlearn: 0.6564181\ttotal: 962ms\tremaining: 36s\n",
      "26:\tlearn: 0.6444280\ttotal: 996ms\tremaining: 35.9s\n",
      "27:\tlearn: 0.6361730\ttotal: 1.03s\tremaining: 35.7s\n",
      "28:\tlearn: 0.6251143\ttotal: 1.08s\tremaining: 36.1s\n",
      "29:\tlearn: 0.6128355\ttotal: 1.12s\tremaining: 36.3s\n",
      "30:\tlearn: 0.6057218\ttotal: 1.16s\tremaining: 36.2s\n",
      "31:\tlearn: 0.5993962\ttotal: 1.19s\tremaining: 36s\n",
      "32:\tlearn: 0.5886299\ttotal: 1.22s\tremaining: 35.8s\n",
      "33:\tlearn: 0.5804960\ttotal: 1.26s\tremaining: 35.8s\n",
      "34:\tlearn: 0.5752852\ttotal: 1.3s\tremaining: 35.9s\n",
      "35:\tlearn: 0.5681416\ttotal: 1.34s\tremaining: 35.9s\n",
      "36:\tlearn: 0.5616274\ttotal: 1.38s\tremaining: 36s\n",
      "37:\tlearn: 0.5548489\ttotal: 1.42s\tremaining: 35.9s\n",
      "38:\tlearn: 0.5484620\ttotal: 1.45s\tremaining: 35.8s\n",
      "39:\tlearn: 0.5432018\ttotal: 1.49s\tremaining: 35.7s\n",
      "40:\tlearn: 0.5380070\ttotal: 1.54s\tremaining: 36s\n",
      "41:\tlearn: 0.5328099\ttotal: 1.58s\tremaining: 36s\n",
      "42:\tlearn: 0.5300378\ttotal: 1.61s\tremaining: 35.9s\n",
      "43:\tlearn: 0.5264858\ttotal: 1.65s\tremaining: 35.8s\n",
      "44:\tlearn: 0.5218288\ttotal: 1.68s\tremaining: 35.7s\n",
      "45:\tlearn: 0.5166658\ttotal: 1.72s\tremaining: 35.7s\n",
      "46:\tlearn: 0.5121222\ttotal: 1.77s\tremaining: 36s\n",
      "47:\tlearn: 0.5082860\ttotal: 1.81s\tremaining: 35.9s\n",
      "48:\tlearn: 0.5044710\ttotal: 1.85s\tremaining: 35.9s\n",
      "49:\tlearn: 0.4988666\ttotal: 1.88s\tremaining: 35.8s\n",
      "50:\tlearn: 0.4952287\ttotal: 1.91s\tremaining: 35.6s\n",
      "51:\tlearn: 0.4921774\ttotal: 1.95s\tremaining: 35.5s\n",
      "52:\tlearn: 0.4868179\ttotal: 2s\tremaining: 35.7s\n",
      "53:\tlearn: 0.4844406\ttotal: 2.04s\tremaining: 35.7s\n",
      "54:\tlearn: 0.4818794\ttotal: 2.07s\tremaining: 35.6s\n",
      "55:\tlearn: 0.4780458\ttotal: 2.12s\tremaining: 35.7s\n",
      "56:\tlearn: 0.4757536\ttotal: 2.15s\tremaining: 35.6s\n",
      "57:\tlearn: 0.4737262\ttotal: 2.19s\tremaining: 35.5s\n",
      "58:\tlearn: 0.4716658\ttotal: 2.23s\tremaining: 35.5s\n",
      "59:\tlearn: 0.4701650\ttotal: 2.27s\tremaining: 35.5s\n",
      "60:\tlearn: 0.4668481\ttotal: 2.31s\tremaining: 35.5s\n",
      "61:\tlearn: 0.4642986\ttotal: 2.34s\tremaining: 35.4s\n",
      "62:\tlearn: 0.4610697\ttotal: 2.38s\tremaining: 35.3s\n",
      "63:\tlearn: 0.4590132\ttotal: 2.41s\tremaining: 35.2s\n",
      "64:\tlearn: 0.4572018\ttotal: 2.44s\tremaining: 35.2s\n",
      "65:\tlearn: 0.4557102\ttotal: 2.48s\tremaining: 35s\n",
      "66:\tlearn: 0.4528141\ttotal: 2.51s\tremaining: 35s\n",
      "67:\tlearn: 0.4501692\ttotal: 2.54s\tremaining: 34.8s\n",
      "68:\tlearn: 0.4480043\ttotal: 2.58s\tremaining: 34.8s\n",
      "69:\tlearn: 0.4455194\ttotal: 2.61s\tremaining: 34.7s\n",
      "70:\tlearn: 0.4438874\ttotal: 2.64s\tremaining: 34.5s\n",
      "71:\tlearn: 0.4422311\ttotal: 2.67s\tremaining: 34.4s\n",
      "72:\tlearn: 0.4394728\ttotal: 2.7s\tremaining: 34.3s\n",
      "73:\tlearn: 0.4373470\ttotal: 2.73s\tremaining: 34.1s\n",
      "74:\tlearn: 0.4347180\ttotal: 2.76s\tremaining: 34.1s\n",
      "75:\tlearn: 0.4330199\ttotal: 2.81s\tremaining: 34.1s\n",
      "76:\tlearn: 0.4299825\ttotal: 2.85s\tremaining: 34.1s\n",
      "77:\tlearn: 0.4282573\ttotal: 2.88s\tremaining: 34.1s\n",
      "78:\tlearn: 0.4262008\ttotal: 2.92s\tremaining: 34s\n",
      "79:\tlearn: 0.4246228\ttotal: 2.96s\tremaining: 34s\n",
      "80:\tlearn: 0.4232229\ttotal: 3s\tremaining: 34s\n",
      "81:\tlearn: 0.4220117\ttotal: 3.03s\tremaining: 33.9s\n",
      "82:\tlearn: 0.4196979\ttotal: 3.07s\tremaining: 33.9s\n",
      "83:\tlearn: 0.4182657\ttotal: 3.1s\tremaining: 33.8s\n",
      "84:\tlearn: 0.4174432\ttotal: 3.15s\tremaining: 33.9s\n",
      "85:\tlearn: 0.4166552\ttotal: 3.19s\tremaining: 33.9s\n",
      "86:\tlearn: 0.4156161\ttotal: 3.22s\tremaining: 33.8s\n",
      "87:\tlearn: 0.4144667\ttotal: 3.26s\tremaining: 33.8s\n",
      "88:\tlearn: 0.4129199\ttotal: 3.3s\tremaining: 33.8s\n",
      "89:\tlearn: 0.4123195\ttotal: 3.33s\tremaining: 33.6s\n",
      "90:\tlearn: 0.4100285\ttotal: 3.36s\tremaining: 33.6s\n",
      "91:\tlearn: 0.4091470\ttotal: 3.4s\tremaining: 33.6s\n",
      "92:\tlearn: 0.4084004\ttotal: 3.45s\tremaining: 33.6s\n",
      "93:\tlearn: 0.4061002\ttotal: 3.49s\tremaining: 33.6s\n",
      "94:\tlearn: 0.4045269\ttotal: 3.53s\tremaining: 33.6s\n",
      "95:\tlearn: 0.4026876\ttotal: 3.56s\tremaining: 33.5s\n",
      "96:\tlearn: 0.4015717\ttotal: 3.6s\tremaining: 33.5s\n",
      "97:\tlearn: 0.4002445\ttotal: 3.64s\tremaining: 33.5s\n",
      "98:\tlearn: 0.3984625\ttotal: 3.68s\tremaining: 33.5s\n",
      "99:\tlearn: 0.3963099\ttotal: 3.71s\tremaining: 33.4s\n",
      "100:\tlearn: 0.3954451\ttotal: 3.75s\tremaining: 33.4s\n",
      "101:\tlearn: 0.3941864\ttotal: 3.78s\tremaining: 33.3s\n",
      "102:\tlearn: 0.3931752\ttotal: 3.82s\tremaining: 33.3s\n",
      "103:\tlearn: 0.3922608\ttotal: 3.85s\tremaining: 33.2s\n",
      "104:\tlearn: 0.3911019\ttotal: 3.89s\tremaining: 33.1s\n",
      "105:\tlearn: 0.3901611\ttotal: 3.92s\tremaining: 33s\n",
      "106:\tlearn: 0.3884828\ttotal: 3.95s\tremaining: 33s\n",
      "107:\tlearn: 0.3877123\ttotal: 3.98s\tremaining: 32.9s\n",
      "108:\tlearn: 0.3867814\ttotal: 4.03s\tremaining: 32.9s\n",
      "109:\tlearn: 0.3861664\ttotal: 4.07s\tremaining: 32.9s\n",
      "110:\tlearn: 0.3855816\ttotal: 4.1s\tremaining: 32.8s\n",
      "111:\tlearn: 0.3842596\ttotal: 4.14s\tremaining: 32.8s\n",
      "112:\tlearn: 0.3832486\ttotal: 4.18s\tremaining: 32.8s\n",
      "113:\tlearn: 0.3822309\ttotal: 4.21s\tremaining: 32.7s\n",
      "114:\tlearn: 0.3810761\ttotal: 4.25s\tremaining: 32.7s\n",
      "115:\tlearn: 0.3800476\ttotal: 4.29s\tremaining: 32.7s\n",
      "116:\tlearn: 0.3785803\ttotal: 4.33s\tremaining: 32.7s\n",
      "117:\tlearn: 0.3781069\ttotal: 4.37s\tremaining: 32.7s\n",
      "118:\tlearn: 0.3775939\ttotal: 4.41s\tremaining: 32.6s\n",
      "119:\tlearn: 0.3768035\ttotal: 4.44s\tremaining: 32.6s\n",
      "120:\tlearn: 0.3760409\ttotal: 4.48s\tremaining: 32.5s\n",
      "121:\tlearn: 0.3750530\ttotal: 4.51s\tremaining: 32.5s\n",
      "122:\tlearn: 0.3744159\ttotal: 4.54s\tremaining: 32.4s\n",
      "123:\tlearn: 0.3739766\ttotal: 4.58s\tremaining: 32.3s\n",
      "124:\tlearn: 0.3735912\ttotal: 4.61s\tremaining: 32.3s\n",
      "125:\tlearn: 0.3729550\ttotal: 4.65s\tremaining: 32.3s\n",
      "126:\tlearn: 0.3716473\ttotal: 4.7s\tremaining: 32.3s\n",
      "127:\tlearn: 0.3713291\ttotal: 4.74s\tremaining: 32.3s\n",
      "128:\tlearn: 0.3706674\ttotal: 4.77s\tremaining: 32.2s\n",
      "129:\tlearn: 0.3700074\ttotal: 4.81s\tremaining: 32.2s\n",
      "130:\tlearn: 0.3693222\ttotal: 4.84s\tremaining: 32.1s\n",
      "131:\tlearn: 0.3689594\ttotal: 4.87s\tremaining: 32s\n",
      "132:\tlearn: 0.3683063\ttotal: 4.91s\tremaining: 32s\n",
      "133:\tlearn: 0.3671195\ttotal: 4.95s\tremaining: 32s\n",
      "134:\tlearn: 0.3663388\ttotal: 4.99s\tremaining: 32s\n",
      "135:\tlearn: 0.3647917\ttotal: 5.02s\tremaining: 31.9s\n",
      "136:\tlearn: 0.3643293\ttotal: 5.05s\tremaining: 31.8s\n",
      "137:\tlearn: 0.3630194\ttotal: 5.08s\tremaining: 31.8s\n",
      "138:\tlearn: 0.3622584\ttotal: 5.12s\tremaining: 31.7s\n",
      "139:\tlearn: 0.3621350\ttotal: 5.15s\tremaining: 31.7s\n",
      "140:\tlearn: 0.3611783\ttotal: 5.19s\tremaining: 31.6s\n",
      "141:\tlearn: 0.3609104\ttotal: 5.22s\tremaining: 31.5s\n",
      "142:\tlearn: 0.3605576\ttotal: 5.25s\tremaining: 31.5s\n",
      "143:\tlearn: 0.3602488\ttotal: 5.29s\tremaining: 31.4s\n",
      "144:\tlearn: 0.3595337\ttotal: 5.33s\tremaining: 31.4s\n",
      "145:\tlearn: 0.3592854\ttotal: 5.37s\tremaining: 31.4s\n",
      "146:\tlearn: 0.3588579\ttotal: 5.4s\tremaining: 31.3s\n",
      "147:\tlearn: 0.3586180\ttotal: 5.43s\tremaining: 31.3s\n",
      "148:\tlearn: 0.3576831\ttotal: 5.47s\tremaining: 31.2s\n",
      "149:\tlearn: 0.3568090\ttotal: 5.5s\tremaining: 31.2s\n",
      "150:\tlearn: 0.3561924\ttotal: 5.53s\tremaining: 31.1s\n",
      "151:\tlearn: 0.3556032\ttotal: 5.57s\tremaining: 31s\n",
      "152:\tlearn: 0.3553915\ttotal: 5.6s\tremaining: 31s\n",
      "153:\tlearn: 0.3551517\ttotal: 5.64s\tremaining: 31s\n",
      "154:\tlearn: 0.3543688\ttotal: 5.69s\tremaining: 31s\n",
      "155:\tlearn: 0.3538793\ttotal: 5.72s\tremaining: 31s\n",
      "156:\tlearn: 0.3530926\ttotal: 5.75s\tremaining: 30.9s\n",
      "157:\tlearn: 0.3527314\ttotal: 5.79s\tremaining: 30.9s\n",
      "158:\tlearn: 0.3520505\ttotal: 5.82s\tremaining: 30.8s\n",
      "159:\tlearn: 0.3515876\ttotal: 5.86s\tremaining: 30.8s\n",
      "160:\tlearn: 0.3512502\ttotal: 5.89s\tremaining: 30.7s\n",
      "161:\tlearn: 0.3510891\ttotal: 5.92s\tremaining: 30.6s\n",
      "162:\tlearn: 0.3504651\ttotal: 5.96s\tremaining: 30.6s\n",
      "163:\tlearn: 0.3493143\ttotal: 6.01s\tremaining: 30.6s\n",
      "164:\tlearn: 0.3489170\ttotal: 6.04s\tremaining: 30.6s\n",
      "165:\tlearn: 0.3487208\ttotal: 6.07s\tremaining: 30.5s\n",
      "166:\tlearn: 0.3484032\ttotal: 6.11s\tremaining: 30.5s\n",
      "167:\tlearn: 0.3473631\ttotal: 6.15s\tremaining: 30.4s\n",
      "168:\tlearn: 0.3470144\ttotal: 6.18s\tremaining: 30.4s\n",
      "169:\tlearn: 0.3466361\ttotal: 6.21s\tremaining: 30.3s\n",
      "170:\tlearn: 0.3460841\ttotal: 6.25s\tremaining: 30.3s\n",
      "171:\tlearn: 0.3454023\ttotal: 6.29s\tremaining: 30.3s\n",
      "172:\tlearn: 0.3447143\ttotal: 6.33s\tremaining: 30.2s\n",
      "173:\tlearn: 0.3440902\ttotal: 6.37s\tremaining: 30.2s\n",
      "174:\tlearn: 0.3435286\ttotal: 6.4s\tremaining: 30.2s\n",
      "175:\tlearn: 0.3430134\ttotal: 6.43s\tremaining: 30.1s\n",
      "176:\tlearn: 0.3428318\ttotal: 6.47s\tremaining: 30.1s\n",
      "177:\tlearn: 0.3424163\ttotal: 6.52s\tremaining: 30.1s\n",
      "178:\tlearn: 0.3417091\ttotal: 6.56s\tremaining: 30.1s\n",
      "179:\tlearn: 0.3413069\ttotal: 6.59s\tremaining: 30s\n",
      "180:\tlearn: 0.3411160\ttotal: 6.62s\tremaining: 29.9s\n",
      "181:\tlearn: 0.3402319\ttotal: 6.65s\tremaining: 29.9s\n",
      "182:\tlearn: 0.3391674\ttotal: 6.69s\tremaining: 29.9s\n",
      "183:\tlearn: 0.3384143\ttotal: 6.72s\tremaining: 29.8s\n",
      "184:\tlearn: 0.3381301\ttotal: 6.75s\tremaining: 29.7s\n",
      "185:\tlearn: 0.3369778\ttotal: 6.79s\tremaining: 29.7s\n",
      "186:\tlearn: 0.3361158\ttotal: 6.83s\tremaining: 29.7s\n",
      "187:\tlearn: 0.3355147\ttotal: 6.86s\tremaining: 29.6s\n",
      "188:\tlearn: 0.3352132\ttotal: 6.9s\tremaining: 29.6s\n",
      "189:\tlearn: 0.3343356\ttotal: 6.95s\tremaining: 29.6s\n",
      "190:\tlearn: 0.3340531\ttotal: 6.98s\tremaining: 29.6s\n",
      "191:\tlearn: 0.3333818\ttotal: 7.02s\tremaining: 29.6s\n",
      "192:\tlearn: 0.3332138\ttotal: 7.05s\tremaining: 29.5s\n",
      "193:\tlearn: 0.3327463\ttotal: 7.08s\tremaining: 29.4s\n",
      "194:\tlearn: 0.3324330\ttotal: 7.12s\tremaining: 29.4s\n",
      "195:\tlearn: 0.3321952\ttotal: 7.16s\tremaining: 29.4s\n",
      "196:\tlearn: 0.3319107\ttotal: 7.21s\tremaining: 29.4s\n",
      "197:\tlearn: 0.3313824\ttotal: 7.24s\tremaining: 29.3s\n",
      "198:\tlearn: 0.3309284\ttotal: 7.28s\tremaining: 29.3s\n",
      "199:\tlearn: 0.3303222\ttotal: 7.31s\tremaining: 29.2s\n",
      "200:\tlearn: 0.3297141\ttotal: 7.34s\tremaining: 29.2s\n",
      "201:\tlearn: 0.3292805\ttotal: 7.38s\tremaining: 29.2s\n",
      "202:\tlearn: 0.3284416\ttotal: 7.43s\tremaining: 29.2s\n",
      "203:\tlearn: 0.3280624\ttotal: 7.47s\tremaining: 29.2s\n",
      "204:\tlearn: 0.3278984\ttotal: 7.5s\tremaining: 29.1s\n",
      "205:\tlearn: 0.3271826\ttotal: 7.54s\tremaining: 29.1s\n",
      "206:\tlearn: 0.3266185\ttotal: 7.57s\tremaining: 29s\n",
      "207:\tlearn: 0.3262392\ttotal: 7.61s\tremaining: 29s\n",
      "208:\tlearn: 0.3260037\ttotal: 7.65s\tremaining: 29s\n",
      "209:\tlearn: 0.3257138\ttotal: 7.69s\tremaining: 28.9s\n",
      "210:\tlearn: 0.3251361\ttotal: 7.73s\tremaining: 28.9s\n",
      "211:\tlearn: 0.3249561\ttotal: 7.76s\tremaining: 28.9s\n",
      "212:\tlearn: 0.3247146\ttotal: 7.79s\tremaining: 28.8s\n",
      "213:\tlearn: 0.3241653\ttotal: 7.82s\tremaining: 28.7s\n",
      "214:\tlearn: 0.3240915\ttotal: 7.86s\tremaining: 28.7s\n",
      "215:\tlearn: 0.3236950\ttotal: 7.9s\tremaining: 28.7s\n",
      "216:\tlearn: 0.3230206\ttotal: 7.95s\tremaining: 28.7s\n",
      "217:\tlearn: 0.3227826\ttotal: 7.98s\tremaining: 28.6s\n",
      "218:\tlearn: 0.3224530\ttotal: 8.01s\tremaining: 28.6s\n",
      "219:\tlearn: 0.3222247\ttotal: 8.04s\tremaining: 28.5s\n",
      "220:\tlearn: 0.3216978\ttotal: 8.08s\tremaining: 28.5s\n",
      "221:\tlearn: 0.3215550\ttotal: 8.11s\tremaining: 28.4s\n",
      "222:\tlearn: 0.3207495\ttotal: 8.15s\tremaining: 28.4s\n",
      "223:\tlearn: 0.3203677\ttotal: 8.18s\tremaining: 28.3s\n",
      "224:\tlearn: 0.3201102\ttotal: 8.23s\tremaining: 28.3s\n",
      "225:\tlearn: 0.3195694\ttotal: 8.27s\tremaining: 28.3s\n",
      "226:\tlearn: 0.3193250\ttotal: 8.31s\tremaining: 28.3s\n",
      "227:\tlearn: 0.3184917\ttotal: 8.35s\tremaining: 28.3s\n",
      "228:\tlearn: 0.3184341\ttotal: 8.38s\tremaining: 28.2s\n",
      "229:\tlearn: 0.3180495\ttotal: 8.41s\tremaining: 28.2s\n",
      "230:\tlearn: 0.3176343\ttotal: 8.45s\tremaining: 28.1s\n",
      "231:\tlearn: 0.3173477\ttotal: 8.48s\tremaining: 28.1s\n",
      "232:\tlearn: 0.3171380\ttotal: 8.51s\tremaining: 28s\n",
      "233:\tlearn: 0.3166916\ttotal: 8.55s\tremaining: 28s\n",
      "234:\tlearn: 0.3161718\ttotal: 8.6s\tremaining: 28s\n",
      "235:\tlearn: 0.3159527\ttotal: 8.63s\tremaining: 27.9s\n",
      "236:\tlearn: 0.3156783\ttotal: 8.66s\tremaining: 27.9s\n",
      "237:\tlearn: 0.3151033\ttotal: 8.7s\tremaining: 27.9s\n",
      "238:\tlearn: 0.3144637\ttotal: 8.74s\tremaining: 27.8s\n",
      "239:\tlearn: 0.3141780\ttotal: 8.77s\tremaining: 27.8s\n",
      "240:\tlearn: 0.3139869\ttotal: 8.8s\tremaining: 27.7s\n",
      "241:\tlearn: 0.3135826\ttotal: 8.84s\tremaining: 27.7s\n",
      "242:\tlearn: 0.3133072\ttotal: 8.87s\tremaining: 27.6s\n",
      "243:\tlearn: 0.3129419\ttotal: 8.91s\tremaining: 27.6s\n",
      "244:\tlearn: 0.3124462\ttotal: 8.95s\tremaining: 27.6s\n",
      "245:\tlearn: 0.3121514\ttotal: 8.99s\tremaining: 27.6s\n",
      "246:\tlearn: 0.3117951\ttotal: 9.03s\tremaining: 27.5s\n",
      "247:\tlearn: 0.3114983\ttotal: 9.06s\tremaining: 27.5s\n",
      "248:\tlearn: 0.3106230\ttotal: 9.1s\tremaining: 27.4s\n",
      "249:\tlearn: 0.3103485\ttotal: 9.13s\tremaining: 27.4s\n",
      "250:\tlearn: 0.3098981\ttotal: 9.18s\tremaining: 27.4s\n",
      "251:\tlearn: 0.3094568\ttotal: 9.23s\tremaining: 27.4s\n",
      "252:\tlearn: 0.3091905\ttotal: 9.26s\tremaining: 27.3s\n",
      "253:\tlearn: 0.3088351\ttotal: 9.29s\tremaining: 27.3s\n",
      "254:\tlearn: 0.3086374\ttotal: 9.32s\tremaining: 27.2s\n",
      "255:\tlearn: 0.3079486\ttotal: 9.36s\tremaining: 27.2s\n",
      "256:\tlearn: 0.3074152\ttotal: 9.41s\tremaining: 27.2s\n",
      "257:\tlearn: 0.3071707\ttotal: 9.45s\tremaining: 27.2s\n",
      "258:\tlearn: 0.3069390\ttotal: 9.49s\tremaining: 27.1s\n",
      "259:\tlearn: 0.3068219\ttotal: 9.52s\tremaining: 27.1s\n",
      "260:\tlearn: 0.3063753\ttotal: 9.56s\tremaining: 27.1s\n",
      "261:\tlearn: 0.3059831\ttotal: 9.59s\tremaining: 27s\n",
      "262:\tlearn: 0.3058564\ttotal: 9.62s\tremaining: 27s\n",
      "263:\tlearn: 0.3056710\ttotal: 9.67s\tremaining: 27s\n",
      "264:\tlearn: 0.3052980\ttotal: 9.71s\tremaining: 26.9s\n",
      "265:\tlearn: 0.3050475\ttotal: 9.75s\tremaining: 26.9s\n",
      "266:\tlearn: 0.3048668\ttotal: 9.78s\tremaining: 26.9s\n",
      "267:\tlearn: 0.3045560\ttotal: 9.81s\tremaining: 26.8s\n",
      "268:\tlearn: 0.3039883\ttotal: 9.85s\tremaining: 26.8s\n",
      "269:\tlearn: 0.3037181\ttotal: 9.9s\tremaining: 26.8s\n",
      "270:\tlearn: 0.3032667\ttotal: 9.93s\tremaining: 26.7s\n",
      "271:\tlearn: 0.3026804\ttotal: 9.97s\tremaining: 26.7s\n",
      "272:\tlearn: 0.3024509\ttotal: 10s\tremaining: 26.6s\n",
      "273:\tlearn: 0.3021255\ttotal: 10s\tremaining: 26.6s\n",
      "274:\tlearn: 0.3015154\ttotal: 10.1s\tremaining: 26.6s\n",
      "275:\tlearn: 0.3011867\ttotal: 10.1s\tremaining: 26.5s\n",
      "276:\tlearn: 0.3009075\ttotal: 10.1s\tremaining: 26.5s\n",
      "277:\tlearn: 0.3001616\ttotal: 10.2s\tremaining: 26.4s\n",
      "278:\tlearn: 0.2999862\ttotal: 10.2s\tremaining: 26.4s\n",
      "279:\tlearn: 0.2997935\ttotal: 10.2s\tremaining: 26.3s\n",
      "280:\tlearn: 0.2993946\ttotal: 10.3s\tremaining: 26.3s\n",
      "281:\tlearn: 0.2992093\ttotal: 10.3s\tremaining: 26.3s\n",
      "282:\tlearn: 0.2988957\ttotal: 10.4s\tremaining: 26.2s\n",
      "283:\tlearn: 0.2987555\ttotal: 10.4s\tremaining: 26.2s\n",
      "284:\tlearn: 0.2982349\ttotal: 10.4s\tremaining: 26.2s\n",
      "285:\tlearn: 0.2980936\ttotal: 10.5s\tremaining: 26.1s\n",
      "286:\tlearn: 0.2974468\ttotal: 10.5s\tremaining: 26.1s\n",
      "287:\tlearn: 0.2969558\ttotal: 10.5s\tremaining: 26s\n",
      "288:\tlearn: 0.2967610\ttotal: 10.6s\tremaining: 26s\n",
      "289:\tlearn: 0.2963186\ttotal: 10.6s\tremaining: 26s\n",
      "290:\tlearn: 0.2960147\ttotal: 10.7s\tremaining: 25.9s\n",
      "291:\tlearn: 0.2957943\ttotal: 10.7s\tremaining: 25.9s\n",
      "292:\tlearn: 0.2952234\ttotal: 10.7s\tremaining: 25.9s\n",
      "293:\tlearn: 0.2947248\ttotal: 10.8s\tremaining: 25.8s\n",
      "294:\tlearn: 0.2945888\ttotal: 10.8s\tremaining: 25.8s\n",
      "295:\tlearn: 0.2944858\ttotal: 10.8s\tremaining: 25.7s\n",
      "296:\tlearn: 0.2943696\ttotal: 10.8s\tremaining: 25.7s\n",
      "297:\tlearn: 0.2941903\ttotal: 10.9s\tremaining: 25.6s\n",
      "298:\tlearn: 0.2939915\ttotal: 10.9s\tremaining: 25.6s\n",
      "299:\tlearn: 0.2937590\ttotal: 11s\tremaining: 25.6s\n",
      "300:\tlearn: 0.2933528\ttotal: 11s\tremaining: 25.5s\n",
      "301:\tlearn: 0.2928555\ttotal: 11s\tremaining: 25.5s\n",
      "302:\tlearn: 0.2927652\ttotal: 11.1s\tremaining: 25.5s\n",
      "303:\tlearn: 0.2925948\ttotal: 11.1s\tremaining: 25.4s\n",
      "304:\tlearn: 0.2923204\ttotal: 11.1s\tremaining: 25.4s\n",
      "305:\tlearn: 0.2920296\ttotal: 11.2s\tremaining: 25.4s\n",
      "306:\tlearn: 0.2918349\ttotal: 11.2s\tremaining: 25.3s\n",
      "307:\tlearn: 0.2914145\ttotal: 11.3s\tremaining: 25.3s\n",
      "308:\tlearn: 0.2909397\ttotal: 11.3s\tremaining: 25.3s\n",
      "309:\tlearn: 0.2907021\ttotal: 11.3s\tremaining: 25.2s\n",
      "310:\tlearn: 0.2903703\ttotal: 11.4s\tremaining: 25.2s\n",
      "311:\tlearn: 0.2900567\ttotal: 11.4s\tremaining: 25.1s\n",
      "312:\tlearn: 0.2898390\ttotal: 11.4s\tremaining: 25.1s\n",
      "313:\tlearn: 0.2894201\ttotal: 11.5s\tremaining: 25.1s\n",
      "314:\tlearn: 0.2891919\ttotal: 11.5s\tremaining: 25.1s\n",
      "315:\tlearn: 0.2885675\ttotal: 11.6s\tremaining: 25s\n",
      "316:\tlearn: 0.2883007\ttotal: 11.6s\tremaining: 25s\n",
      "317:\tlearn: 0.2878367\ttotal: 11.6s\tremaining: 24.9s\n",
      "318:\tlearn: 0.2875932\ttotal: 11.7s\tremaining: 24.9s\n",
      "319:\tlearn: 0.2872176\ttotal: 11.7s\tremaining: 24.9s\n",
      "320:\tlearn: 0.2870390\ttotal: 11.7s\tremaining: 24.8s\n",
      "321:\tlearn: 0.2865889\ttotal: 11.8s\tremaining: 24.8s\n",
      "322:\tlearn: 0.2864744\ttotal: 11.8s\tremaining: 24.7s\n",
      "323:\tlearn: 0.2862920\ttotal: 11.9s\tremaining: 24.7s\n",
      "324:\tlearn: 0.2860370\ttotal: 11.9s\tremaining: 24.7s\n",
      "325:\tlearn: 0.2859134\ttotal: 11.9s\tremaining: 24.7s\n",
      "326:\tlearn: 0.2854893\ttotal: 12s\tremaining: 24.6s\n",
      "327:\tlearn: 0.2853827\ttotal: 12s\tremaining: 24.6s\n",
      "328:\tlearn: 0.2851987\ttotal: 12s\tremaining: 24.5s\n",
      "329:\tlearn: 0.2847831\ttotal: 12.1s\tremaining: 24.5s\n",
      "330:\tlearn: 0.2845901\ttotal: 12.1s\tremaining: 24.5s\n",
      "331:\tlearn: 0.2844253\ttotal: 12.2s\tremaining: 24.5s\n",
      "332:\tlearn: 0.2841511\ttotal: 12.2s\tremaining: 24.4s\n",
      "333:\tlearn: 0.2839433\ttotal: 12.2s\tremaining: 24.4s\n",
      "334:\tlearn: 0.2835033\ttotal: 12.3s\tremaining: 24.3s\n",
      "335:\tlearn: 0.2832340\ttotal: 12.3s\tremaining: 24.3s\n",
      "336:\tlearn: 0.2831197\ttotal: 12.3s\tremaining: 24.3s\n",
      "337:\tlearn: 0.2824921\ttotal: 12.4s\tremaining: 24.3s\n",
      "338:\tlearn: 0.2822423\ttotal: 12.4s\tremaining: 24.2s\n",
      "339:\tlearn: 0.2820623\ttotal: 12.4s\tremaining: 24.2s\n",
      "340:\tlearn: 0.2817596\ttotal: 12.5s\tremaining: 24.1s\n",
      "341:\tlearn: 0.2813864\ttotal: 12.5s\tremaining: 24.1s\n",
      "342:\tlearn: 0.2811710\ttotal: 12.6s\tremaining: 24s\n",
      "343:\tlearn: 0.2810225\ttotal: 12.6s\tremaining: 24s\n",
      "344:\tlearn: 0.2807731\ttotal: 12.6s\tremaining: 23.9s\n",
      "345:\tlearn: 0.2804762\ttotal: 12.6s\tremaining: 23.9s\n",
      "346:\tlearn: 0.2802442\ttotal: 12.7s\tremaining: 23.9s\n",
      "347:\tlearn: 0.2800604\ttotal: 12.7s\tremaining: 23.8s\n",
      "348:\tlearn: 0.2798029\ttotal: 12.8s\tremaining: 23.8s\n",
      "349:\tlearn: 0.2795416\ttotal: 12.8s\tremaining: 23.8s\n",
      "350:\tlearn: 0.2793888\ttotal: 12.8s\tremaining: 23.7s\n",
      "351:\tlearn: 0.2790928\ttotal: 12.9s\tremaining: 23.7s\n",
      "352:\tlearn: 0.2789661\ttotal: 12.9s\tremaining: 23.7s\n",
      "353:\tlearn: 0.2786935\ttotal: 12.9s\tremaining: 23.6s\n",
      "354:\tlearn: 0.2784786\ttotal: 13s\tremaining: 23.6s\n",
      "355:\tlearn: 0.2780057\ttotal: 13s\tremaining: 23.5s\n",
      "356:\tlearn: 0.2774711\ttotal: 13.1s\tremaining: 23.5s\n",
      "357:\tlearn: 0.2770739\ttotal: 13.1s\tremaining: 23.5s\n",
      "358:\tlearn: 0.2769709\ttotal: 13.1s\tremaining: 23.5s\n",
      "359:\tlearn: 0.2767575\ttotal: 13.2s\tremaining: 23.4s\n",
      "360:\tlearn: 0.2761933\ttotal: 13.2s\tremaining: 23.4s\n",
      "361:\tlearn: 0.2757073\ttotal: 13.2s\tremaining: 23.3s\n",
      "362:\tlearn: 0.2755090\ttotal: 13.3s\tremaining: 23.3s\n",
      "363:\tlearn: 0.2750304\ttotal: 13.3s\tremaining: 23.3s\n",
      "364:\tlearn: 0.2748132\ttotal: 13.3s\tremaining: 23.2s\n",
      "365:\tlearn: 0.2745429\ttotal: 13.4s\tremaining: 23.2s\n",
      "366:\tlearn: 0.2742655\ttotal: 13.4s\tremaining: 23.1s\n",
      "367:\tlearn: 0.2740585\ttotal: 13.5s\tremaining: 23.1s\n",
      "368:\tlearn: 0.2740118\ttotal: 13.5s\tremaining: 23.1s\n",
      "369:\tlearn: 0.2734470\ttotal: 13.5s\tremaining: 23.1s\n",
      "370:\tlearn: 0.2729894\ttotal: 13.6s\tremaining: 23s\n",
      "371:\tlearn: 0.2728806\ttotal: 13.6s\tremaining: 23s\n",
      "372:\tlearn: 0.2727272\ttotal: 13.6s\tremaining: 22.9s\n",
      "373:\tlearn: 0.2724519\ttotal: 13.7s\tremaining: 22.9s\n",
      "374:\tlearn: 0.2721888\ttotal: 13.7s\tremaining: 22.9s\n",
      "375:\tlearn: 0.2720418\ttotal: 13.7s\tremaining: 22.8s\n",
      "376:\tlearn: 0.2716078\ttotal: 13.8s\tremaining: 22.8s\n",
      "377:\tlearn: 0.2712309\ttotal: 13.8s\tremaining: 22.7s\n",
      "378:\tlearn: 0.2708255\ttotal: 13.9s\tremaining: 22.7s\n",
      "379:\tlearn: 0.2706217\ttotal: 13.9s\tremaining: 22.7s\n",
      "380:\tlearn: 0.2702622\ttotal: 13.9s\tremaining: 22.6s\n",
      "381:\tlearn: 0.2700135\ttotal: 14s\tremaining: 22.6s\n",
      "382:\tlearn: 0.2696815\ttotal: 14s\tremaining: 22.6s\n",
      "383:\tlearn: 0.2693575\ttotal: 14s\tremaining: 22.5s\n",
      "384:\tlearn: 0.2690419\ttotal: 14.1s\tremaining: 22.5s\n",
      "385:\tlearn: 0.2687823\ttotal: 14.1s\tremaining: 22.5s\n",
      "386:\tlearn: 0.2685324\ttotal: 14.2s\tremaining: 22.4s\n",
      "387:\tlearn: 0.2681761\ttotal: 14.2s\tremaining: 22.4s\n",
      "388:\tlearn: 0.2677681\ttotal: 14.2s\tremaining: 22.4s\n",
      "389:\tlearn: 0.2674499\ttotal: 14.3s\tremaining: 22.3s\n",
      "390:\tlearn: 0.2671231\ttotal: 14.3s\tremaining: 22.3s\n",
      "391:\tlearn: 0.2669857\ttotal: 14.4s\tremaining: 22.3s\n",
      "392:\tlearn: 0.2667322\ttotal: 14.4s\tremaining: 22.2s\n",
      "393:\tlearn: 0.2665543\ttotal: 14.4s\tremaining: 22.2s\n",
      "394:\tlearn: 0.2663461\ttotal: 14.4s\tremaining: 22.1s\n",
      "395:\tlearn: 0.2660945\ttotal: 14.5s\tremaining: 22.1s\n",
      "396:\tlearn: 0.2659505\ttotal: 14.5s\tremaining: 22.1s\n",
      "397:\tlearn: 0.2656440\ttotal: 14.6s\tremaining: 22.1s\n",
      "398:\tlearn: 0.2653679\ttotal: 14.6s\tremaining: 22s\n",
      "399:\tlearn: 0.2650061\ttotal: 14.6s\tremaining: 22s\n",
      "400:\tlearn: 0.2647768\ttotal: 14.7s\tremaining: 21.9s\n",
      "401:\tlearn: 0.2643777\ttotal: 14.7s\tremaining: 21.9s\n",
      "402:\tlearn: 0.2642004\ttotal: 14.8s\tremaining: 21.9s\n",
      "403:\tlearn: 0.2639092\ttotal: 14.8s\tremaining: 21.8s\n",
      "404:\tlearn: 0.2635962\ttotal: 14.8s\tremaining: 21.8s\n",
      "405:\tlearn: 0.2632645\ttotal: 14.9s\tremaining: 21.8s\n",
      "406:\tlearn: 0.2630821\ttotal: 14.9s\tremaining: 21.7s\n",
      "407:\tlearn: 0.2628843\ttotal: 14.9s\tremaining: 21.7s\n",
      "408:\tlearn: 0.2627433\ttotal: 15s\tremaining: 21.6s\n",
      "409:\tlearn: 0.2625689\ttotal: 15s\tremaining: 21.6s\n",
      "410:\tlearn: 0.2624134\ttotal: 15s\tremaining: 21.6s\n",
      "411:\tlearn: 0.2620972\ttotal: 15.1s\tremaining: 21.5s\n",
      "412:\tlearn: 0.2618614\ttotal: 15.1s\tremaining: 21.5s\n",
      "413:\tlearn: 0.2615133\ttotal: 15.2s\tremaining: 21.5s\n",
      "414:\tlearn: 0.2614275\ttotal: 15.2s\tremaining: 21.4s\n",
      "415:\tlearn: 0.2611346\ttotal: 15.2s\tremaining: 21.4s\n",
      "416:\tlearn: 0.2610173\ttotal: 15.3s\tremaining: 21.3s\n",
      "417:\tlearn: 0.2606439\ttotal: 15.3s\tremaining: 21.3s\n",
      "418:\tlearn: 0.2602475\ttotal: 15.3s\tremaining: 21.3s\n",
      "419:\tlearn: 0.2599730\ttotal: 15.4s\tremaining: 21.2s\n",
      "420:\tlearn: 0.2595341\ttotal: 15.4s\tremaining: 21.2s\n",
      "421:\tlearn: 0.2593295\ttotal: 15.5s\tremaining: 21.2s\n",
      "422:\tlearn: 0.2591347\ttotal: 15.5s\tremaining: 21.1s\n",
      "423:\tlearn: 0.2589855\ttotal: 15.5s\tremaining: 21.1s\n",
      "424:\tlearn: 0.2586176\ttotal: 15.6s\tremaining: 21.1s\n",
      "425:\tlearn: 0.2582182\ttotal: 15.6s\tremaining: 21s\n",
      "426:\tlearn: 0.2579637\ttotal: 15.6s\tremaining: 21s\n",
      "427:\tlearn: 0.2576918\ttotal: 15.7s\tremaining: 21s\n",
      "428:\tlearn: 0.2573492\ttotal: 15.7s\tremaining: 20.9s\n",
      "429:\tlearn: 0.2571983\ttotal: 15.8s\tremaining: 20.9s\n",
      "430:\tlearn: 0.2570974\ttotal: 15.8s\tremaining: 20.8s\n",
      "431:\tlearn: 0.2568291\ttotal: 15.8s\tremaining: 20.8s\n",
      "432:\tlearn: 0.2565728\ttotal: 15.9s\tremaining: 20.8s\n",
      "433:\tlearn: 0.2564585\ttotal: 15.9s\tremaining: 20.7s\n",
      "434:\tlearn: 0.2563163\ttotal: 15.9s\tremaining: 20.7s\n",
      "435:\tlearn: 0.2561112\ttotal: 16s\tremaining: 20.7s\n",
      "436:\tlearn: 0.2557691\ttotal: 16s\tremaining: 20.6s\n",
      "437:\tlearn: 0.2554613\ttotal: 16s\tremaining: 20.6s\n",
      "438:\tlearn: 0.2550602\ttotal: 16.1s\tremaining: 20.6s\n",
      "439:\tlearn: 0.2549045\ttotal: 16.1s\tremaining: 20.5s\n",
      "440:\tlearn: 0.2545652\ttotal: 16.2s\tremaining: 20.5s\n",
      "441:\tlearn: 0.2542245\ttotal: 16.2s\tremaining: 20.5s\n",
      "442:\tlearn: 0.2540967\ttotal: 16.2s\tremaining: 20.4s\n",
      "443:\tlearn: 0.2538892\ttotal: 16.3s\tremaining: 20.4s\n",
      "444:\tlearn: 0.2537639\ttotal: 16.3s\tremaining: 20.3s\n",
      "445:\tlearn: 0.2534873\ttotal: 16.3s\tremaining: 20.3s\n",
      "446:\tlearn: 0.2533674\ttotal: 16.4s\tremaining: 20.3s\n",
      "447:\tlearn: 0.2531908\ttotal: 16.4s\tremaining: 20.2s\n",
      "448:\tlearn: 0.2529964\ttotal: 16.5s\tremaining: 20.2s\n",
      "449:\tlearn: 0.2528203\ttotal: 16.5s\tremaining: 20.2s\n",
      "450:\tlearn: 0.2527057\ttotal: 16.5s\tremaining: 20.1s\n",
      "451:\tlearn: 0.2526052\ttotal: 16.6s\tremaining: 20.1s\n",
      "452:\tlearn: 0.2523391\ttotal: 16.6s\tremaining: 20.1s\n",
      "453:\tlearn: 0.2521869\ttotal: 16.7s\tremaining: 20s\n",
      "454:\tlearn: 0.2518954\ttotal: 16.7s\tremaining: 20s\n",
      "455:\tlearn: 0.2515961\ttotal: 16.7s\tremaining: 20s\n",
      "456:\tlearn: 0.2514923\ttotal: 16.8s\tremaining: 19.9s\n",
      "457:\tlearn: 0.2512417\ttotal: 16.8s\tremaining: 19.9s\n",
      "458:\tlearn: 0.2510504\ttotal: 16.8s\tremaining: 19.8s\n",
      "459:\tlearn: 0.2505957\ttotal: 16.9s\tremaining: 19.8s\n",
      "460:\tlearn: 0.2503782\ttotal: 16.9s\tremaining: 19.8s\n",
      "461:\tlearn: 0.2503122\ttotal: 16.9s\tremaining: 19.7s\n",
      "462:\tlearn: 0.2501408\ttotal: 17s\tremaining: 19.7s\n",
      "463:\tlearn: 0.2498722\ttotal: 17s\tremaining: 19.7s\n",
      "464:\tlearn: 0.2495869\ttotal: 17.1s\tremaining: 19.6s\n",
      "465:\tlearn: 0.2494481\ttotal: 17.1s\tremaining: 19.6s\n",
      "466:\tlearn: 0.2493310\ttotal: 17.1s\tremaining: 19.6s\n",
      "467:\tlearn: 0.2490403\ttotal: 17.2s\tremaining: 19.5s\n",
      "468:\tlearn: 0.2487865\ttotal: 17.2s\tremaining: 19.5s\n",
      "469:\tlearn: 0.2486263\ttotal: 17.2s\tremaining: 19.4s\n",
      "470:\tlearn: 0.2483691\ttotal: 17.3s\tremaining: 19.4s\n",
      "471:\tlearn: 0.2480465\ttotal: 17.3s\tremaining: 19.4s\n",
      "472:\tlearn: 0.2479411\ttotal: 17.4s\tremaining: 19.4s\n",
      "473:\tlearn: 0.2478252\ttotal: 17.4s\tremaining: 19.3s\n",
      "474:\tlearn: 0.2474606\ttotal: 17.4s\tremaining: 19.3s\n",
      "475:\tlearn: 0.2472721\ttotal: 17.5s\tremaining: 19.2s\n",
      "476:\tlearn: 0.2470162\ttotal: 17.5s\tremaining: 19.2s\n",
      "477:\tlearn: 0.2467948\ttotal: 17.6s\tremaining: 19.2s\n",
      "478:\tlearn: 0.2465951\ttotal: 17.6s\tremaining: 19.1s\n",
      "479:\tlearn: 0.2462840\ttotal: 17.6s\tremaining: 19.1s\n",
      "480:\tlearn: 0.2461003\ttotal: 17.7s\tremaining: 19.1s\n",
      "481:\tlearn: 0.2458700\ttotal: 17.7s\tremaining: 19s\n",
      "482:\tlearn: 0.2456196\ttotal: 17.7s\tremaining: 19s\n",
      "483:\tlearn: 0.2454719\ttotal: 17.8s\tremaining: 19s\n",
      "484:\tlearn: 0.2453585\ttotal: 17.8s\tremaining: 18.9s\n",
      "485:\tlearn: 0.2451560\ttotal: 17.8s\tremaining: 18.9s\n",
      "486:\tlearn: 0.2448322\ttotal: 17.9s\tremaining: 18.8s\n",
      "487:\tlearn: 0.2444663\ttotal: 17.9s\tremaining: 18.8s\n",
      "488:\tlearn: 0.2442392\ttotal: 18s\tremaining: 18.8s\n",
      "489:\tlearn: 0.2439296\ttotal: 18s\tremaining: 18.7s\n",
      "490:\tlearn: 0.2436566\ttotal: 18s\tremaining: 18.7s\n",
      "491:\tlearn: 0.2433929\ttotal: 18.1s\tremaining: 18.7s\n",
      "492:\tlearn: 0.2432527\ttotal: 18.1s\tremaining: 18.6s\n",
      "493:\tlearn: 0.2430975\ttotal: 18.1s\tremaining: 18.6s\n",
      "494:\tlearn: 0.2428540\ttotal: 18.2s\tremaining: 18.5s\n",
      "495:\tlearn: 0.2425628\ttotal: 18.2s\tremaining: 18.5s\n",
      "496:\tlearn: 0.2424131\ttotal: 18.2s\tremaining: 18.5s\n",
      "497:\tlearn: 0.2422299\ttotal: 18.3s\tremaining: 18.4s\n",
      "498:\tlearn: 0.2419582\ttotal: 18.3s\tremaining: 18.4s\n",
      "499:\tlearn: 0.2416192\ttotal: 18.4s\tremaining: 18.4s\n",
      "500:\tlearn: 0.2414424\ttotal: 18.4s\tremaining: 18.3s\n",
      "501:\tlearn: 0.2412965\ttotal: 18.4s\tremaining: 18.3s\n",
      "502:\tlearn: 0.2411557\ttotal: 18.5s\tremaining: 18.2s\n",
      "503:\tlearn: 0.2410833\ttotal: 18.5s\tremaining: 18.2s\n",
      "504:\tlearn: 0.2409279\ttotal: 18.5s\tremaining: 18.2s\n",
      "505:\tlearn: 0.2407740\ttotal: 18.6s\tremaining: 18.1s\n",
      "506:\tlearn: 0.2406327\ttotal: 18.6s\tremaining: 18.1s\n",
      "507:\tlearn: 0.2405256\ttotal: 18.6s\tremaining: 18.1s\n",
      "508:\tlearn: 0.2403387\ttotal: 18.7s\tremaining: 18s\n",
      "509:\tlearn: 0.2400951\ttotal: 18.7s\tremaining: 18s\n",
      "510:\tlearn: 0.2397205\ttotal: 18.8s\tremaining: 18s\n",
      "511:\tlearn: 0.2394779\ttotal: 18.8s\tremaining: 17.9s\n",
      "512:\tlearn: 0.2391730\ttotal: 18.8s\tremaining: 17.9s\n",
      "513:\tlearn: 0.2389564\ttotal: 18.9s\tremaining: 17.8s\n",
      "514:\tlearn: 0.2386096\ttotal: 18.9s\tremaining: 17.8s\n",
      "515:\tlearn: 0.2383824\ttotal: 18.9s\tremaining: 17.8s\n",
      "516:\tlearn: 0.2382216\ttotal: 19s\tremaining: 17.7s\n",
      "517:\tlearn: 0.2380029\ttotal: 19s\tremaining: 17.7s\n",
      "518:\tlearn: 0.2378010\ttotal: 19.1s\tremaining: 17.7s\n",
      "519:\tlearn: 0.2376026\ttotal: 19.1s\tremaining: 17.6s\n",
      "520:\tlearn: 0.2374934\ttotal: 19.1s\tremaining: 17.6s\n",
      "521:\tlearn: 0.2372587\ttotal: 19.2s\tremaining: 17.5s\n",
      "522:\tlearn: 0.2371883\ttotal: 19.2s\tremaining: 17.5s\n",
      "523:\tlearn: 0.2370375\ttotal: 19.2s\tremaining: 17.5s\n",
      "524:\tlearn: 0.2366977\ttotal: 19.3s\tremaining: 17.4s\n",
      "525:\tlearn: 0.2366365\ttotal: 19.3s\tremaining: 17.4s\n",
      "526:\tlearn: 0.2364469\ttotal: 19.3s\tremaining: 17.4s\n",
      "527:\tlearn: 0.2362593\ttotal: 19.4s\tremaining: 17.3s\n",
      "528:\tlearn: 0.2359729\ttotal: 19.4s\tremaining: 17.3s\n",
      "529:\tlearn: 0.2356637\ttotal: 19.4s\tremaining: 17.2s\n",
      "530:\tlearn: 0.2354457\ttotal: 19.5s\tremaining: 17.2s\n",
      "531:\tlearn: 0.2352498\ttotal: 19.5s\tremaining: 17.2s\n",
      "532:\tlearn: 0.2350674\ttotal: 19.6s\tremaining: 17.1s\n",
      "533:\tlearn: 0.2349060\ttotal: 19.6s\tremaining: 17.1s\n",
      "534:\tlearn: 0.2347359\ttotal: 19.6s\tremaining: 17.1s\n",
      "535:\tlearn: 0.2345022\ttotal: 19.7s\tremaining: 17s\n",
      "536:\tlearn: 0.2342914\ttotal: 19.7s\tremaining: 17s\n",
      "537:\tlearn: 0.2340174\ttotal: 19.7s\tremaining: 16.9s\n",
      "538:\tlearn: 0.2338276\ttotal: 19.8s\tremaining: 16.9s\n",
      "539:\tlearn: 0.2335852\ttotal: 19.8s\tremaining: 16.9s\n",
      "540:\tlearn: 0.2334241\ttotal: 19.9s\tremaining: 16.8s\n",
      "541:\tlearn: 0.2332454\ttotal: 19.9s\tremaining: 16.8s\n",
      "542:\tlearn: 0.2330911\ttotal: 19.9s\tremaining: 16.8s\n",
      "543:\tlearn: 0.2328764\ttotal: 20s\tremaining: 16.7s\n",
      "544:\tlearn: 0.2326749\ttotal: 20s\tremaining: 16.7s\n",
      "545:\tlearn: 0.2325562\ttotal: 20s\tremaining: 16.7s\n",
      "546:\tlearn: 0.2324488\ttotal: 20.1s\tremaining: 16.6s\n",
      "547:\tlearn: 0.2322276\ttotal: 20.1s\tremaining: 16.6s\n",
      "548:\tlearn: 0.2320907\ttotal: 20.1s\tremaining: 16.5s\n",
      "549:\tlearn: 0.2318544\ttotal: 20.2s\tremaining: 16.5s\n",
      "550:\tlearn: 0.2317032\ttotal: 20.2s\tremaining: 16.5s\n",
      "551:\tlearn: 0.2314586\ttotal: 20.3s\tremaining: 16.5s\n",
      "552:\tlearn: 0.2313512\ttotal: 20.3s\tremaining: 16.4s\n",
      "553:\tlearn: 0.2309619\ttotal: 20.3s\tremaining: 16.4s\n",
      "554:\tlearn: 0.2308052\ttotal: 20.4s\tremaining: 16.3s\n",
      "555:\tlearn: 0.2305426\ttotal: 20.4s\tremaining: 16.3s\n",
      "556:\tlearn: 0.2304319\ttotal: 20.4s\tremaining: 16.3s\n",
      "557:\tlearn: 0.2302812\ttotal: 20.5s\tremaining: 16.2s\n",
      "558:\tlearn: 0.2300503\ttotal: 20.5s\tremaining: 16.2s\n",
      "559:\tlearn: 0.2298878\ttotal: 20.5s\tremaining: 16.1s\n",
      "560:\tlearn: 0.2298033\ttotal: 20.6s\tremaining: 16.1s\n",
      "561:\tlearn: 0.2296811\ttotal: 20.6s\tremaining: 16.1s\n",
      "562:\tlearn: 0.2295694\ttotal: 20.7s\tremaining: 16s\n",
      "563:\tlearn: 0.2294620\ttotal: 20.7s\tremaining: 16s\n",
      "564:\tlearn: 0.2293542\ttotal: 20.7s\tremaining: 16s\n",
      "565:\tlearn: 0.2291753\ttotal: 20.8s\tremaining: 15.9s\n",
      "566:\tlearn: 0.2289671\ttotal: 20.8s\tremaining: 15.9s\n",
      "567:\tlearn: 0.2287063\ttotal: 20.8s\tremaining: 15.9s\n",
      "568:\tlearn: 0.2286305\ttotal: 20.9s\tremaining: 15.8s\n",
      "569:\tlearn: 0.2284891\ttotal: 20.9s\tremaining: 15.8s\n",
      "570:\tlearn: 0.2283055\ttotal: 21s\tremaining: 15.7s\n",
      "571:\tlearn: 0.2281038\ttotal: 21s\tremaining: 15.7s\n",
      "572:\tlearn: 0.2279341\ttotal: 21s\tremaining: 15.7s\n",
      "573:\tlearn: 0.2276756\ttotal: 21.1s\tremaining: 15.6s\n",
      "574:\tlearn: 0.2275875\ttotal: 21.1s\tremaining: 15.6s\n",
      "575:\tlearn: 0.2272534\ttotal: 21.1s\tremaining: 15.6s\n",
      "576:\tlearn: 0.2271906\ttotal: 21.2s\tremaining: 15.5s\n",
      "577:\tlearn: 0.2268682\ttotal: 21.2s\tremaining: 15.5s\n",
      "578:\tlearn: 0.2267961\ttotal: 21.3s\tremaining: 15.5s\n",
      "579:\tlearn: 0.2265976\ttotal: 21.3s\tremaining: 15.4s\n",
      "580:\tlearn: 0.2265233\ttotal: 21.3s\tremaining: 15.4s\n",
      "581:\tlearn: 0.2263961\ttotal: 21.4s\tremaining: 15.3s\n",
      "582:\tlearn: 0.2262516\ttotal: 21.4s\tremaining: 15.3s\n",
      "583:\tlearn: 0.2260844\ttotal: 21.4s\tremaining: 15.3s\n",
      "584:\tlearn: 0.2260031\ttotal: 21.5s\tremaining: 15.2s\n",
      "585:\tlearn: 0.2257878\ttotal: 21.5s\tremaining: 15.2s\n",
      "586:\tlearn: 0.2256048\ttotal: 21.5s\tremaining: 15.2s\n",
      "587:\tlearn: 0.2254401\ttotal: 21.6s\tremaining: 15.1s\n",
      "588:\tlearn: 0.2253440\ttotal: 21.6s\tremaining: 15.1s\n",
      "589:\tlearn: 0.2251262\ttotal: 21.7s\tremaining: 15.1s\n",
      "590:\tlearn: 0.2249513\ttotal: 21.7s\tremaining: 15s\n",
      "591:\tlearn: 0.2246577\ttotal: 21.7s\tremaining: 15s\n",
      "592:\tlearn: 0.2243896\ttotal: 21.8s\tremaining: 14.9s\n",
      "593:\tlearn: 0.2243397\ttotal: 21.8s\tremaining: 14.9s\n",
      "594:\tlearn: 0.2240526\ttotal: 21.8s\tremaining: 14.9s\n",
      "595:\tlearn: 0.2237834\ttotal: 21.9s\tremaining: 14.8s\n",
      "596:\tlearn: 0.2236768\ttotal: 21.9s\tremaining: 14.8s\n",
      "597:\tlearn: 0.2235738\ttotal: 21.9s\tremaining: 14.7s\n",
      "598:\tlearn: 0.2233434\ttotal: 22s\tremaining: 14.7s\n",
      "599:\tlearn: 0.2232648\ttotal: 22s\tremaining: 14.7s\n",
      "600:\tlearn: 0.2229257\ttotal: 22.1s\tremaining: 14.6s\n",
      "601:\tlearn: 0.2226405\ttotal: 22.1s\tremaining: 14.6s\n",
      "602:\tlearn: 0.2224911\ttotal: 22.1s\tremaining: 14.6s\n",
      "603:\tlearn: 0.2222503\ttotal: 22.2s\tremaining: 14.5s\n",
      "604:\tlearn: 0.2221237\ttotal: 22.2s\tremaining: 14.5s\n",
      "605:\tlearn: 0.2219108\ttotal: 22.2s\tremaining: 14.5s\n",
      "606:\tlearn: 0.2218272\ttotal: 22.3s\tremaining: 14.4s\n",
      "607:\tlearn: 0.2216242\ttotal: 22.3s\tremaining: 14.4s\n",
      "608:\tlearn: 0.2213504\ttotal: 22.3s\tremaining: 14.3s\n",
      "609:\tlearn: 0.2211673\ttotal: 22.4s\tremaining: 14.3s\n",
      "610:\tlearn: 0.2210020\ttotal: 22.4s\tremaining: 14.3s\n",
      "611:\tlearn: 0.2208770\ttotal: 22.4s\tremaining: 14.2s\n",
      "612:\tlearn: 0.2206752\ttotal: 22.5s\tremaining: 14.2s\n",
      "613:\tlearn: 0.2205761\ttotal: 22.5s\tremaining: 14.1s\n",
      "614:\tlearn: 0.2203882\ttotal: 22.5s\tremaining: 14.1s\n",
      "615:\tlearn: 0.2202068\ttotal: 22.6s\tremaining: 14.1s\n",
      "616:\tlearn: 0.2200762\ttotal: 22.6s\tremaining: 14s\n",
      "617:\tlearn: 0.2199767\ttotal: 22.7s\tremaining: 14s\n",
      "618:\tlearn: 0.2198948\ttotal: 22.7s\tremaining: 14s\n",
      "619:\tlearn: 0.2197826\ttotal: 22.7s\tremaining: 13.9s\n",
      "620:\tlearn: 0.2195225\ttotal: 22.8s\tremaining: 13.9s\n",
      "621:\tlearn: 0.2192908\ttotal: 22.8s\tremaining: 13.9s\n",
      "622:\tlearn: 0.2190877\ttotal: 22.9s\tremaining: 13.8s\n",
      "623:\tlearn: 0.2186968\ttotal: 22.9s\tremaining: 13.8s\n",
      "624:\tlearn: 0.2184790\ttotal: 22.9s\tremaining: 13.8s\n",
      "625:\tlearn: 0.2182779\ttotal: 23s\tremaining: 13.7s\n",
      "626:\tlearn: 0.2181545\ttotal: 23s\tremaining: 13.7s\n",
      "627:\tlearn: 0.2179750\ttotal: 23s\tremaining: 13.6s\n",
      "628:\tlearn: 0.2177789\ttotal: 23.1s\tremaining: 13.6s\n",
      "629:\tlearn: 0.2176408\ttotal: 23.1s\tremaining: 13.6s\n",
      "630:\tlearn: 0.2174970\ttotal: 23.1s\tremaining: 13.5s\n",
      "631:\tlearn: 0.2173768\ttotal: 23.2s\tremaining: 13.5s\n",
      "632:\tlearn: 0.2172557\ttotal: 23.2s\tremaining: 13.5s\n",
      "633:\tlearn: 0.2171962\ttotal: 23.3s\tremaining: 13.4s\n",
      "634:\tlearn: 0.2169385\ttotal: 23.3s\tremaining: 13.4s\n",
      "635:\tlearn: 0.2169149\ttotal: 23.3s\tremaining: 13.3s\n",
      "636:\tlearn: 0.2166668\ttotal: 23.4s\tremaining: 13.3s\n",
      "637:\tlearn: 0.2164061\ttotal: 23.4s\tremaining: 13.3s\n",
      "638:\tlearn: 0.2161724\ttotal: 23.4s\tremaining: 13.2s\n",
      "639:\tlearn: 0.2160008\ttotal: 23.5s\tremaining: 13.2s\n",
      "640:\tlearn: 0.2159079\ttotal: 23.5s\tremaining: 13.2s\n",
      "641:\tlearn: 0.2157220\ttotal: 23.5s\tremaining: 13.1s\n",
      "642:\tlearn: 0.2155817\ttotal: 23.6s\tremaining: 13.1s\n",
      "643:\tlearn: 0.2153533\ttotal: 23.6s\tremaining: 13.1s\n",
      "644:\tlearn: 0.2151125\ttotal: 23.7s\tremaining: 13s\n",
      "645:\tlearn: 0.2148901\ttotal: 23.7s\tremaining: 13s\n",
      "646:\tlearn: 0.2147725\ttotal: 23.7s\tremaining: 12.9s\n",
      "647:\tlearn: 0.2146509\ttotal: 23.8s\tremaining: 12.9s\n",
      "648:\tlearn: 0.2145056\ttotal: 23.8s\tremaining: 12.9s\n",
      "649:\tlearn: 0.2142393\ttotal: 23.8s\tremaining: 12.8s\n",
      "650:\tlearn: 0.2140618\ttotal: 23.9s\tremaining: 12.8s\n",
      "651:\tlearn: 0.2137239\ttotal: 23.9s\tremaining: 12.8s\n",
      "652:\tlearn: 0.2137063\ttotal: 23.9s\tremaining: 12.7s\n",
      "653:\tlearn: 0.2134080\ttotal: 24s\tremaining: 12.7s\n",
      "654:\tlearn: 0.2131937\ttotal: 24s\tremaining: 12.6s\n",
      "655:\tlearn: 0.2131305\ttotal: 24s\tremaining: 12.6s\n",
      "656:\tlearn: 0.2129630\ttotal: 24.1s\tremaining: 12.6s\n",
      "657:\tlearn: 0.2128380\ttotal: 24.1s\tremaining: 12.5s\n",
      "658:\tlearn: 0.2125718\ttotal: 24.2s\tremaining: 12.5s\n",
      "659:\tlearn: 0.2122963\ttotal: 24.2s\tremaining: 12.5s\n",
      "660:\tlearn: 0.2121785\ttotal: 24.2s\tremaining: 12.4s\n",
      "661:\tlearn: 0.2120424\ttotal: 24.3s\tremaining: 12.4s\n",
      "662:\tlearn: 0.2119163\ttotal: 24.3s\tremaining: 12.4s\n",
      "663:\tlearn: 0.2118015\ttotal: 24.4s\tremaining: 12.3s\n",
      "664:\tlearn: 0.2114139\ttotal: 24.4s\tremaining: 12.3s\n",
      "665:\tlearn: 0.2112677\ttotal: 24.4s\tremaining: 12.3s\n",
      "666:\tlearn: 0.2111878\ttotal: 24.5s\tremaining: 12.2s\n",
      "667:\tlearn: 0.2109176\ttotal: 24.5s\tremaining: 12.2s\n",
      "668:\tlearn: 0.2108239\ttotal: 24.5s\tremaining: 12.1s\n",
      "669:\tlearn: 0.2107614\ttotal: 24.6s\tremaining: 12.1s\n",
      "670:\tlearn: 0.2107090\ttotal: 24.6s\tremaining: 12.1s\n",
      "671:\tlearn: 0.2105990\ttotal: 24.6s\tremaining: 12s\n",
      "672:\tlearn: 0.2104997\ttotal: 24.7s\tremaining: 12s\n",
      "673:\tlearn: 0.2104240\ttotal: 24.7s\tremaining: 11.9s\n",
      "674:\tlearn: 0.2102477\ttotal: 24.7s\tremaining: 11.9s\n",
      "675:\tlearn: 0.2100955\ttotal: 24.8s\tremaining: 11.9s\n",
      "676:\tlearn: 0.2098309\ttotal: 24.8s\tremaining: 11.8s\n",
      "677:\tlearn: 0.2096225\ttotal: 24.9s\tremaining: 11.8s\n",
      "678:\tlearn: 0.2093536\ttotal: 24.9s\tremaining: 11.8s\n",
      "679:\tlearn: 0.2091943\ttotal: 24.9s\tremaining: 11.7s\n",
      "680:\tlearn: 0.2090983\ttotal: 25s\tremaining: 11.7s\n",
      "681:\tlearn: 0.2088773\ttotal: 25s\tremaining: 11.7s\n",
      "682:\tlearn: 0.2086751\ttotal: 25s\tremaining: 11.6s\n",
      "683:\tlearn: 0.2085890\ttotal: 25.1s\tremaining: 11.6s\n",
      "684:\tlearn: 0.2085135\ttotal: 25.1s\tremaining: 11.5s\n",
      "685:\tlearn: 0.2083514\ttotal: 25.1s\tremaining: 11.5s\n",
      "686:\tlearn: 0.2082971\ttotal: 25.2s\tremaining: 11.5s\n",
      "687:\tlearn: 0.2081821\ttotal: 25.2s\tremaining: 11.4s\n",
      "688:\tlearn: 0.2080860\ttotal: 25.3s\tremaining: 11.4s\n",
      "689:\tlearn: 0.2079274\ttotal: 25.3s\tremaining: 11.4s\n",
      "690:\tlearn: 0.2077717\ttotal: 25.3s\tremaining: 11.3s\n",
      "691:\tlearn: 0.2076627\ttotal: 25.4s\tremaining: 11.3s\n",
      "692:\tlearn: 0.2075409\ttotal: 25.4s\tremaining: 11.3s\n",
      "693:\tlearn: 0.2073839\ttotal: 25.4s\tremaining: 11.2s\n",
      "694:\tlearn: 0.2073073\ttotal: 25.5s\tremaining: 11.2s\n",
      "695:\tlearn: 0.2070575\ttotal: 25.5s\tremaining: 11.1s\n",
      "696:\tlearn: 0.2069930\ttotal: 25.5s\tremaining: 11.1s\n",
      "697:\tlearn: 0.2069207\ttotal: 25.6s\tremaining: 11.1s\n",
      "698:\tlearn: 0.2067523\ttotal: 25.6s\tremaining: 11s\n",
      "699:\tlearn: 0.2066508\ttotal: 25.7s\tremaining: 11s\n",
      "700:\tlearn: 0.2065415\ttotal: 25.7s\tremaining: 11s\n",
      "701:\tlearn: 0.2064875\ttotal: 25.7s\tremaining: 10.9s\n",
      "702:\tlearn: 0.2062659\ttotal: 25.8s\tremaining: 10.9s\n",
      "703:\tlearn: 0.2061649\ttotal: 25.8s\tremaining: 10.8s\n",
      "704:\tlearn: 0.2060854\ttotal: 25.8s\tremaining: 10.8s\n",
      "705:\tlearn: 0.2058231\ttotal: 25.9s\tremaining: 10.8s\n",
      "706:\tlearn: 0.2055722\ttotal: 25.9s\tremaining: 10.7s\n",
      "707:\tlearn: 0.2053845\ttotal: 25.9s\tremaining: 10.7s\n",
      "708:\tlearn: 0.2052786\ttotal: 26s\tremaining: 10.7s\n",
      "709:\tlearn: 0.2051312\ttotal: 26s\tremaining: 10.6s\n",
      "710:\tlearn: 0.2050223\ttotal: 26s\tremaining: 10.6s\n",
      "711:\tlearn: 0.2048878\ttotal: 26.1s\tremaining: 10.5s\n",
      "712:\tlearn: 0.2046629\ttotal: 26.1s\tremaining: 10.5s\n",
      "713:\tlearn: 0.2045247\ttotal: 26.1s\tremaining: 10.5s\n",
      "714:\tlearn: 0.2043385\ttotal: 26.2s\tremaining: 10.4s\n",
      "715:\tlearn: 0.2041595\ttotal: 26.2s\tremaining: 10.4s\n",
      "716:\tlearn: 0.2040238\ttotal: 26.3s\tremaining: 10.4s\n",
      "717:\tlearn: 0.2038932\ttotal: 26.3s\tremaining: 10.3s\n",
      "718:\tlearn: 0.2036846\ttotal: 26.3s\tremaining: 10.3s\n",
      "719:\tlearn: 0.2035566\ttotal: 26.4s\tremaining: 10.3s\n",
      "720:\tlearn: 0.2034750\ttotal: 26.4s\tremaining: 10.2s\n",
      "721:\tlearn: 0.2032428\ttotal: 26.5s\tremaining: 10.2s\n",
      "722:\tlearn: 0.2030891\ttotal: 26.5s\tremaining: 10.2s\n",
      "723:\tlearn: 0.2029232\ttotal: 26.5s\tremaining: 10.1s\n",
      "724:\tlearn: 0.2027341\ttotal: 26.6s\tremaining: 10.1s\n",
      "725:\tlearn: 0.2025594\ttotal: 26.6s\tremaining: 10s\n",
      "726:\tlearn: 0.2024879\ttotal: 26.7s\tremaining: 10s\n",
      "727:\tlearn: 0.2024150\ttotal: 26.7s\tremaining: 9.98s\n",
      "728:\tlearn: 0.2021838\ttotal: 26.8s\tremaining: 9.95s\n",
      "729:\tlearn: 0.2019872\ttotal: 26.8s\tremaining: 9.91s\n",
      "730:\tlearn: 0.2018671\ttotal: 26.8s\tremaining: 9.87s\n",
      "731:\tlearn: 0.2016926\ttotal: 26.9s\tremaining: 9.83s\n",
      "732:\tlearn: 0.2016277\ttotal: 26.9s\tremaining: 9.8s\n",
      "733:\tlearn: 0.2014432\ttotal: 26.9s\tremaining: 9.76s\n",
      "734:\tlearn: 0.2013633\ttotal: 27s\tremaining: 9.73s\n",
      "735:\tlearn: 0.2012423\ttotal: 27s\tremaining: 9.69s\n",
      "736:\tlearn: 0.2010504\ttotal: 27.1s\tremaining: 9.65s\n",
      "737:\tlearn: 0.2008672\ttotal: 27.1s\tremaining: 9.62s\n",
      "738:\tlearn: 0.2006582\ttotal: 27.1s\tremaining: 9.58s\n",
      "739:\tlearn: 0.2004547\ttotal: 27.2s\tremaining: 9.54s\n",
      "740:\tlearn: 0.2003493\ttotal: 27.2s\tremaining: 9.51s\n",
      "741:\tlearn: 0.2003056\ttotal: 27.2s\tremaining: 9.47s\n",
      "742:\tlearn: 0.2001822\ttotal: 27.3s\tremaining: 9.43s\n",
      "743:\tlearn: 0.2000331\ttotal: 27.3s\tremaining: 9.39s\n",
      "744:\tlearn: 0.1998556\ttotal: 27.3s\tremaining: 9.36s\n",
      "745:\tlearn: 0.1997640\ttotal: 27.4s\tremaining: 9.32s\n",
      "746:\tlearn: 0.1995951\ttotal: 27.4s\tremaining: 9.29s\n",
      "747:\tlearn: 0.1994468\ttotal: 27.5s\tremaining: 9.25s\n",
      "748:\tlearn: 0.1992394\ttotal: 27.5s\tremaining: 9.21s\n",
      "749:\tlearn: 0.1990831\ttotal: 27.5s\tremaining: 9.18s\n",
      "750:\tlearn: 0.1988841\ttotal: 27.6s\tremaining: 9.14s\n",
      "751:\tlearn: 0.1988352\ttotal: 27.6s\tremaining: 9.11s\n",
      "752:\tlearn: 0.1986733\ttotal: 27.7s\tremaining: 9.07s\n",
      "753:\tlearn: 0.1984761\ttotal: 27.7s\tremaining: 9.03s\n",
      "754:\tlearn: 0.1982402\ttotal: 27.7s\tremaining: 8.99s\n",
      "755:\tlearn: 0.1981220\ttotal: 27.8s\tremaining: 8.96s\n",
      "756:\tlearn: 0.1980234\ttotal: 27.8s\tremaining: 8.92s\n",
      "757:\tlearn: 0.1978424\ttotal: 27.8s\tremaining: 8.88s\n",
      "758:\tlearn: 0.1975179\ttotal: 27.9s\tremaining: 8.85s\n",
      "759:\tlearn: 0.1974256\ttotal: 27.9s\tremaining: 8.81s\n",
      "760:\tlearn: 0.1973152\ttotal: 27.9s\tremaining: 8.77s\n",
      "761:\tlearn: 0.1971228\ttotal: 28s\tremaining: 8.74s\n",
      "762:\tlearn: 0.1969793\ttotal: 28s\tremaining: 8.7s\n",
      "763:\tlearn: 0.1969456\ttotal: 28.1s\tremaining: 8.66s\n",
      "764:\tlearn: 0.1968835\ttotal: 28.1s\tremaining: 8.63s\n",
      "765:\tlearn: 0.1966259\ttotal: 28.1s\tremaining: 8.59s\n",
      "766:\tlearn: 0.1965033\ttotal: 28.2s\tremaining: 8.55s\n",
      "767:\tlearn: 0.1963615\ttotal: 28.2s\tremaining: 8.52s\n",
      "768:\tlearn: 0.1962966\ttotal: 28.2s\tremaining: 8.48s\n",
      "769:\tlearn: 0.1961180\ttotal: 28.3s\tremaining: 8.45s\n",
      "770:\tlearn: 0.1959499\ttotal: 28.3s\tremaining: 8.41s\n",
      "771:\tlearn: 0.1958779\ttotal: 28.4s\tremaining: 8.37s\n",
      "772:\tlearn: 0.1957600\ttotal: 28.4s\tremaining: 8.34s\n",
      "773:\tlearn: 0.1956955\ttotal: 28.4s\tremaining: 8.3s\n",
      "774:\tlearn: 0.1956457\ttotal: 28.5s\tremaining: 8.26s\n",
      "775:\tlearn: 0.1955845\ttotal: 28.5s\tremaining: 8.22s\n",
      "776:\tlearn: 0.1954366\ttotal: 28.5s\tremaining: 8.19s\n",
      "777:\tlearn: 0.1953248\ttotal: 28.6s\tremaining: 8.15s\n",
      "778:\tlearn: 0.1952472\ttotal: 28.6s\tremaining: 8.11s\n",
      "779:\tlearn: 0.1951596\ttotal: 28.6s\tremaining: 8.07s\n",
      "780:\tlearn: 0.1948996\ttotal: 28.7s\tremaining: 8.04s\n",
      "781:\tlearn: 0.1947329\ttotal: 28.7s\tremaining: 8.01s\n",
      "782:\tlearn: 0.1946355\ttotal: 28.8s\tremaining: 7.97s\n",
      "783:\tlearn: 0.1945215\ttotal: 28.8s\tremaining: 7.93s\n",
      "784:\tlearn: 0.1943278\ttotal: 28.8s\tremaining: 7.9s\n",
      "785:\tlearn: 0.1941354\ttotal: 28.9s\tremaining: 7.86s\n",
      "786:\tlearn: 0.1940324\ttotal: 28.9s\tremaining: 7.82s\n",
      "787:\tlearn: 0.1939003\ttotal: 28.9s\tremaining: 7.78s\n",
      "788:\tlearn: 0.1937834\ttotal: 29s\tremaining: 7.75s\n",
      "789:\tlearn: 0.1936579\ttotal: 29s\tremaining: 7.72s\n",
      "790:\tlearn: 0.1934955\ttotal: 29.1s\tremaining: 7.68s\n",
      "791:\tlearn: 0.1934389\ttotal: 29.1s\tremaining: 7.64s\n",
      "792:\tlearn: 0.1933826\ttotal: 29.1s\tremaining: 7.6s\n",
      "793:\tlearn: 0.1932697\ttotal: 29.2s\tremaining: 7.57s\n",
      "794:\tlearn: 0.1931028\ttotal: 29.2s\tremaining: 7.53s\n",
      "795:\tlearn: 0.1928967\ttotal: 29.2s\tremaining: 7.49s\n",
      "796:\tlearn: 0.1927245\ttotal: 29.3s\tremaining: 7.46s\n",
      "797:\tlearn: 0.1926703\ttotal: 29.3s\tremaining: 7.42s\n",
      "798:\tlearn: 0.1925034\ttotal: 29.3s\tremaining: 7.38s\n",
      "799:\tlearn: 0.1923636\ttotal: 29.4s\tremaining: 7.34s\n",
      "800:\tlearn: 0.1922588\ttotal: 29.4s\tremaining: 7.31s\n",
      "801:\tlearn: 0.1921782\ttotal: 29.5s\tremaining: 7.27s\n",
      "802:\tlearn: 0.1920149\ttotal: 29.5s\tremaining: 7.24s\n",
      "803:\tlearn: 0.1919100\ttotal: 29.5s\tremaining: 7.2s\n",
      "804:\tlearn: 0.1917326\ttotal: 29.6s\tremaining: 7.17s\n",
      "805:\tlearn: 0.1915573\ttotal: 29.6s\tremaining: 7.13s\n",
      "806:\tlearn: 0.1915232\ttotal: 29.6s\tremaining: 7.09s\n",
      "807:\tlearn: 0.1914539\ttotal: 29.7s\tremaining: 7.05s\n",
      "808:\tlearn: 0.1913913\ttotal: 29.7s\tremaining: 7.02s\n",
      "809:\tlearn: 0.1912510\ttotal: 29.8s\tremaining: 6.98s\n",
      "810:\tlearn: 0.1911784\ttotal: 29.8s\tremaining: 6.95s\n",
      "811:\tlearn: 0.1910614\ttotal: 29.8s\tremaining: 6.91s\n",
      "812:\tlearn: 0.1909325\ttotal: 29.9s\tremaining: 6.87s\n",
      "813:\tlearn: 0.1908500\ttotal: 29.9s\tremaining: 6.83s\n",
      "814:\tlearn: 0.1907900\ttotal: 29.9s\tremaining: 6.79s\n",
      "815:\tlearn: 0.1906135\ttotal: 30s\tremaining: 6.76s\n",
      "816:\tlearn: 0.1904571\ttotal: 30s\tremaining: 6.72s\n",
      "817:\tlearn: 0.1903476\ttotal: 30s\tremaining: 6.68s\n",
      "818:\tlearn: 0.1901912\ttotal: 30.1s\tremaining: 6.65s\n",
      "819:\tlearn: 0.1901322\ttotal: 30.1s\tremaining: 6.61s\n",
      "820:\tlearn: 0.1900279\ttotal: 30.2s\tremaining: 6.58s\n",
      "821:\tlearn: 0.1898772\ttotal: 30.2s\tremaining: 6.54s\n",
      "822:\tlearn: 0.1898261\ttotal: 30.2s\tremaining: 6.5s\n",
      "823:\tlearn: 0.1897160\ttotal: 30.3s\tremaining: 6.47s\n",
      "824:\tlearn: 0.1896571\ttotal: 30.3s\tremaining: 6.43s\n",
      "825:\tlearn: 0.1895185\ttotal: 30.3s\tremaining: 6.39s\n",
      "826:\tlearn: 0.1894674\ttotal: 30.4s\tremaining: 6.35s\n",
      "827:\tlearn: 0.1894064\ttotal: 30.4s\tremaining: 6.32s\n",
      "828:\tlearn: 0.1892043\ttotal: 30.5s\tremaining: 6.28s\n",
      "829:\tlearn: 0.1890955\ttotal: 30.5s\tremaining: 6.25s\n",
      "830:\tlearn: 0.1889644\ttotal: 30.5s\tremaining: 6.21s\n",
      "831:\tlearn: 0.1889183\ttotal: 30.6s\tremaining: 6.17s\n",
      "832:\tlearn: 0.1888118\ttotal: 30.6s\tremaining: 6.13s\n",
      "833:\tlearn: 0.1886488\ttotal: 30.6s\tremaining: 6.1s\n",
      "834:\tlearn: 0.1886062\ttotal: 30.7s\tremaining: 6.06s\n",
      "835:\tlearn: 0.1885268\ttotal: 30.7s\tremaining: 6.02s\n",
      "836:\tlearn: 0.1883558\ttotal: 30.7s\tremaining: 5.99s\n",
      "837:\tlearn: 0.1881859\ttotal: 30.8s\tremaining: 5.95s\n",
      "838:\tlearn: 0.1880675\ttotal: 30.8s\tremaining: 5.91s\n",
      "839:\tlearn: 0.1879481\ttotal: 30.8s\tremaining: 5.87s\n",
      "840:\tlearn: 0.1878021\ttotal: 30.9s\tremaining: 5.84s\n",
      "841:\tlearn: 0.1877391\ttotal: 30.9s\tremaining: 5.8s\n",
      "842:\tlearn: 0.1876913\ttotal: 31s\tremaining: 5.77s\n",
      "843:\tlearn: 0.1875962\ttotal: 31s\tremaining: 5.73s\n",
      "844:\tlearn: 0.1875223\ttotal: 31s\tremaining: 5.69s\n",
      "845:\tlearn: 0.1874303\ttotal: 31.1s\tremaining: 5.66s\n",
      "846:\tlearn: 0.1872972\ttotal: 31.1s\tremaining: 5.62s\n",
      "847:\tlearn: 0.1871644\ttotal: 31.1s\tremaining: 5.58s\n",
      "848:\tlearn: 0.1870282\ttotal: 31.2s\tremaining: 5.55s\n",
      "849:\tlearn: 0.1869592\ttotal: 31.2s\tremaining: 5.51s\n",
      "850:\tlearn: 0.1867771\ttotal: 31.3s\tremaining: 5.47s\n",
      "851:\tlearn: 0.1866795\ttotal: 31.3s\tremaining: 5.43s\n",
      "852:\tlearn: 0.1865201\ttotal: 31.3s\tremaining: 5.4s\n",
      "853:\tlearn: 0.1863852\ttotal: 31.4s\tremaining: 5.36s\n",
      "854:\tlearn: 0.1862978\ttotal: 31.4s\tremaining: 5.33s\n",
      "855:\tlearn: 0.1861958\ttotal: 31.4s\tremaining: 5.29s\n",
      "856:\tlearn: 0.1860994\ttotal: 31.5s\tremaining: 5.25s\n",
      "857:\tlearn: 0.1859470\ttotal: 31.5s\tremaining: 5.22s\n",
      "858:\tlearn: 0.1858137\ttotal: 31.6s\tremaining: 5.18s\n",
      "859:\tlearn: 0.1856713\ttotal: 31.6s\tremaining: 5.14s\n",
      "860:\tlearn: 0.1856211\ttotal: 31.6s\tremaining: 5.11s\n",
      "861:\tlearn: 0.1854664\ttotal: 31.7s\tremaining: 5.07s\n",
      "862:\tlearn: 0.1854399\ttotal: 31.7s\tremaining: 5.03s\n",
      "863:\tlearn: 0.1852545\ttotal: 31.8s\tremaining: 5s\n",
      "864:\tlearn: 0.1851879\ttotal: 31.8s\tremaining: 4.96s\n",
      "865:\tlearn: 0.1850968\ttotal: 31.8s\tremaining: 4.92s\n",
      "866:\tlearn: 0.1849352\ttotal: 31.9s\tremaining: 4.89s\n",
      "867:\tlearn: 0.1848440\ttotal: 31.9s\tremaining: 4.85s\n",
      "868:\tlearn: 0.1847894\ttotal: 31.9s\tremaining: 4.81s\n",
      "869:\tlearn: 0.1847201\ttotal: 32s\tremaining: 4.78s\n",
      "870:\tlearn: 0.1846543\ttotal: 32s\tremaining: 4.74s\n",
      "871:\tlearn: 0.1845091\ttotal: 32.1s\tremaining: 4.71s\n",
      "872:\tlearn: 0.1843771\ttotal: 32.1s\tremaining: 4.67s\n",
      "873:\tlearn: 0.1842956\ttotal: 32.1s\tremaining: 4.63s\n",
      "874:\tlearn: 0.1841543\ttotal: 32.2s\tremaining: 4.59s\n",
      "875:\tlearn: 0.1841204\ttotal: 32.2s\tremaining: 4.56s\n",
      "876:\tlearn: 0.1838857\ttotal: 32.2s\tremaining: 4.52s\n",
      "877:\tlearn: 0.1837924\ttotal: 32.3s\tremaining: 4.48s\n",
      "878:\tlearn: 0.1836872\ttotal: 32.3s\tremaining: 4.45s\n",
      "879:\tlearn: 0.1835485\ttotal: 32.3s\tremaining: 4.41s\n",
      "880:\tlearn: 0.1833711\ttotal: 32.4s\tremaining: 4.37s\n",
      "881:\tlearn: 0.1833073\ttotal: 32.4s\tremaining: 4.34s\n",
      "882:\tlearn: 0.1831330\ttotal: 32.4s\tremaining: 4.3s\n",
      "883:\tlearn: 0.1830167\ttotal: 32.5s\tremaining: 4.26s\n",
      "884:\tlearn: 0.1828716\ttotal: 32.5s\tremaining: 4.23s\n",
      "885:\tlearn: 0.1827539\ttotal: 32.6s\tremaining: 4.19s\n",
      "886:\tlearn: 0.1826994\ttotal: 32.6s\tremaining: 4.15s\n",
      "887:\tlearn: 0.1824943\ttotal: 32.6s\tremaining: 4.12s\n",
      "888:\tlearn: 0.1823970\ttotal: 32.7s\tremaining: 4.08s\n",
      "889:\tlearn: 0.1823348\ttotal: 32.7s\tremaining: 4.04s\n",
      "890:\tlearn: 0.1822758\ttotal: 32.7s\tremaining: 4.01s\n",
      "891:\tlearn: 0.1822145\ttotal: 32.8s\tremaining: 3.97s\n",
      "892:\tlearn: 0.1821315\ttotal: 32.8s\tremaining: 3.93s\n",
      "893:\tlearn: 0.1819383\ttotal: 32.8s\tremaining: 3.89s\n",
      "894:\tlearn: 0.1818841\ttotal: 32.9s\tremaining: 3.86s\n",
      "895:\tlearn: 0.1817324\ttotal: 32.9s\tremaining: 3.82s\n",
      "896:\tlearn: 0.1816653\ttotal: 33s\tremaining: 3.78s\n",
      "897:\tlearn: 0.1815976\ttotal: 33s\tremaining: 3.75s\n",
      "898:\tlearn: 0.1814675\ttotal: 33s\tremaining: 3.71s\n",
      "899:\tlearn: 0.1814253\ttotal: 33.1s\tremaining: 3.67s\n",
      "900:\tlearn: 0.1813168\ttotal: 33.1s\tremaining: 3.63s\n",
      "901:\tlearn: 0.1812215\ttotal: 33.1s\tremaining: 3.6s\n",
      "902:\tlearn: 0.1811811\ttotal: 33.2s\tremaining: 3.56s\n",
      "903:\tlearn: 0.1811107\ttotal: 33.2s\tremaining: 3.53s\n",
      "904:\tlearn: 0.1810276\ttotal: 33.2s\tremaining: 3.49s\n",
      "905:\tlearn: 0.1808916\ttotal: 33.3s\tremaining: 3.45s\n",
      "906:\tlearn: 0.1808504\ttotal: 33.3s\tremaining: 3.42s\n",
      "907:\tlearn: 0.1807362\ttotal: 33.4s\tremaining: 3.38s\n",
      "908:\tlearn: 0.1805539\ttotal: 33.4s\tremaining: 3.34s\n",
      "909:\tlearn: 0.1804614\ttotal: 33.4s\tremaining: 3.31s\n",
      "910:\tlearn: 0.1803911\ttotal: 33.5s\tremaining: 3.27s\n",
      "911:\tlearn: 0.1803038\ttotal: 33.5s\tremaining: 3.23s\n",
      "912:\tlearn: 0.1802465\ttotal: 33.5s\tremaining: 3.19s\n",
      "913:\tlearn: 0.1801348\ttotal: 33.6s\tremaining: 3.16s\n",
      "914:\tlearn: 0.1800047\ttotal: 33.6s\tremaining: 3.12s\n",
      "915:\tlearn: 0.1799039\ttotal: 33.6s\tremaining: 3.08s\n",
      "916:\tlearn: 0.1798724\ttotal: 33.7s\tremaining: 3.05s\n",
      "917:\tlearn: 0.1796581\ttotal: 33.7s\tremaining: 3.01s\n",
      "918:\tlearn: 0.1795294\ttotal: 33.8s\tremaining: 2.98s\n",
      "919:\tlearn: 0.1794741\ttotal: 33.8s\tremaining: 2.94s\n",
      "920:\tlearn: 0.1793601\ttotal: 33.8s\tremaining: 2.9s\n",
      "921:\tlearn: 0.1792692\ttotal: 33.9s\tremaining: 2.86s\n",
      "922:\tlearn: 0.1791884\ttotal: 33.9s\tremaining: 2.83s\n",
      "923:\tlearn: 0.1790669\ttotal: 33.9s\tremaining: 2.79s\n",
      "924:\tlearn: 0.1790140\ttotal: 34s\tremaining: 2.75s\n",
      "925:\tlearn: 0.1788981\ttotal: 34s\tremaining: 2.72s\n",
      "926:\tlearn: 0.1787855\ttotal: 34s\tremaining: 2.68s\n",
      "927:\tlearn: 0.1785711\ttotal: 34.1s\tremaining: 2.64s\n",
      "928:\tlearn: 0.1784324\ttotal: 34.1s\tremaining: 2.61s\n",
      "929:\tlearn: 0.1783076\ttotal: 34.2s\tremaining: 2.57s\n",
      "930:\tlearn: 0.1781791\ttotal: 34.2s\tremaining: 2.53s\n",
      "931:\tlearn: 0.1780856\ttotal: 34.2s\tremaining: 2.5s\n",
      "932:\tlearn: 0.1779534\ttotal: 34.3s\tremaining: 2.46s\n",
      "933:\tlearn: 0.1777413\ttotal: 34.3s\tremaining: 2.42s\n",
      "934:\tlearn: 0.1776073\ttotal: 34.3s\tremaining: 2.39s\n",
      "935:\tlearn: 0.1774401\ttotal: 34.4s\tremaining: 2.35s\n",
      "936:\tlearn: 0.1773882\ttotal: 34.4s\tremaining: 2.31s\n",
      "937:\tlearn: 0.1772787\ttotal: 34.5s\tremaining: 2.28s\n",
      "938:\tlearn: 0.1771925\ttotal: 34.5s\tremaining: 2.24s\n",
      "939:\tlearn: 0.1770617\ttotal: 34.5s\tremaining: 2.2s\n",
      "940:\tlearn: 0.1769805\ttotal: 34.6s\tremaining: 2.17s\n",
      "941:\tlearn: 0.1769307\ttotal: 34.6s\tremaining: 2.13s\n",
      "942:\tlearn: 0.1767798\ttotal: 34.6s\tremaining: 2.09s\n",
      "943:\tlearn: 0.1766089\ttotal: 34.7s\tremaining: 2.06s\n",
      "944:\tlearn: 0.1765438\ttotal: 34.7s\tremaining: 2.02s\n",
      "945:\tlearn: 0.1764587\ttotal: 34.8s\tremaining: 1.98s\n",
      "946:\tlearn: 0.1763983\ttotal: 34.8s\tremaining: 1.95s\n",
      "947:\tlearn: 0.1762850\ttotal: 34.8s\tremaining: 1.91s\n",
      "948:\tlearn: 0.1762233\ttotal: 34.9s\tremaining: 1.87s\n",
      "949:\tlearn: 0.1761089\ttotal: 34.9s\tremaining: 1.84s\n",
      "950:\tlearn: 0.1760219\ttotal: 35s\tremaining: 1.8s\n",
      "951:\tlearn: 0.1759324\ttotal: 35s\tremaining: 1.76s\n",
      "952:\tlearn: 0.1758852\ttotal: 35s\tremaining: 1.73s\n",
      "953:\tlearn: 0.1757618\ttotal: 35.1s\tremaining: 1.69s\n",
      "954:\tlearn: 0.1756614\ttotal: 35.1s\tremaining: 1.65s\n",
      "955:\tlearn: 0.1756316\ttotal: 35.1s\tremaining: 1.62s\n",
      "956:\tlearn: 0.1755423\ttotal: 35.2s\tremaining: 1.58s\n",
      "957:\tlearn: 0.1753814\ttotal: 35.2s\tremaining: 1.54s\n",
      "958:\tlearn: 0.1752094\ttotal: 35.2s\tremaining: 1.51s\n",
      "959:\tlearn: 0.1751087\ttotal: 35.3s\tremaining: 1.47s\n",
      "960:\tlearn: 0.1750023\ttotal: 35.3s\tremaining: 1.43s\n",
      "961:\tlearn: 0.1748763\ttotal: 35.3s\tremaining: 1.4s\n",
      "962:\tlearn: 0.1748227\ttotal: 35.4s\tremaining: 1.36s\n",
      "963:\tlearn: 0.1746744\ttotal: 35.4s\tremaining: 1.32s\n",
      "964:\tlearn: 0.1745547\ttotal: 35.5s\tremaining: 1.29s\n",
      "965:\tlearn: 0.1744486\ttotal: 35.5s\tremaining: 1.25s\n",
      "966:\tlearn: 0.1742589\ttotal: 35.5s\tremaining: 1.21s\n",
      "967:\tlearn: 0.1742247\ttotal: 35.6s\tremaining: 1.18s\n",
      "968:\tlearn: 0.1741223\ttotal: 35.6s\tremaining: 1.14s\n",
      "969:\tlearn: 0.1740233\ttotal: 35.6s\tremaining: 1.1s\n",
      "970:\tlearn: 0.1739069\ttotal: 35.7s\tremaining: 1.06s\n",
      "971:\tlearn: 0.1737987\ttotal: 35.7s\tremaining: 1.03s\n",
      "972:\tlearn: 0.1737103\ttotal: 35.7s\tremaining: 992ms\n",
      "973:\tlearn: 0.1736171\ttotal: 35.8s\tremaining: 955ms\n",
      "974:\tlearn: 0.1735705\ttotal: 35.8s\tremaining: 919ms\n",
      "975:\tlearn: 0.1734801\ttotal: 35.9s\tremaining: 882ms\n",
      "976:\tlearn: 0.1734317\ttotal: 35.9s\tremaining: 845ms\n",
      "977:\tlearn: 0.1733136\ttotal: 35.9s\tremaining: 808ms\n",
      "978:\tlearn: 0.1732487\ttotal: 36s\tremaining: 772ms\n",
      "979:\tlearn: 0.1731178\ttotal: 36s\tremaining: 735ms\n",
      "980:\tlearn: 0.1729269\ttotal: 36s\tremaining: 698ms\n",
      "981:\tlearn: 0.1728806\ttotal: 36.1s\tremaining: 661ms\n",
      "982:\tlearn: 0.1727985\ttotal: 36.1s\tremaining: 625ms\n",
      "983:\tlearn: 0.1727196\ttotal: 36.2s\tremaining: 588ms\n",
      "984:\tlearn: 0.1726699\ttotal: 36.2s\tremaining: 551ms\n",
      "985:\tlearn: 0.1725398\ttotal: 36.2s\tremaining: 514ms\n",
      "986:\tlearn: 0.1724541\ttotal: 36.3s\tremaining: 478ms\n",
      "987:\tlearn: 0.1723224\ttotal: 36.3s\tremaining: 441ms\n",
      "988:\tlearn: 0.1721748\ttotal: 36.4s\tremaining: 404ms\n",
      "989:\tlearn: 0.1720812\ttotal: 36.4s\tremaining: 368ms\n",
      "990:\tlearn: 0.1719258\ttotal: 36.4s\tremaining: 331ms\n",
      "991:\tlearn: 0.1718233\ttotal: 36.5s\tremaining: 294ms\n",
      "992:\tlearn: 0.1715807\ttotal: 36.5s\tremaining: 257ms\n",
      "993:\tlearn: 0.1715059\ttotal: 36.5s\tremaining: 221ms\n",
      "994:\tlearn: 0.1713255\ttotal: 36.6s\tremaining: 184ms\n",
      "995:\tlearn: 0.1711857\ttotal: 36.6s\tremaining: 147ms\n",
      "996:\tlearn: 0.1711137\ttotal: 36.6s\tremaining: 110ms\n",
      "997:\tlearn: 0.1710519\ttotal: 36.7s\tremaining: 73.5ms\n",
      "998:\tlearn: 0.1710112\ttotal: 36.7s\tremaining: 36.8ms\n",
      "999:\tlearn: 0.1708724\ttotal: 36.8s\tremaining: 0us\n",
      "Learning rate set to 0.091926\n",
      "0:\tlearn: 1.8408179\ttotal: 42.4ms\tremaining: 42.3s\n",
      "1:\tlearn: 1.6166781\ttotal: 78.7ms\tremaining: 39.3s\n",
      "2:\tlearn: 1.4648775\ttotal: 113ms\tremaining: 37.6s\n",
      "3:\tlearn: 1.3661645\ttotal: 155ms\tremaining: 38.6s\n",
      "4:\tlearn: 1.2769432\ttotal: 208ms\tremaining: 41.4s\n",
      "5:\tlearn: 1.2113973\ttotal: 244ms\tremaining: 40.4s\n",
      "6:\tlearn: 1.1551449\ttotal: 287ms\tremaining: 40.7s\n",
      "7:\tlearn: 1.0899099\ttotal: 327ms\tremaining: 40.6s\n",
      "8:\tlearn: 1.0322050\ttotal: 363ms\tremaining: 39.9s\n",
      "9:\tlearn: 0.9896682\ttotal: 398ms\tremaining: 39.4s\n",
      "10:\tlearn: 0.9467658\ttotal: 436ms\tremaining: 39.2s\n",
      "11:\tlearn: 0.9129810\ttotal: 487ms\tremaining: 40.1s\n",
      "12:\tlearn: 0.8814210\ttotal: 526ms\tremaining: 39.9s\n",
      "13:\tlearn: 0.8516527\ttotal: 564ms\tremaining: 39.7s\n",
      "14:\tlearn: 0.8262498\ttotal: 606ms\tremaining: 39.8s\n",
      "15:\tlearn: 0.8063042\ttotal: 640ms\tremaining: 39.3s\n",
      "16:\tlearn: 0.7812504\ttotal: 676ms\tremaining: 39.1s\n",
      "17:\tlearn: 0.7599468\ttotal: 712ms\tremaining: 38.9s\n",
      "18:\tlearn: 0.7449480\ttotal: 751ms\tremaining: 38.8s\n",
      "19:\tlearn: 0.7272726\ttotal: 795ms\tremaining: 39s\n",
      "20:\tlearn: 0.7096772\ttotal: 840ms\tremaining: 39.2s\n",
      "21:\tlearn: 0.6957784\ttotal: 882ms\tremaining: 39.2s\n",
      "22:\tlearn: 0.6792673\ttotal: 919ms\tremaining: 39s\n",
      "23:\tlearn: 0.6680812\ttotal: 952ms\tremaining: 38.7s\n",
      "24:\tlearn: 0.6554625\ttotal: 986ms\tremaining: 38.5s\n",
      "25:\tlearn: 0.6445771\ttotal: 1.02s\tremaining: 38.2s\n",
      "26:\tlearn: 0.6359297\ttotal: 1.07s\tremaining: 38.5s\n",
      "27:\tlearn: 0.6276540\ttotal: 1.11s\tremaining: 38.5s\n",
      "28:\tlearn: 0.6185050\ttotal: 1.14s\tremaining: 38.2s\n",
      "29:\tlearn: 0.6100098\ttotal: 1.18s\tremaining: 38s\n",
      "30:\tlearn: 0.6004632\ttotal: 1.21s\tremaining: 37.8s\n",
      "31:\tlearn: 0.5931202\ttotal: 1.24s\tremaining: 37.6s\n",
      "32:\tlearn: 0.5839621\ttotal: 1.28s\tremaining: 37.4s\n",
      "33:\tlearn: 0.5763389\ttotal: 1.32s\tremaining: 37.4s\n",
      "34:\tlearn: 0.5693733\ttotal: 1.35s\tremaining: 37.3s\n",
      "35:\tlearn: 0.5636679\ttotal: 1.38s\tremaining: 37s\n",
      "36:\tlearn: 0.5572967\ttotal: 1.42s\tremaining: 36.9s\n",
      "37:\tlearn: 0.5509667\ttotal: 1.45s\tremaining: 36.7s\n",
      "38:\tlearn: 0.5452532\ttotal: 1.5s\tremaining: 36.9s\n",
      "39:\tlearn: 0.5404127\ttotal: 1.54s\tremaining: 36.9s\n",
      "40:\tlearn: 0.5368722\ttotal: 1.58s\tremaining: 36.9s\n",
      "41:\tlearn: 0.5311988\ttotal: 1.62s\tremaining: 36.9s\n",
      "42:\tlearn: 0.5260580\ttotal: 1.65s\tremaining: 36.8s\n",
      "43:\tlearn: 0.5226259\ttotal: 1.69s\tremaining: 36.7s\n",
      "44:\tlearn: 0.5180908\ttotal: 1.72s\tremaining: 36.5s\n",
      "45:\tlearn: 0.5128821\ttotal: 1.75s\tremaining: 36.4s\n",
      "46:\tlearn: 0.5074585\ttotal: 1.81s\tremaining: 36.8s\n",
      "47:\tlearn: 0.5033712\ttotal: 1.85s\tremaining: 36.7s\n",
      "48:\tlearn: 0.5007533\ttotal: 1.89s\tremaining: 36.7s\n",
      "49:\tlearn: 0.4951830\ttotal: 1.93s\tremaining: 36.6s\n",
      "50:\tlearn: 0.4908046\ttotal: 1.96s\tremaining: 36.5s\n",
      "51:\tlearn: 0.4879240\ttotal: 2s\tremaining: 36.4s\n",
      "52:\tlearn: 0.4843307\ttotal: 2.03s\tremaining: 36.3s\n",
      "53:\tlearn: 0.4824340\ttotal: 2.06s\tremaining: 36.2s\n",
      "54:\tlearn: 0.4805182\ttotal: 2.11s\tremaining: 36.2s\n",
      "55:\tlearn: 0.4777819\ttotal: 2.14s\tremaining: 36.1s\n",
      "56:\tlearn: 0.4755354\ttotal: 2.18s\tremaining: 36.1s\n",
      "57:\tlearn: 0.4714836\ttotal: 2.22s\tremaining: 36.1s\n",
      "58:\tlearn: 0.4697593\ttotal: 2.26s\tremaining: 36s\n",
      "59:\tlearn: 0.4674739\ttotal: 2.29s\tremaining: 35.9s\n",
      "60:\tlearn: 0.4655123\ttotal: 2.32s\tremaining: 35.8s\n",
      "61:\tlearn: 0.4630789\ttotal: 2.36s\tremaining: 35.6s\n",
      "62:\tlearn: 0.4607906\ttotal: 2.39s\tremaining: 35.6s\n",
      "63:\tlearn: 0.4583108\ttotal: 2.43s\tremaining: 35.5s\n",
      "64:\tlearn: 0.4563736\ttotal: 2.48s\tremaining: 35.6s\n",
      "65:\tlearn: 0.4550032\ttotal: 2.52s\tremaining: 35.6s\n",
      "66:\tlearn: 0.4523388\ttotal: 2.55s\tremaining: 35.5s\n",
      "67:\tlearn: 0.4496028\ttotal: 2.58s\tremaining: 35.4s\n",
      "68:\tlearn: 0.4472674\ttotal: 2.62s\tremaining: 35.3s\n",
      "69:\tlearn: 0.4450688\ttotal: 2.65s\tremaining: 35.2s\n",
      "70:\tlearn: 0.4426365\ttotal: 2.7s\tremaining: 35.3s\n",
      "71:\tlearn: 0.4409844\ttotal: 2.73s\tremaining: 35.2s\n",
      "72:\tlearn: 0.4395107\ttotal: 2.76s\tremaining: 35.1s\n",
      "73:\tlearn: 0.4380523\ttotal: 2.8s\tremaining: 35s\n",
      "74:\tlearn: 0.4359434\ttotal: 2.83s\tremaining: 34.9s\n",
      "75:\tlearn: 0.4347143\ttotal: 2.87s\tremaining: 34.9s\n",
      "76:\tlearn: 0.4316851\ttotal: 2.91s\tremaining: 34.9s\n",
      "77:\tlearn: 0.4303578\ttotal: 2.95s\tremaining: 34.9s\n",
      "78:\tlearn: 0.4269546\ttotal: 2.99s\tremaining: 34.8s\n",
      "79:\tlearn: 0.4256768\ttotal: 3.02s\tremaining: 34.7s\n",
      "80:\tlearn: 0.4244292\ttotal: 3.05s\tremaining: 34.6s\n",
      "81:\tlearn: 0.4232735\ttotal: 3.08s\tremaining: 34.5s\n",
      "82:\tlearn: 0.4215975\ttotal: 3.12s\tremaining: 34.4s\n",
      "83:\tlearn: 0.4196423\ttotal: 3.15s\tremaining: 34.4s\n",
      "84:\tlearn: 0.4180011\ttotal: 3.18s\tremaining: 34.3s\n",
      "85:\tlearn: 0.4170441\ttotal: 3.23s\tremaining: 34.3s\n",
      "86:\tlearn: 0.4154415\ttotal: 3.26s\tremaining: 34.2s\n",
      "87:\tlearn: 0.4132686\ttotal: 3.29s\tremaining: 34.2s\n",
      "88:\tlearn: 0.4121196\ttotal: 3.33s\tremaining: 34.1s\n",
      "89:\tlearn: 0.4102379\ttotal: 3.36s\tremaining: 34s\n",
      "90:\tlearn: 0.4084455\ttotal: 3.4s\tremaining: 33.9s\n",
      "91:\tlearn: 0.4067926\ttotal: 3.45s\tremaining: 34s\n",
      "92:\tlearn: 0.4057808\ttotal: 3.48s\tremaining: 34s\n",
      "93:\tlearn: 0.4051493\ttotal: 3.52s\tremaining: 33.9s\n",
      "94:\tlearn: 0.4045094\ttotal: 3.55s\tremaining: 33.8s\n",
      "95:\tlearn: 0.4033046\ttotal: 3.58s\tremaining: 33.7s\n",
      "96:\tlearn: 0.4018973\ttotal: 3.61s\tremaining: 33.6s\n",
      "97:\tlearn: 0.4007574\ttotal: 3.65s\tremaining: 33.6s\n",
      "98:\tlearn: 0.3996978\ttotal: 3.69s\tremaining: 33.6s\n",
      "99:\tlearn: 0.3988642\ttotal: 3.73s\tremaining: 33.5s\n",
      "100:\tlearn: 0.3969069\ttotal: 3.76s\tremaining: 33.5s\n",
      "101:\tlearn: 0.3955071\ttotal: 3.8s\tremaining: 33.4s\n",
      "102:\tlearn: 0.3937609\ttotal: 3.83s\tremaining: 33.4s\n",
      "103:\tlearn: 0.3928632\ttotal: 3.87s\tremaining: 33.3s\n",
      "104:\tlearn: 0.3914464\ttotal: 3.9s\tremaining: 33.3s\n",
      "105:\tlearn: 0.3902321\ttotal: 3.95s\tremaining: 33.3s\n",
      "106:\tlearn: 0.3894726\ttotal: 3.98s\tremaining: 33.3s\n",
      "107:\tlearn: 0.3888013\ttotal: 4.02s\tremaining: 33.2s\n",
      "108:\tlearn: 0.3882619\ttotal: 4.05s\tremaining: 33.1s\n",
      "109:\tlearn: 0.3873415\ttotal: 4.08s\tremaining: 33s\n",
      "110:\tlearn: 0.3861666\ttotal: 4.12s\tremaining: 33s\n",
      "111:\tlearn: 0.3851517\ttotal: 4.16s\tremaining: 33s\n",
      "112:\tlearn: 0.3834569\ttotal: 4.2s\tremaining: 33s\n",
      "113:\tlearn: 0.3829544\ttotal: 4.23s\tremaining: 32.9s\n",
      "114:\tlearn: 0.3825564\ttotal: 4.26s\tremaining: 32.8s\n",
      "115:\tlearn: 0.3818229\ttotal: 4.29s\tremaining: 32.7s\n",
      "116:\tlearn: 0.3813673\ttotal: 4.32s\tremaining: 32.6s\n",
      "117:\tlearn: 0.3801553\ttotal: 4.36s\tremaining: 32.6s\n",
      "118:\tlearn: 0.3795792\ttotal: 4.4s\tremaining: 32.6s\n",
      "119:\tlearn: 0.3790955\ttotal: 4.44s\tremaining: 32.6s\n",
      "120:\tlearn: 0.3780191\ttotal: 4.48s\tremaining: 32.5s\n",
      "121:\tlearn: 0.3765481\ttotal: 4.51s\tremaining: 32.4s\n",
      "122:\tlearn: 0.3757548\ttotal: 4.54s\tremaining: 32.4s\n",
      "123:\tlearn: 0.3753728\ttotal: 4.57s\tremaining: 32.3s\n",
      "124:\tlearn: 0.3743343\ttotal: 4.6s\tremaining: 32.2s\n",
      "125:\tlearn: 0.3738903\ttotal: 4.63s\tremaining: 32.1s\n",
      "126:\tlearn: 0.3726566\ttotal: 4.67s\tremaining: 32.1s\n",
      "127:\tlearn: 0.3715379\ttotal: 4.71s\tremaining: 32.1s\n",
      "128:\tlearn: 0.3706333\ttotal: 4.75s\tremaining: 32.1s\n",
      "129:\tlearn: 0.3698094\ttotal: 4.78s\tremaining: 32s\n",
      "130:\tlearn: 0.3684733\ttotal: 4.81s\tremaining: 31.9s\n",
      "131:\tlearn: 0.3676108\ttotal: 4.84s\tremaining: 31.9s\n",
      "132:\tlearn: 0.3666013\ttotal: 4.88s\tremaining: 31.8s\n",
      "133:\tlearn: 0.3657873\ttotal: 4.93s\tremaining: 31.9s\n",
      "134:\tlearn: 0.3653717\ttotal: 4.97s\tremaining: 31.8s\n",
      "135:\tlearn: 0.3643753\ttotal: 5s\tremaining: 31.8s\n",
      "136:\tlearn: 0.3636121\ttotal: 5.03s\tremaining: 31.7s\n",
      "137:\tlearn: 0.3628741\ttotal: 5.07s\tremaining: 31.6s\n",
      "138:\tlearn: 0.3619833\ttotal: 5.1s\tremaining: 31.6s\n",
      "139:\tlearn: 0.3616511\ttotal: 5.13s\tremaining: 31.5s\n",
      "140:\tlearn: 0.3608230\ttotal: 5.17s\tremaining: 31.5s\n",
      "141:\tlearn: 0.3597578\ttotal: 5.21s\tremaining: 31.5s\n",
      "142:\tlearn: 0.3593238\ttotal: 5.24s\tremaining: 31.4s\n",
      "143:\tlearn: 0.3587632\ttotal: 5.28s\tremaining: 31.4s\n",
      "144:\tlearn: 0.3584515\ttotal: 5.31s\tremaining: 31.3s\n",
      "145:\tlearn: 0.3579278\ttotal: 5.34s\tremaining: 31.2s\n",
      "146:\tlearn: 0.3574111\ttotal: 5.38s\tremaining: 31.2s\n",
      "147:\tlearn: 0.3569223\ttotal: 5.41s\tremaining: 31.2s\n",
      "148:\tlearn: 0.3560105\ttotal: 5.47s\tremaining: 31.2s\n",
      "149:\tlearn: 0.3555799\ttotal: 5.5s\tremaining: 31.2s\n",
      "150:\tlearn: 0.3551266\ttotal: 5.53s\tremaining: 31.1s\n",
      "151:\tlearn: 0.3548446\ttotal: 5.56s\tremaining: 31s\n",
      "152:\tlearn: 0.3545095\ttotal: 5.59s\tremaining: 31s\n",
      "153:\tlearn: 0.3535767\ttotal: 5.63s\tremaining: 30.9s\n",
      "154:\tlearn: 0.3527704\ttotal: 5.67s\tremaining: 30.9s\n",
      "155:\tlearn: 0.3525633\ttotal: 5.7s\tremaining: 30.9s\n",
      "156:\tlearn: 0.3521168\ttotal: 5.74s\tremaining: 30.8s\n",
      "157:\tlearn: 0.3514620\ttotal: 5.77s\tremaining: 30.8s\n",
      "158:\tlearn: 0.3508024\ttotal: 5.8s\tremaining: 30.7s\n",
      "159:\tlearn: 0.3501489\ttotal: 5.84s\tremaining: 30.6s\n",
      "160:\tlearn: 0.3490809\ttotal: 5.88s\tremaining: 30.6s\n",
      "161:\tlearn: 0.3487872\ttotal: 5.91s\tremaining: 30.6s\n",
      "162:\tlearn: 0.3477888\ttotal: 5.97s\tremaining: 30.6s\n",
      "163:\tlearn: 0.3474967\ttotal: 6s\tremaining: 30.6s\n",
      "164:\tlearn: 0.3467049\ttotal: 6.04s\tremaining: 30.5s\n",
      "165:\tlearn: 0.3461204\ttotal: 6.07s\tremaining: 30.5s\n",
      "166:\tlearn: 0.3453084\ttotal: 6.1s\tremaining: 30.4s\n",
      "167:\tlearn: 0.3446782\ttotal: 6.13s\tremaining: 30.4s\n",
      "168:\tlearn: 0.3441592\ttotal: 6.17s\tremaining: 30.3s\n",
      "169:\tlearn: 0.3437838\ttotal: 6.2s\tremaining: 30.3s\n",
      "170:\tlearn: 0.3429218\ttotal: 6.24s\tremaining: 30.3s\n",
      "171:\tlearn: 0.3422674\ttotal: 6.28s\tremaining: 30.2s\n",
      "172:\tlearn: 0.3419122\ttotal: 6.31s\tremaining: 30.2s\n",
      "173:\tlearn: 0.3411636\ttotal: 6.34s\tremaining: 30.1s\n",
      "174:\tlearn: 0.3402029\ttotal: 6.38s\tremaining: 30.1s\n",
      "175:\tlearn: 0.3398803\ttotal: 6.41s\tremaining: 30s\n",
      "176:\tlearn: 0.3388240\ttotal: 6.46s\tremaining: 30s\n",
      "177:\tlearn: 0.3381730\ttotal: 6.5s\tremaining: 30s\n",
      "178:\tlearn: 0.3371982\ttotal: 6.54s\tremaining: 30s\n",
      "179:\tlearn: 0.3370689\ttotal: 6.57s\tremaining: 29.9s\n",
      "180:\tlearn: 0.3362288\ttotal: 6.6s\tremaining: 29.9s\n",
      "181:\tlearn: 0.3351953\ttotal: 6.64s\tremaining: 29.8s\n",
      "182:\tlearn: 0.3349918\ttotal: 6.67s\tremaining: 29.8s\n",
      "183:\tlearn: 0.3345756\ttotal: 6.7s\tremaining: 29.7s\n",
      "184:\tlearn: 0.3338327\ttotal: 6.74s\tremaining: 29.7s\n",
      "185:\tlearn: 0.3332992\ttotal: 6.78s\tremaining: 29.7s\n",
      "186:\tlearn: 0.3329594\ttotal: 6.82s\tremaining: 29.6s\n",
      "187:\tlearn: 0.3324646\ttotal: 6.85s\tremaining: 29.6s\n",
      "188:\tlearn: 0.3321259\ttotal: 6.88s\tremaining: 29.5s\n",
      "189:\tlearn: 0.3317858\ttotal: 6.91s\tremaining: 29.5s\n",
      "190:\tlearn: 0.3307662\ttotal: 6.95s\tremaining: 29.4s\n",
      "191:\tlearn: 0.3300745\ttotal: 7s\tremaining: 29.4s\n",
      "192:\tlearn: 0.3293408\ttotal: 7.04s\tremaining: 29.4s\n",
      "193:\tlearn: 0.3287002\ttotal: 7.07s\tremaining: 29.4s\n",
      "194:\tlearn: 0.3281132\ttotal: 7.1s\tremaining: 29.3s\n",
      "195:\tlearn: 0.3276687\ttotal: 7.13s\tremaining: 29.3s\n",
      "196:\tlearn: 0.3273887\ttotal: 7.17s\tremaining: 29.2s\n",
      "197:\tlearn: 0.3271687\ttotal: 7.2s\tremaining: 29.2s\n",
      "198:\tlearn: 0.3269433\ttotal: 7.24s\tremaining: 29.1s\n",
      "199:\tlearn: 0.3266397\ttotal: 7.28s\tremaining: 29.1s\n",
      "200:\tlearn: 0.3264147\ttotal: 7.31s\tremaining: 29.1s\n",
      "201:\tlearn: 0.3257195\ttotal: 7.34s\tremaining: 29s\n",
      "202:\tlearn: 0.3251471\ttotal: 7.37s\tremaining: 28.9s\n",
      "203:\tlearn: 0.3249915\ttotal: 7.4s\tremaining: 28.9s\n",
      "204:\tlearn: 0.3244376\ttotal: 7.44s\tremaining: 28.8s\n",
      "205:\tlearn: 0.3241256\ttotal: 7.47s\tremaining: 28.8s\n",
      "206:\tlearn: 0.3239686\ttotal: 7.51s\tremaining: 28.8s\n",
      "207:\tlearn: 0.3237047\ttotal: 7.55s\tremaining: 28.8s\n",
      "208:\tlearn: 0.3230435\ttotal: 7.59s\tremaining: 28.7s\n",
      "209:\tlearn: 0.3226254\ttotal: 7.62s\tremaining: 28.7s\n",
      "210:\tlearn: 0.3223931\ttotal: 7.65s\tremaining: 28.6s\n",
      "211:\tlearn: 0.3220726\ttotal: 7.68s\tremaining: 28.6s\n",
      "212:\tlearn: 0.3214550\ttotal: 7.72s\tremaining: 28.5s\n",
      "213:\tlearn: 0.3212079\ttotal: 7.75s\tremaining: 28.5s\n",
      "214:\tlearn: 0.3205754\ttotal: 7.79s\tremaining: 28.4s\n",
      "215:\tlearn: 0.3199471\ttotal: 7.83s\tremaining: 28.4s\n",
      "216:\tlearn: 0.3197946\ttotal: 7.86s\tremaining: 28.4s\n",
      "217:\tlearn: 0.3193466\ttotal: 7.89s\tremaining: 28.3s\n",
      "218:\tlearn: 0.3192407\ttotal: 7.92s\tremaining: 28.3s\n",
      "219:\tlearn: 0.3186370\ttotal: 7.96s\tremaining: 28.2s\n",
      "220:\tlearn: 0.3181285\ttotal: 7.99s\tremaining: 28.2s\n",
      "221:\tlearn: 0.3177871\ttotal: 8.03s\tremaining: 28.1s\n",
      "222:\tlearn: 0.3174981\ttotal: 8.07s\tremaining: 28.1s\n",
      "223:\tlearn: 0.3169496\ttotal: 8.11s\tremaining: 28.1s\n",
      "224:\tlearn: 0.3166712\ttotal: 8.14s\tremaining: 28s\n",
      "225:\tlearn: 0.3165157\ttotal: 8.18s\tremaining: 28s\n",
      "226:\tlearn: 0.3163216\ttotal: 8.22s\tremaining: 28s\n",
      "227:\tlearn: 0.3161305\ttotal: 8.26s\tremaining: 28s\n",
      "228:\tlearn: 0.3157333\ttotal: 8.29s\tremaining: 27.9s\n",
      "229:\tlearn: 0.3153041\ttotal: 8.32s\tremaining: 27.9s\n",
      "230:\tlearn: 0.3149218\ttotal: 8.35s\tremaining: 27.8s\n",
      "231:\tlearn: 0.3147813\ttotal: 8.4s\tremaining: 27.8s\n",
      "232:\tlearn: 0.3143343\ttotal: 8.44s\tremaining: 27.8s\n",
      "233:\tlearn: 0.3138630\ttotal: 8.48s\tremaining: 27.8s\n",
      "234:\tlearn: 0.3135770\ttotal: 8.51s\tremaining: 27.7s\n",
      "235:\tlearn: 0.3131978\ttotal: 8.54s\tremaining: 27.7s\n",
      "236:\tlearn: 0.3131113\ttotal: 8.58s\tremaining: 27.6s\n",
      "237:\tlearn: 0.3130710\ttotal: 8.61s\tremaining: 27.6s\n",
      "238:\tlearn: 0.3128010\ttotal: 8.64s\tremaining: 27.5s\n",
      "239:\tlearn: 0.3123614\ttotal: 8.68s\tremaining: 27.5s\n",
      "240:\tlearn: 0.3118125\ttotal: 8.71s\tremaining: 27.4s\n",
      "241:\tlearn: 0.3117121\ttotal: 8.75s\tremaining: 27.4s\n",
      "242:\tlearn: 0.3115087\ttotal: 8.79s\tremaining: 27.4s\n",
      "243:\tlearn: 0.3111102\ttotal: 8.82s\tremaining: 27.3s\n",
      "244:\tlearn: 0.3105633\ttotal: 8.85s\tremaining: 27.3s\n",
      "245:\tlearn: 0.3104571\ttotal: 8.88s\tremaining: 27.2s\n",
      "246:\tlearn: 0.3101999\ttotal: 8.93s\tremaining: 27.2s\n",
      "247:\tlearn: 0.3099123\ttotal: 8.97s\tremaining: 27.2s\n",
      "248:\tlearn: 0.3095835\ttotal: 9s\tremaining: 27.2s\n",
      "249:\tlearn: 0.3092186\ttotal: 9.04s\tremaining: 27.1s\n",
      "250:\tlearn: 0.3089573\ttotal: 9.07s\tremaining: 27.1s\n",
      "251:\tlearn: 0.3083510\ttotal: 9.1s\tremaining: 27s\n",
      "252:\tlearn: 0.3080382\ttotal: 9.13s\tremaining: 27s\n",
      "253:\tlearn: 0.3076337\ttotal: 9.17s\tremaining: 26.9s\n",
      "254:\tlearn: 0.3072113\ttotal: 9.21s\tremaining: 26.9s\n",
      "255:\tlearn: 0.3069368\ttotal: 9.25s\tremaining: 26.9s\n",
      "256:\tlearn: 0.3068027\ttotal: 9.28s\tremaining: 26.8s\n",
      "257:\tlearn: 0.3064842\ttotal: 9.31s\tremaining: 26.8s\n",
      "258:\tlearn: 0.3062858\ttotal: 9.34s\tremaining: 26.7s\n",
      "259:\tlearn: 0.3059088\ttotal: 9.37s\tremaining: 26.7s\n",
      "260:\tlearn: 0.3057874\ttotal: 9.42s\tremaining: 26.7s\n",
      "261:\tlearn: 0.3051995\ttotal: 9.47s\tremaining: 26.7s\n",
      "262:\tlearn: 0.3047253\ttotal: 9.5s\tremaining: 26.6s\n",
      "263:\tlearn: 0.3044612\ttotal: 9.54s\tremaining: 26.6s\n",
      "264:\tlearn: 0.3040667\ttotal: 9.57s\tremaining: 26.5s\n",
      "265:\tlearn: 0.3039445\ttotal: 9.6s\tremaining: 26.5s\n",
      "266:\tlearn: 0.3034439\ttotal: 9.63s\tremaining: 26.5s\n",
      "267:\tlearn: 0.3032269\ttotal: 9.67s\tremaining: 26.4s\n",
      "268:\tlearn: 0.3030760\ttotal: 9.71s\tremaining: 26.4s\n",
      "269:\tlearn: 0.3026458\ttotal: 9.75s\tremaining: 26.4s\n",
      "270:\tlearn: 0.3024482\ttotal: 9.78s\tremaining: 26.3s\n",
      "271:\tlearn: 0.3018666\ttotal: 9.81s\tremaining: 26.3s\n",
      "272:\tlearn: 0.3012752\ttotal: 9.85s\tremaining: 26.2s\n",
      "273:\tlearn: 0.3010449\ttotal: 9.88s\tremaining: 26.2s\n",
      "274:\tlearn: 0.3008407\ttotal: 9.92s\tremaining: 26.1s\n",
      "275:\tlearn: 0.3005872\ttotal: 9.96s\tremaining: 26.1s\n",
      "276:\tlearn: 0.3001258\ttotal: 10s\tremaining: 26.1s\n",
      "277:\tlearn: 0.2996067\ttotal: 10s\tremaining: 26s\n",
      "278:\tlearn: 0.2989942\ttotal: 10.1s\tremaining: 26s\n",
      "279:\tlearn: 0.2987243\ttotal: 10.1s\tremaining: 26s\n",
      "280:\tlearn: 0.2984406\ttotal: 10.1s\tremaining: 25.9s\n",
      "281:\tlearn: 0.2981715\ttotal: 10.2s\tremaining: 25.9s\n",
      "282:\tlearn: 0.2978755\ttotal: 10.2s\tremaining: 25.9s\n",
      "283:\tlearn: 0.2974442\ttotal: 10.2s\tremaining: 25.8s\n",
      "284:\tlearn: 0.2970210\ttotal: 10.3s\tremaining: 25.8s\n",
      "285:\tlearn: 0.2966139\ttotal: 10.3s\tremaining: 25.7s\n",
      "286:\tlearn: 0.2963855\ttotal: 10.3s\tremaining: 25.7s\n",
      "287:\tlearn: 0.2960673\ttotal: 10.4s\tremaining: 25.7s\n",
      "288:\tlearn: 0.2957906\ttotal: 10.4s\tremaining: 25.6s\n",
      "289:\tlearn: 0.2954204\ttotal: 10.4s\tremaining: 25.6s\n",
      "290:\tlearn: 0.2948538\ttotal: 10.5s\tremaining: 25.5s\n",
      "291:\tlearn: 0.2944784\ttotal: 10.5s\tremaining: 25.5s\n",
      "292:\tlearn: 0.2941353\ttotal: 10.5s\tremaining: 25.4s\n",
      "293:\tlearn: 0.2938696\ttotal: 10.6s\tremaining: 25.4s\n",
      "294:\tlearn: 0.2937020\ttotal: 10.6s\tremaining: 25.4s\n",
      "295:\tlearn: 0.2930554\ttotal: 10.7s\tremaining: 25.3s\n",
      "296:\tlearn: 0.2926240\ttotal: 10.7s\tremaining: 25.3s\n",
      "297:\tlearn: 0.2923511\ttotal: 10.7s\tremaining: 25.3s\n",
      "298:\tlearn: 0.2921703\ttotal: 10.8s\tremaining: 25.2s\n",
      "299:\tlearn: 0.2916927\ttotal: 10.8s\tremaining: 25.2s\n",
      "300:\tlearn: 0.2914734\ttotal: 10.8s\tremaining: 25.1s\n",
      "301:\tlearn: 0.2912449\ttotal: 10.9s\tremaining: 25.1s\n",
      "302:\tlearn: 0.2907410\ttotal: 10.9s\tremaining: 25.1s\n",
      "303:\tlearn: 0.2901994\ttotal: 11s\tremaining: 25.1s\n",
      "304:\tlearn: 0.2900191\ttotal: 11s\tremaining: 25s\n",
      "305:\tlearn: 0.2896020\ttotal: 11s\tremaining: 25s\n",
      "306:\tlearn: 0.2890900\ttotal: 11.1s\tremaining: 25s\n",
      "307:\tlearn: 0.2889198\ttotal: 11.1s\tremaining: 24.9s\n",
      "308:\tlearn: 0.2882747\ttotal: 11.1s\tremaining: 24.9s\n",
      "309:\tlearn: 0.2881654\ttotal: 11.2s\tremaining: 24.9s\n",
      "310:\tlearn: 0.2875723\ttotal: 11.2s\tremaining: 24.8s\n",
      "311:\tlearn: 0.2871647\ttotal: 11.3s\tremaining: 24.8s\n",
      "312:\tlearn: 0.2867923\ttotal: 11.3s\tremaining: 24.8s\n",
      "313:\tlearn: 0.2865135\ttotal: 11.3s\tremaining: 24.7s\n",
      "314:\tlearn: 0.2861106\ttotal: 11.4s\tremaining: 24.7s\n",
      "315:\tlearn: 0.2856301\ttotal: 11.4s\tremaining: 24.7s\n",
      "316:\tlearn: 0.2854187\ttotal: 11.4s\tremaining: 24.6s\n",
      "317:\tlearn: 0.2851412\ttotal: 11.5s\tremaining: 24.6s\n",
      "318:\tlearn: 0.2847807\ttotal: 11.5s\tremaining: 24.5s\n",
      "319:\tlearn: 0.2845333\ttotal: 11.5s\tremaining: 24.5s\n",
      "320:\tlearn: 0.2838979\ttotal: 11.6s\tremaining: 24.5s\n",
      "321:\tlearn: 0.2835788\ttotal: 11.6s\tremaining: 24.4s\n",
      "322:\tlearn: 0.2833870\ttotal: 11.6s\tremaining: 24.4s\n",
      "323:\tlearn: 0.2825939\ttotal: 11.7s\tremaining: 24.3s\n",
      "324:\tlearn: 0.2824085\ttotal: 11.7s\tremaining: 24.3s\n",
      "325:\tlearn: 0.2822855\ttotal: 11.7s\tremaining: 24.3s\n",
      "326:\tlearn: 0.2820389\ttotal: 11.8s\tremaining: 24.2s\n",
      "327:\tlearn: 0.2818680\ttotal: 11.8s\tremaining: 24.2s\n",
      "328:\tlearn: 0.2813980\ttotal: 11.9s\tremaining: 24.2s\n",
      "329:\tlearn: 0.2811526\ttotal: 11.9s\tremaining: 24.1s\n",
      "330:\tlearn: 0.2809565\ttotal: 11.9s\tremaining: 24.1s\n",
      "331:\tlearn: 0.2805496\ttotal: 12s\tremaining: 24.1s\n",
      "332:\tlearn: 0.2803828\ttotal: 12s\tremaining: 24s\n",
      "333:\tlearn: 0.2800266\ttotal: 12s\tremaining: 24s\n",
      "334:\tlearn: 0.2797369\ttotal: 12.1s\tremaining: 24s\n",
      "335:\tlearn: 0.2794224\ttotal: 12.1s\tremaining: 23.9s\n",
      "336:\tlearn: 0.2792721\ttotal: 12.2s\tremaining: 23.9s\n",
      "337:\tlearn: 0.2788367\ttotal: 12.2s\tremaining: 23.9s\n",
      "338:\tlearn: 0.2785047\ttotal: 12.2s\tremaining: 23.8s\n",
      "339:\tlearn: 0.2782459\ttotal: 12.3s\tremaining: 23.8s\n",
      "340:\tlearn: 0.2778853\ttotal: 12.3s\tremaining: 23.8s\n",
      "341:\tlearn: 0.2776813\ttotal: 12.3s\tremaining: 23.7s\n",
      "342:\tlearn: 0.2772054\ttotal: 12.4s\tremaining: 23.7s\n",
      "343:\tlearn: 0.2769523\ttotal: 12.4s\tremaining: 23.6s\n",
      "344:\tlearn: 0.2764652\ttotal: 12.4s\tremaining: 23.6s\n",
      "345:\tlearn: 0.2760852\ttotal: 12.5s\tremaining: 23.6s\n",
      "346:\tlearn: 0.2757296\ttotal: 12.5s\tremaining: 23.5s\n",
      "347:\tlearn: 0.2754173\ttotal: 12.5s\tremaining: 23.5s\n",
      "348:\tlearn: 0.2751790\ttotal: 12.6s\tremaining: 23.4s\n",
      "349:\tlearn: 0.2749603\ttotal: 12.6s\tremaining: 23.4s\n",
      "350:\tlearn: 0.2747752\ttotal: 12.6s\tremaining: 23.4s\n",
      "351:\tlearn: 0.2745209\ttotal: 12.7s\tremaining: 23.3s\n",
      "352:\tlearn: 0.2743854\ttotal: 12.7s\tremaining: 23.3s\n",
      "353:\tlearn: 0.2739006\ttotal: 12.8s\tremaining: 23.3s\n",
      "354:\tlearn: 0.2736407\ttotal: 12.8s\tremaining: 23.3s\n",
      "355:\tlearn: 0.2734099\ttotal: 12.8s\tremaining: 23.2s\n",
      "356:\tlearn: 0.2729651\ttotal: 12.9s\tremaining: 23.2s\n",
      "357:\tlearn: 0.2728000\ttotal: 12.9s\tremaining: 23.1s\n",
      "358:\tlearn: 0.2726560\ttotal: 12.9s\tremaining: 23.1s\n",
      "359:\tlearn: 0.2721849\ttotal: 13s\tremaining: 23.1s\n",
      "360:\tlearn: 0.2717749\ttotal: 13s\tremaining: 23s\n",
      "361:\tlearn: 0.2713830\ttotal: 13.1s\tremaining: 23s\n",
      "362:\tlearn: 0.2711421\ttotal: 13.1s\tremaining: 23s\n",
      "363:\tlearn: 0.2708552\ttotal: 13.1s\tremaining: 22.9s\n",
      "364:\tlearn: 0.2707390\ttotal: 13.1s\tremaining: 22.9s\n",
      "365:\tlearn: 0.2704180\ttotal: 13.2s\tremaining: 22.8s\n",
      "366:\tlearn: 0.2702312\ttotal: 13.2s\tremaining: 22.8s\n",
      "367:\tlearn: 0.2700838\ttotal: 13.3s\tremaining: 22.8s\n",
      "368:\tlearn: 0.2699660\ttotal: 13.3s\tremaining: 22.8s\n",
      "369:\tlearn: 0.2698084\ttotal: 13.3s\tremaining: 22.7s\n",
      "370:\tlearn: 0.2695981\ttotal: 13.4s\tremaining: 22.7s\n",
      "371:\tlearn: 0.2694770\ttotal: 13.4s\tremaining: 22.6s\n",
      "372:\tlearn: 0.2693869\ttotal: 13.4s\tremaining: 22.6s\n",
      "373:\tlearn: 0.2692891\ttotal: 13.5s\tremaining: 22.5s\n",
      "374:\tlearn: 0.2691869\ttotal: 13.5s\tremaining: 22.5s\n",
      "375:\tlearn: 0.2688208\ttotal: 13.5s\tremaining: 22.5s\n",
      "376:\tlearn: 0.2687141\ttotal: 13.6s\tremaining: 22.4s\n",
      "377:\tlearn: 0.2684556\ttotal: 13.6s\tremaining: 22.4s\n",
      "378:\tlearn: 0.2682968\ttotal: 13.6s\tremaining: 22.4s\n",
      "379:\tlearn: 0.2682026\ttotal: 13.7s\tremaining: 22.3s\n",
      "380:\tlearn: 0.2681121\ttotal: 13.7s\tremaining: 22.3s\n",
      "381:\tlearn: 0.2677043\ttotal: 13.7s\tremaining: 22.2s\n",
      "382:\tlearn: 0.2675699\ttotal: 13.8s\tremaining: 22.2s\n",
      "383:\tlearn: 0.2673390\ttotal: 13.8s\tremaining: 22.1s\n",
      "384:\tlearn: 0.2669970\ttotal: 13.9s\tremaining: 22.1s\n",
      "385:\tlearn: 0.2669068\ttotal: 13.9s\tremaining: 22.1s\n",
      "386:\tlearn: 0.2666878\ttotal: 13.9s\tremaining: 22s\n",
      "387:\tlearn: 0.2665029\ttotal: 14s\tremaining: 22s\n",
      "388:\tlearn: 0.2662622\ttotal: 14s\tremaining: 22s\n",
      "389:\tlearn: 0.2660020\ttotal: 14s\tremaining: 21.9s\n",
      "390:\tlearn: 0.2658217\ttotal: 14.1s\tremaining: 21.9s\n",
      "391:\tlearn: 0.2654993\ttotal: 14.1s\tremaining: 21.9s\n",
      "392:\tlearn: 0.2652846\ttotal: 14.1s\tremaining: 21.8s\n",
      "393:\tlearn: 0.2649944\ttotal: 14.2s\tremaining: 21.8s\n",
      "394:\tlearn: 0.2648839\ttotal: 14.2s\tremaining: 21.8s\n",
      "395:\tlearn: 0.2647683\ttotal: 14.2s\tremaining: 21.7s\n",
      "396:\tlearn: 0.2645548\ttotal: 14.3s\tremaining: 21.7s\n",
      "397:\tlearn: 0.2640305\ttotal: 14.3s\tremaining: 21.7s\n",
      "398:\tlearn: 0.2637854\ttotal: 14.3s\tremaining: 21.6s\n",
      "399:\tlearn: 0.2637147\ttotal: 14.4s\tremaining: 21.6s\n",
      "400:\tlearn: 0.2632496\ttotal: 14.4s\tremaining: 21.5s\n",
      "401:\tlearn: 0.2628993\ttotal: 14.4s\tremaining: 21.5s\n",
      "402:\tlearn: 0.2628083\ttotal: 14.5s\tremaining: 21.5s\n",
      "403:\tlearn: 0.2626775\ttotal: 14.5s\tremaining: 21.4s\n",
      "404:\tlearn: 0.2625119\ttotal: 14.6s\tremaining: 21.4s\n",
      "405:\tlearn: 0.2621671\ttotal: 14.6s\tremaining: 21.3s\n",
      "406:\tlearn: 0.2620110\ttotal: 14.6s\tremaining: 21.3s\n",
      "407:\tlearn: 0.2616449\ttotal: 14.7s\tremaining: 21.3s\n",
      "408:\tlearn: 0.2614455\ttotal: 14.7s\tremaining: 21.2s\n",
      "409:\tlearn: 0.2611730\ttotal: 14.7s\tremaining: 21.2s\n",
      "410:\tlearn: 0.2607800\ttotal: 14.8s\tremaining: 21.2s\n",
      "411:\tlearn: 0.2606653\ttotal: 14.8s\tremaining: 21.1s\n",
      "412:\tlearn: 0.2602806\ttotal: 14.9s\tremaining: 21.1s\n",
      "413:\tlearn: 0.2601125\ttotal: 14.9s\tremaining: 21.1s\n",
      "414:\tlearn: 0.2599124\ttotal: 14.9s\tremaining: 21s\n",
      "415:\tlearn: 0.2597478\ttotal: 14.9s\tremaining: 21s\n",
      "416:\tlearn: 0.2592593\ttotal: 15s\tremaining: 20.9s\n",
      "417:\tlearn: 0.2589595\ttotal: 15s\tremaining: 20.9s\n",
      "418:\tlearn: 0.2587527\ttotal: 15s\tremaining: 20.9s\n",
      "419:\tlearn: 0.2584634\ttotal: 15.1s\tremaining: 20.8s\n",
      "420:\tlearn: 0.2583334\ttotal: 15.1s\tremaining: 20.8s\n",
      "421:\tlearn: 0.2581313\ttotal: 15.2s\tremaining: 20.8s\n",
      "422:\tlearn: 0.2578693\ttotal: 15.2s\tremaining: 20.7s\n",
      "423:\tlearn: 0.2576710\ttotal: 15.2s\tremaining: 20.7s\n",
      "424:\tlearn: 0.2574922\ttotal: 15.3s\tremaining: 20.7s\n",
      "425:\tlearn: 0.2573363\ttotal: 15.3s\tremaining: 20.6s\n",
      "426:\tlearn: 0.2569986\ttotal: 15.3s\tremaining: 20.6s\n",
      "427:\tlearn: 0.2568452\ttotal: 15.4s\tremaining: 20.6s\n",
      "428:\tlearn: 0.2566589\ttotal: 15.4s\tremaining: 20.5s\n",
      "429:\tlearn: 0.2564313\ttotal: 15.5s\tremaining: 20.5s\n",
      "430:\tlearn: 0.2563546\ttotal: 15.5s\tremaining: 20.4s\n",
      "431:\tlearn: 0.2560629\ttotal: 15.5s\tremaining: 20.4s\n",
      "432:\tlearn: 0.2559373\ttotal: 15.6s\tremaining: 20.4s\n",
      "433:\tlearn: 0.2557718\ttotal: 15.6s\tremaining: 20.3s\n",
      "434:\tlearn: 0.2556499\ttotal: 15.6s\tremaining: 20.3s\n",
      "435:\tlearn: 0.2553976\ttotal: 15.7s\tremaining: 20.3s\n",
      "436:\tlearn: 0.2550978\ttotal: 15.7s\tremaining: 20.2s\n",
      "437:\tlearn: 0.2549335\ttotal: 15.7s\tremaining: 20.2s\n",
      "438:\tlearn: 0.2547289\ttotal: 15.8s\tremaining: 20.2s\n",
      "439:\tlearn: 0.2543943\ttotal: 15.8s\tremaining: 20.1s\n",
      "440:\tlearn: 0.2541565\ttotal: 15.8s\tremaining: 20.1s\n",
      "441:\tlearn: 0.2537965\ttotal: 15.9s\tremaining: 20.1s\n",
      "442:\tlearn: 0.2532677\ttotal: 15.9s\tremaining: 20s\n",
      "443:\tlearn: 0.2531586\ttotal: 16s\tremaining: 20s\n",
      "444:\tlearn: 0.2529658\ttotal: 16s\tremaining: 20s\n",
      "445:\tlearn: 0.2527906\ttotal: 16s\tremaining: 19.9s\n",
      "446:\tlearn: 0.2526468\ttotal: 16.1s\tremaining: 19.9s\n",
      "447:\tlearn: 0.2525877\ttotal: 16.1s\tremaining: 19.8s\n",
      "448:\tlearn: 0.2524491\ttotal: 16.1s\tremaining: 19.8s\n",
      "449:\tlearn: 0.2522127\ttotal: 16.2s\tremaining: 19.8s\n",
      "450:\tlearn: 0.2520439\ttotal: 16.2s\tremaining: 19.7s\n",
      "451:\tlearn: 0.2515656\ttotal: 16.2s\tremaining: 19.7s\n",
      "452:\tlearn: 0.2514767\ttotal: 16.3s\tremaining: 19.7s\n",
      "453:\tlearn: 0.2513402\ttotal: 16.3s\tremaining: 19.6s\n",
      "454:\tlearn: 0.2510667\ttotal: 16.3s\tremaining: 19.6s\n",
      "455:\tlearn: 0.2509281\ttotal: 16.4s\tremaining: 19.5s\n",
      "456:\tlearn: 0.2507045\ttotal: 16.4s\tremaining: 19.5s\n",
      "457:\tlearn: 0.2504849\ttotal: 16.4s\tremaining: 19.5s\n",
      "458:\tlearn: 0.2503532\ttotal: 16.5s\tremaining: 19.4s\n",
      "459:\tlearn: 0.2499189\ttotal: 16.5s\tremaining: 19.4s\n",
      "460:\tlearn: 0.2495402\ttotal: 16.6s\tremaining: 19.4s\n",
      "461:\tlearn: 0.2494129\ttotal: 16.6s\tremaining: 19.3s\n",
      "462:\tlearn: 0.2493267\ttotal: 16.6s\tremaining: 19.3s\n",
      "463:\tlearn: 0.2491704\ttotal: 16.7s\tremaining: 19.3s\n",
      "464:\tlearn: 0.2489977\ttotal: 16.7s\tremaining: 19.2s\n",
      "465:\tlearn: 0.2487443\ttotal: 16.7s\tremaining: 19.2s\n",
      "466:\tlearn: 0.2485781\ttotal: 16.8s\tremaining: 19.2s\n",
      "467:\tlearn: 0.2484382\ttotal: 16.8s\tremaining: 19.1s\n",
      "468:\tlearn: 0.2482761\ttotal: 16.9s\tremaining: 19.1s\n",
      "469:\tlearn: 0.2480719\ttotal: 16.9s\tremaining: 19.1s\n",
      "470:\tlearn: 0.2478702\ttotal: 16.9s\tremaining: 19s\n",
      "471:\tlearn: 0.2474931\ttotal: 17s\tremaining: 19s\n",
      "472:\tlearn: 0.2471495\ttotal: 17s\tremaining: 19s\n",
      "473:\tlearn: 0.2468235\ttotal: 17s\tremaining: 18.9s\n",
      "474:\tlearn: 0.2467124\ttotal: 17.1s\tremaining: 18.9s\n",
      "475:\tlearn: 0.2464933\ttotal: 17.1s\tremaining: 18.8s\n",
      "476:\tlearn: 0.2463423\ttotal: 17.2s\tremaining: 18.8s\n",
      "477:\tlearn: 0.2459950\ttotal: 17.2s\tremaining: 18.8s\n",
      "478:\tlearn: 0.2459526\ttotal: 17.2s\tremaining: 18.7s\n",
      "479:\tlearn: 0.2456052\ttotal: 17.3s\tremaining: 18.7s\n",
      "480:\tlearn: 0.2453553\ttotal: 17.3s\tremaining: 18.7s\n",
      "481:\tlearn: 0.2452530\ttotal: 17.3s\tremaining: 18.6s\n",
      "482:\tlearn: 0.2451403\ttotal: 17.4s\tremaining: 18.6s\n",
      "483:\tlearn: 0.2449896\ttotal: 17.4s\tremaining: 18.6s\n",
      "484:\tlearn: 0.2448933\ttotal: 17.4s\tremaining: 18.5s\n",
      "485:\tlearn: 0.2447419\ttotal: 17.5s\tremaining: 18.5s\n",
      "486:\tlearn: 0.2445102\ttotal: 17.5s\tremaining: 18.4s\n",
      "487:\tlearn: 0.2443849\ttotal: 17.5s\tremaining: 18.4s\n",
      "488:\tlearn: 0.2442221\ttotal: 17.6s\tremaining: 18.4s\n",
      "489:\tlearn: 0.2440735\ttotal: 17.6s\tremaining: 18.3s\n",
      "490:\tlearn: 0.2438333\ttotal: 17.7s\tremaining: 18.3s\n",
      "491:\tlearn: 0.2437171\ttotal: 17.7s\tremaining: 18.3s\n",
      "492:\tlearn: 0.2435870\ttotal: 17.7s\tremaining: 18.2s\n",
      "493:\tlearn: 0.2433585\ttotal: 17.8s\tremaining: 18.2s\n",
      "494:\tlearn: 0.2431455\ttotal: 17.8s\tremaining: 18.2s\n",
      "495:\tlearn: 0.2429159\ttotal: 17.8s\tremaining: 18.1s\n",
      "496:\tlearn: 0.2428442\ttotal: 17.9s\tremaining: 18.1s\n",
      "497:\tlearn: 0.2426121\ttotal: 17.9s\tremaining: 18s\n",
      "498:\tlearn: 0.2423839\ttotal: 17.9s\tremaining: 18s\n",
      "499:\tlearn: 0.2422115\ttotal: 18s\tremaining: 18s\n",
      "500:\tlearn: 0.2421087\ttotal: 18s\tremaining: 17.9s\n",
      "501:\tlearn: 0.2418528\ttotal: 18s\tremaining: 17.9s\n",
      "502:\tlearn: 0.2416422\ttotal: 18.1s\tremaining: 17.9s\n",
      "503:\tlearn: 0.2413181\ttotal: 18.1s\tremaining: 17.8s\n",
      "504:\tlearn: 0.2412608\ttotal: 18.2s\tremaining: 17.8s\n",
      "505:\tlearn: 0.2410389\ttotal: 18.2s\tremaining: 17.8s\n",
      "506:\tlearn: 0.2407423\ttotal: 18.2s\tremaining: 17.7s\n",
      "507:\tlearn: 0.2405975\ttotal: 18.3s\tremaining: 17.7s\n",
      "508:\tlearn: 0.2404446\ttotal: 18.3s\tremaining: 17.6s\n",
      "509:\tlearn: 0.2403581\ttotal: 18.3s\tremaining: 17.6s\n",
      "510:\tlearn: 0.2401204\ttotal: 18.4s\tremaining: 17.6s\n",
      "511:\tlearn: 0.2398954\ttotal: 18.4s\tremaining: 17.5s\n",
      "512:\tlearn: 0.2397599\ttotal: 18.4s\tremaining: 17.5s\n",
      "513:\tlearn: 0.2396111\ttotal: 18.5s\tremaining: 17.5s\n",
      "514:\tlearn: 0.2394149\ttotal: 18.5s\tremaining: 17.4s\n",
      "515:\tlearn: 0.2390111\ttotal: 18.5s\tremaining: 17.4s\n",
      "516:\tlearn: 0.2386172\ttotal: 18.6s\tremaining: 17.4s\n",
      "517:\tlearn: 0.2385456\ttotal: 18.6s\tremaining: 17.3s\n",
      "518:\tlearn: 0.2383964\ttotal: 18.7s\tremaining: 17.3s\n",
      "519:\tlearn: 0.2381994\ttotal: 18.7s\tremaining: 17.3s\n",
      "520:\tlearn: 0.2380351\ttotal: 18.7s\tremaining: 17.2s\n",
      "521:\tlearn: 0.2377490\ttotal: 18.8s\tremaining: 17.2s\n",
      "522:\tlearn: 0.2375194\ttotal: 18.8s\tremaining: 17.1s\n",
      "523:\tlearn: 0.2373452\ttotal: 18.8s\tremaining: 17.1s\n",
      "524:\tlearn: 0.2371480\ttotal: 18.9s\tremaining: 17.1s\n",
      "525:\tlearn: 0.2369779\ttotal: 18.9s\tremaining: 17s\n",
      "526:\tlearn: 0.2368832\ttotal: 18.9s\tremaining: 17s\n",
      "527:\tlearn: 0.2367034\ttotal: 19s\tremaining: 17s\n",
      "528:\tlearn: 0.2363479\ttotal: 19s\tremaining: 16.9s\n",
      "529:\tlearn: 0.2359709\ttotal: 19.1s\tremaining: 16.9s\n",
      "530:\tlearn: 0.2357219\ttotal: 19.1s\tremaining: 16.9s\n",
      "531:\tlearn: 0.2355325\ttotal: 19.1s\tremaining: 16.8s\n",
      "532:\tlearn: 0.2353890\ttotal: 19.2s\tremaining: 16.8s\n",
      "533:\tlearn: 0.2353113\ttotal: 19.2s\tremaining: 16.7s\n",
      "534:\tlearn: 0.2351898\ttotal: 19.2s\tremaining: 16.7s\n",
      "535:\tlearn: 0.2348612\ttotal: 19.3s\tremaining: 16.7s\n",
      "536:\tlearn: 0.2345550\ttotal: 19.3s\tremaining: 16.6s\n",
      "537:\tlearn: 0.2341241\ttotal: 19.3s\tremaining: 16.6s\n",
      "538:\tlearn: 0.2340343\ttotal: 19.4s\tremaining: 16.6s\n",
      "539:\tlearn: 0.2336845\ttotal: 19.4s\tremaining: 16.5s\n",
      "540:\tlearn: 0.2334467\ttotal: 19.4s\tremaining: 16.5s\n",
      "541:\tlearn: 0.2332909\ttotal: 19.5s\tremaining: 16.5s\n",
      "542:\tlearn: 0.2330662\ttotal: 19.5s\tremaining: 16.4s\n",
      "543:\tlearn: 0.2329738\ttotal: 19.5s\tremaining: 16.4s\n",
      "544:\tlearn: 0.2328994\ttotal: 19.6s\tremaining: 16.3s\n",
      "545:\tlearn: 0.2327821\ttotal: 19.6s\tremaining: 16.3s\n",
      "546:\tlearn: 0.2326650\ttotal: 19.7s\tremaining: 16.3s\n",
      "547:\tlearn: 0.2325895\ttotal: 19.7s\tremaining: 16.2s\n",
      "548:\tlearn: 0.2322283\ttotal: 19.7s\tremaining: 16.2s\n",
      "549:\tlearn: 0.2319475\ttotal: 19.8s\tremaining: 16.2s\n",
      "550:\tlearn: 0.2318123\ttotal: 19.8s\tremaining: 16.1s\n",
      "551:\tlearn: 0.2313850\ttotal: 19.8s\tremaining: 16.1s\n",
      "552:\tlearn: 0.2311693\ttotal: 19.9s\tremaining: 16.1s\n",
      "553:\tlearn: 0.2310438\ttotal: 19.9s\tremaining: 16s\n",
      "554:\tlearn: 0.2308760\ttotal: 19.9s\tremaining: 16s\n",
      "555:\tlearn: 0.2305605\ttotal: 20s\tremaining: 16s\n",
      "556:\tlearn: 0.2302984\ttotal: 20s\tremaining: 15.9s\n",
      "557:\tlearn: 0.2299747\ttotal: 20.1s\tremaining: 15.9s\n",
      "558:\tlearn: 0.2298608\ttotal: 20.1s\tremaining: 15.8s\n",
      "559:\tlearn: 0.2297430\ttotal: 20.1s\tremaining: 15.8s\n",
      "560:\tlearn: 0.2295799\ttotal: 20.2s\tremaining: 15.8s\n",
      "561:\tlearn: 0.2295224\ttotal: 20.2s\tremaining: 15.7s\n",
      "562:\tlearn: 0.2293821\ttotal: 20.2s\tremaining: 15.7s\n",
      "563:\tlearn: 0.2290166\ttotal: 20.3s\tremaining: 15.7s\n",
      "564:\tlearn: 0.2288946\ttotal: 20.3s\tremaining: 15.6s\n",
      "565:\tlearn: 0.2287176\ttotal: 20.3s\tremaining: 15.6s\n",
      "566:\tlearn: 0.2284361\ttotal: 20.4s\tremaining: 15.6s\n",
      "567:\tlearn: 0.2282178\ttotal: 20.4s\tremaining: 15.5s\n",
      "568:\tlearn: 0.2279998\ttotal: 20.5s\tremaining: 15.5s\n",
      "569:\tlearn: 0.2278412\ttotal: 20.5s\tremaining: 15.5s\n",
      "570:\tlearn: 0.2277440\ttotal: 20.6s\tremaining: 15.4s\n",
      "571:\tlearn: 0.2276243\ttotal: 20.6s\tremaining: 15.4s\n",
      "572:\tlearn: 0.2274705\ttotal: 20.6s\tremaining: 15.4s\n",
      "573:\tlearn: 0.2273229\ttotal: 20.7s\tremaining: 15.3s\n",
      "574:\tlearn: 0.2270886\ttotal: 20.7s\tremaining: 15.3s\n",
      "575:\tlearn: 0.2267258\ttotal: 20.7s\tremaining: 15.3s\n",
      "576:\tlearn: 0.2265571\ttotal: 20.8s\tremaining: 15.2s\n",
      "577:\tlearn: 0.2264169\ttotal: 20.8s\tremaining: 15.2s\n",
      "578:\tlearn: 0.2262822\ttotal: 20.9s\tremaining: 15.2s\n",
      "579:\tlearn: 0.2260830\ttotal: 20.9s\tremaining: 15.1s\n",
      "580:\tlearn: 0.2259551\ttotal: 20.9s\tremaining: 15.1s\n",
      "581:\tlearn: 0.2258286\ttotal: 21s\tremaining: 15.1s\n",
      "582:\tlearn: 0.2255606\ttotal: 21s\tremaining: 15s\n",
      "583:\tlearn: 0.2253294\ttotal: 21s\tremaining: 15s\n",
      "584:\tlearn: 0.2251430\ttotal: 21.1s\tremaining: 14.9s\n",
      "585:\tlearn: 0.2248876\ttotal: 21.1s\tremaining: 14.9s\n",
      "586:\tlearn: 0.2247551\ttotal: 21.2s\tremaining: 14.9s\n",
      "587:\tlearn: 0.2246811\ttotal: 21.2s\tremaining: 14.8s\n",
      "588:\tlearn: 0.2244407\ttotal: 21.2s\tremaining: 14.8s\n",
      "589:\tlearn: 0.2242265\ttotal: 21.3s\tremaining: 14.8s\n",
      "590:\tlearn: 0.2241301\ttotal: 21.3s\tremaining: 14.7s\n",
      "591:\tlearn: 0.2239114\ttotal: 21.3s\tremaining: 14.7s\n",
      "592:\tlearn: 0.2238061\ttotal: 21.3s\tremaining: 14.7s\n",
      "593:\tlearn: 0.2234988\ttotal: 21.4s\tremaining: 14.6s\n",
      "594:\tlearn: 0.2233862\ttotal: 21.4s\tremaining: 14.6s\n",
      "595:\tlearn: 0.2231813\ttotal: 21.5s\tremaining: 14.6s\n",
      "596:\tlearn: 0.2227813\ttotal: 21.5s\tremaining: 14.5s\n",
      "597:\tlearn: 0.2227060\ttotal: 21.5s\tremaining: 14.5s\n",
      "598:\tlearn: 0.2225920\ttotal: 21.6s\tremaining: 14.4s\n",
      "599:\tlearn: 0.2224005\ttotal: 21.6s\tremaining: 14.4s\n",
      "600:\tlearn: 0.2221303\ttotal: 21.6s\tremaining: 14.4s\n",
      "601:\tlearn: 0.2219970\ttotal: 21.7s\tremaining: 14.3s\n",
      "602:\tlearn: 0.2218606\ttotal: 21.7s\tremaining: 14.3s\n",
      "603:\tlearn: 0.2216509\ttotal: 21.8s\tremaining: 14.3s\n",
      "604:\tlearn: 0.2214773\ttotal: 21.8s\tremaining: 14.2s\n",
      "605:\tlearn: 0.2211524\ttotal: 21.8s\tremaining: 14.2s\n",
      "606:\tlearn: 0.2209918\ttotal: 21.9s\tremaining: 14.2s\n",
      "607:\tlearn: 0.2208593\ttotal: 21.9s\tremaining: 14.1s\n",
      "608:\tlearn: 0.2207628\ttotal: 21.9s\tremaining: 14.1s\n",
      "609:\tlearn: 0.2206316\ttotal: 22s\tremaining: 14s\n",
      "610:\tlearn: 0.2205500\ttotal: 22s\tremaining: 14s\n",
      "611:\tlearn: 0.2203759\ttotal: 22.1s\tremaining: 14s\n",
      "612:\tlearn: 0.2202727\ttotal: 22.1s\tremaining: 13.9s\n",
      "613:\tlearn: 0.2201292\ttotal: 22.1s\tremaining: 13.9s\n",
      "614:\tlearn: 0.2200897\ttotal: 22.2s\tremaining: 13.9s\n",
      "615:\tlearn: 0.2200367\ttotal: 22.2s\tremaining: 13.8s\n",
      "616:\tlearn: 0.2198404\ttotal: 22.2s\tremaining: 13.8s\n",
      "617:\tlearn: 0.2196665\ttotal: 22.3s\tremaining: 13.8s\n",
      "618:\tlearn: 0.2192878\ttotal: 22.3s\tremaining: 13.7s\n",
      "619:\tlearn: 0.2190008\ttotal: 22.3s\tremaining: 13.7s\n",
      "620:\tlearn: 0.2188124\ttotal: 22.4s\tremaining: 13.7s\n",
      "621:\tlearn: 0.2186194\ttotal: 22.4s\tremaining: 13.6s\n",
      "622:\tlearn: 0.2184641\ttotal: 22.4s\tremaining: 13.6s\n",
      "623:\tlearn: 0.2183428\ttotal: 22.5s\tremaining: 13.5s\n",
      "624:\tlearn: 0.2180832\ttotal: 22.5s\tremaining: 13.5s\n",
      "625:\tlearn: 0.2178676\ttotal: 22.6s\tremaining: 13.5s\n",
      "626:\tlearn: 0.2177507\ttotal: 22.6s\tremaining: 13.4s\n",
      "627:\tlearn: 0.2174375\ttotal: 22.6s\tremaining: 13.4s\n",
      "628:\tlearn: 0.2170956\ttotal: 22.7s\tremaining: 13.4s\n",
      "629:\tlearn: 0.2170090\ttotal: 22.7s\tremaining: 13.3s\n",
      "630:\tlearn: 0.2168576\ttotal: 22.7s\tremaining: 13.3s\n",
      "631:\tlearn: 0.2167216\ttotal: 22.8s\tremaining: 13.3s\n",
      "632:\tlearn: 0.2166384\ttotal: 22.8s\tremaining: 13.2s\n",
      "633:\tlearn: 0.2165443\ttotal: 22.9s\tremaining: 13.2s\n",
      "634:\tlearn: 0.2164427\ttotal: 22.9s\tremaining: 13.2s\n",
      "635:\tlearn: 0.2162453\ttotal: 22.9s\tremaining: 13.1s\n",
      "636:\tlearn: 0.2160580\ttotal: 23s\tremaining: 13.1s\n",
      "637:\tlearn: 0.2159584\ttotal: 23s\tremaining: 13.1s\n",
      "638:\tlearn: 0.2157010\ttotal: 23s\tremaining: 13s\n",
      "639:\tlearn: 0.2155063\ttotal: 23.1s\tremaining: 13s\n",
      "640:\tlearn: 0.2152959\ttotal: 23.1s\tremaining: 12.9s\n",
      "641:\tlearn: 0.2150426\ttotal: 23.1s\tremaining: 12.9s\n",
      "642:\tlearn: 0.2149694\ttotal: 23.2s\tremaining: 12.9s\n",
      "643:\tlearn: 0.2147585\ttotal: 23.2s\tremaining: 12.8s\n",
      "644:\tlearn: 0.2145566\ttotal: 23.3s\tremaining: 12.8s\n",
      "645:\tlearn: 0.2143634\ttotal: 23.3s\tremaining: 12.8s\n",
      "646:\tlearn: 0.2142682\ttotal: 23.3s\tremaining: 12.7s\n",
      "647:\tlearn: 0.2141865\ttotal: 23.4s\tremaining: 12.7s\n",
      "648:\tlearn: 0.2139346\ttotal: 23.4s\tremaining: 12.7s\n",
      "649:\tlearn: 0.2138614\ttotal: 23.4s\tremaining: 12.6s\n",
      "650:\tlearn: 0.2136013\ttotal: 23.5s\tremaining: 12.6s\n",
      "651:\tlearn: 0.2135203\ttotal: 23.5s\tremaining: 12.5s\n",
      "652:\tlearn: 0.2132540\ttotal: 23.5s\tremaining: 12.5s\n",
      "653:\tlearn: 0.2129686\ttotal: 23.6s\tremaining: 12.5s\n",
      "654:\tlearn: 0.2127638\ttotal: 23.6s\tremaining: 12.4s\n",
      "655:\tlearn: 0.2125614\ttotal: 23.7s\tremaining: 12.4s\n",
      "656:\tlearn: 0.2124676\ttotal: 23.7s\tremaining: 12.4s\n",
      "657:\tlearn: 0.2123752\ttotal: 23.7s\tremaining: 12.3s\n",
      "658:\tlearn: 0.2122463\ttotal: 23.8s\tremaining: 12.3s\n",
      "659:\tlearn: 0.2120983\ttotal: 23.8s\tremaining: 12.3s\n",
      "660:\tlearn: 0.2119920\ttotal: 23.8s\tremaining: 12.2s\n",
      "661:\tlearn: 0.2118844\ttotal: 23.9s\tremaining: 12.2s\n",
      "662:\tlearn: 0.2117969\ttotal: 23.9s\tremaining: 12.2s\n",
      "663:\tlearn: 0.2115535\ttotal: 23.9s\tremaining: 12.1s\n",
      "664:\tlearn: 0.2113447\ttotal: 24s\tremaining: 12.1s\n",
      "665:\tlearn: 0.2110513\ttotal: 24s\tremaining: 12s\n",
      "666:\tlearn: 0.2107857\ttotal: 24.1s\tremaining: 12s\n",
      "667:\tlearn: 0.2107364\ttotal: 24.1s\tremaining: 12s\n",
      "668:\tlearn: 0.2105614\ttotal: 24.1s\tremaining: 11.9s\n",
      "669:\tlearn: 0.2103346\ttotal: 24.2s\tremaining: 11.9s\n",
      "670:\tlearn: 0.2101775\ttotal: 24.2s\tremaining: 11.9s\n",
      "671:\tlearn: 0.2100526\ttotal: 24.2s\tremaining: 11.8s\n",
      "672:\tlearn: 0.2098348\ttotal: 24.3s\tremaining: 11.8s\n",
      "673:\tlearn: 0.2096709\ttotal: 24.3s\tremaining: 11.8s\n",
      "674:\tlearn: 0.2095561\ttotal: 24.3s\tremaining: 11.7s\n",
      "675:\tlearn: 0.2094154\ttotal: 24.4s\tremaining: 11.7s\n",
      "676:\tlearn: 0.2091263\ttotal: 24.4s\tremaining: 11.6s\n",
      "677:\tlearn: 0.2090684\ttotal: 24.4s\tremaining: 11.6s\n",
      "678:\tlearn: 0.2089145\ttotal: 24.5s\tremaining: 11.6s\n",
      "679:\tlearn: 0.2086438\ttotal: 24.5s\tremaining: 11.5s\n",
      "680:\tlearn: 0.2085804\ttotal: 24.6s\tremaining: 11.5s\n",
      "681:\tlearn: 0.2084653\ttotal: 24.6s\tremaining: 11.5s\n",
      "682:\tlearn: 0.2083045\ttotal: 24.6s\tremaining: 11.4s\n",
      "683:\tlearn: 0.2081389\ttotal: 24.7s\tremaining: 11.4s\n",
      "684:\tlearn: 0.2080888\ttotal: 24.7s\tremaining: 11.4s\n",
      "685:\tlearn: 0.2080320\ttotal: 24.7s\tremaining: 11.3s\n",
      "686:\tlearn: 0.2079501\ttotal: 24.8s\tremaining: 11.3s\n",
      "687:\tlearn: 0.2078139\ttotal: 24.8s\tremaining: 11.3s\n",
      "688:\tlearn: 0.2075541\ttotal: 24.9s\tremaining: 11.2s\n",
      "689:\tlearn: 0.2074611\ttotal: 24.9s\tremaining: 11.2s\n",
      "690:\tlearn: 0.2072728\ttotal: 24.9s\tremaining: 11.2s\n",
      "691:\tlearn: 0.2069543\ttotal: 25s\tremaining: 11.1s\n",
      "692:\tlearn: 0.2067214\ttotal: 25s\tremaining: 11.1s\n",
      "693:\tlearn: 0.2065935\ttotal: 25.1s\tremaining: 11.1s\n",
      "694:\tlearn: 0.2065328\ttotal: 25.1s\tremaining: 11s\n",
      "695:\tlearn: 0.2063513\ttotal: 25.1s\tremaining: 11s\n",
      "696:\tlearn: 0.2062358\ttotal: 25.2s\tremaining: 10.9s\n",
      "697:\tlearn: 0.2061537\ttotal: 25.2s\tremaining: 10.9s\n",
      "698:\tlearn: 0.2060741\ttotal: 25.2s\tremaining: 10.9s\n",
      "699:\tlearn: 0.2058941\ttotal: 25.3s\tremaining: 10.8s\n",
      "700:\tlearn: 0.2057716\ttotal: 25.3s\tremaining: 10.8s\n",
      "701:\tlearn: 0.2056639\ttotal: 25.4s\tremaining: 10.8s\n",
      "702:\tlearn: 0.2055222\ttotal: 25.4s\tremaining: 10.7s\n",
      "703:\tlearn: 0.2053282\ttotal: 25.4s\tremaining: 10.7s\n",
      "704:\tlearn: 0.2052719\ttotal: 25.5s\tremaining: 10.7s\n",
      "705:\tlearn: 0.2050409\ttotal: 25.5s\tremaining: 10.6s\n",
      "706:\tlearn: 0.2047888\ttotal: 25.5s\tremaining: 10.6s\n",
      "707:\tlearn: 0.2046199\ttotal: 25.6s\tremaining: 10.5s\n",
      "708:\tlearn: 0.2044499\ttotal: 25.6s\tremaining: 10.5s\n",
      "709:\tlearn: 0.2043425\ttotal: 25.6s\tremaining: 10.5s\n",
      "710:\tlearn: 0.2042518\ttotal: 25.7s\tremaining: 10.4s\n",
      "711:\tlearn: 0.2041231\ttotal: 25.7s\tremaining: 10.4s\n",
      "712:\tlearn: 0.2040473\ttotal: 25.7s\tremaining: 10.4s\n",
      "713:\tlearn: 0.2039619\ttotal: 25.8s\tremaining: 10.3s\n",
      "714:\tlearn: 0.2037852\ttotal: 25.8s\tremaining: 10.3s\n",
      "715:\tlearn: 0.2037302\ttotal: 25.9s\tremaining: 10.3s\n",
      "716:\tlearn: 0.2036003\ttotal: 25.9s\tremaining: 10.2s\n",
      "717:\tlearn: 0.2035467\ttotal: 25.9s\tremaining: 10.2s\n",
      "718:\tlearn: 0.2034106\ttotal: 26s\tremaining: 10.2s\n",
      "719:\tlearn: 0.2031701\ttotal: 26s\tremaining: 10.1s\n",
      "720:\tlearn: 0.2030317\ttotal: 26s\tremaining: 10.1s\n",
      "721:\tlearn: 0.2028662\ttotal: 26.1s\tremaining: 10s\n",
      "722:\tlearn: 0.2026413\ttotal: 26.1s\tremaining: 10s\n",
      "723:\tlearn: 0.2024421\ttotal: 26.1s\tremaining: 9.97s\n",
      "724:\tlearn: 0.2023159\ttotal: 26.2s\tremaining: 9.93s\n",
      "725:\tlearn: 0.2021726\ttotal: 26.2s\tremaining: 9.9s\n",
      "726:\tlearn: 0.2021237\ttotal: 26.3s\tremaining: 9.86s\n",
      "727:\tlearn: 0.2020203\ttotal: 26.3s\tremaining: 9.83s\n",
      "728:\tlearn: 0.2019393\ttotal: 26.3s\tremaining: 9.79s\n",
      "729:\tlearn: 0.2018471\ttotal: 26.4s\tremaining: 9.75s\n",
      "730:\tlearn: 0.2016627\ttotal: 26.4s\tremaining: 9.71s\n",
      "731:\tlearn: 0.2014692\ttotal: 26.4s\tremaining: 9.68s\n",
      "732:\tlearn: 0.2013928\ttotal: 26.5s\tremaining: 9.64s\n",
      "733:\tlearn: 0.2013012\ttotal: 26.5s\tremaining: 9.61s\n",
      "734:\tlearn: 0.2011524\ttotal: 26.6s\tremaining: 9.58s\n",
      "735:\tlearn: 0.2010070\ttotal: 26.6s\tremaining: 9.54s\n",
      "736:\tlearn: 0.2008831\ttotal: 26.6s\tremaining: 9.5s\n",
      "737:\tlearn: 0.2007036\ttotal: 26.7s\tremaining: 9.46s\n",
      "738:\tlearn: 0.2006520\ttotal: 26.7s\tremaining: 9.43s\n",
      "739:\tlearn: 0.2006169\ttotal: 26.7s\tremaining: 9.39s\n",
      "740:\tlearn: 0.2003906\ttotal: 26.8s\tremaining: 9.35s\n",
      "741:\tlearn: 0.2003327\ttotal: 26.8s\tremaining: 9.32s\n",
      "742:\tlearn: 0.2001754\ttotal: 26.8s\tremaining: 9.28s\n",
      "743:\tlearn: 0.2000954\ttotal: 26.9s\tremaining: 9.25s\n",
      "744:\tlearn: 0.1999580\ttotal: 26.9s\tremaining: 9.21s\n",
      "745:\tlearn: 0.1999100\ttotal: 26.9s\tremaining: 9.17s\n",
      "746:\tlearn: 0.1997444\ttotal: 27s\tremaining: 9.14s\n",
      "747:\tlearn: 0.1996216\ttotal: 27s\tremaining: 9.1s\n",
      "748:\tlearn: 0.1994935\ttotal: 27.1s\tremaining: 9.06s\n",
      "749:\tlearn: 0.1994320\ttotal: 27.1s\tremaining: 9.03s\n",
      "750:\tlearn: 0.1992777\ttotal: 27.1s\tremaining: 9s\n",
      "751:\tlearn: 0.1991894\ttotal: 27.2s\tremaining: 8.96s\n",
      "752:\tlearn: 0.1990868\ttotal: 27.2s\tremaining: 8.93s\n",
      "753:\tlearn: 0.1990091\ttotal: 27.3s\tremaining: 8.89s\n",
      "754:\tlearn: 0.1988995\ttotal: 27.3s\tremaining: 8.86s\n",
      "755:\tlearn: 0.1987567\ttotal: 27.3s\tremaining: 8.82s\n",
      "756:\tlearn: 0.1986397\ttotal: 27.4s\tremaining: 8.78s\n",
      "757:\tlearn: 0.1985623\ttotal: 27.4s\tremaining: 8.74s\n",
      "758:\tlearn: 0.1984201\ttotal: 27.4s\tremaining: 8.71s\n",
      "759:\tlearn: 0.1983286\ttotal: 27.5s\tremaining: 8.67s\n",
      "760:\tlearn: 0.1982288\ttotal: 27.5s\tremaining: 8.64s\n",
      "761:\tlearn: 0.1981071\ttotal: 27.5s\tremaining: 8.6s\n",
      "762:\tlearn: 0.1978168\ttotal: 27.6s\tremaining: 8.57s\n",
      "763:\tlearn: 0.1977179\ttotal: 27.6s\tremaining: 8.53s\n",
      "764:\tlearn: 0.1976006\ttotal: 27.6s\tremaining: 8.49s\n",
      "765:\tlearn: 0.1975361\ttotal: 27.7s\tremaining: 8.46s\n",
      "766:\tlearn: 0.1974152\ttotal: 27.7s\tremaining: 8.43s\n",
      "767:\tlearn: 0.1973693\ttotal: 27.8s\tremaining: 8.39s\n",
      "768:\tlearn: 0.1973257\ttotal: 27.8s\tremaining: 8.35s\n",
      "769:\tlearn: 0.1972229\ttotal: 27.8s\tremaining: 8.31s\n",
      "770:\tlearn: 0.1970622\ttotal: 27.9s\tremaining: 8.28s\n",
      "771:\tlearn: 0.1970146\ttotal: 27.9s\tremaining: 8.24s\n",
      "772:\tlearn: 0.1968526\ttotal: 27.9s\tremaining: 8.2s\n",
      "773:\tlearn: 0.1967149\ttotal: 28s\tremaining: 8.17s\n",
      "774:\tlearn: 0.1966283\ttotal: 28s\tremaining: 8.13s\n",
      "775:\tlearn: 0.1964752\ttotal: 28.1s\tremaining: 8.1s\n",
      "776:\tlearn: 0.1963830\ttotal: 28.1s\tremaining: 8.06s\n",
      "777:\tlearn: 0.1962237\ttotal: 28.1s\tremaining: 8.03s\n",
      "778:\tlearn: 0.1959262\ttotal: 28.2s\tremaining: 7.99s\n",
      "779:\tlearn: 0.1956414\ttotal: 28.2s\tremaining: 7.96s\n",
      "780:\tlearn: 0.1954803\ttotal: 28.2s\tremaining: 7.92s\n",
      "781:\tlearn: 0.1953529\ttotal: 28.3s\tremaining: 7.88s\n",
      "782:\tlearn: 0.1952808\ttotal: 28.3s\tremaining: 7.85s\n",
      "783:\tlearn: 0.1951644\ttotal: 28.4s\tremaining: 7.81s\n",
      "784:\tlearn: 0.1950594\ttotal: 28.4s\tremaining: 7.78s\n",
      "785:\tlearn: 0.1949751\ttotal: 28.5s\tremaining: 7.75s\n",
      "786:\tlearn: 0.1948161\ttotal: 28.5s\tremaining: 7.71s\n",
      "787:\tlearn: 0.1946375\ttotal: 28.5s\tremaining: 7.67s\n",
      "788:\tlearn: 0.1945074\ttotal: 28.6s\tremaining: 7.64s\n",
      "789:\tlearn: 0.1944378\ttotal: 28.6s\tremaining: 7.6s\n",
      "790:\tlearn: 0.1943127\ttotal: 28.6s\tremaining: 7.56s\n",
      "791:\tlearn: 0.1941618\ttotal: 28.7s\tremaining: 7.53s\n",
      "792:\tlearn: 0.1940796\ttotal: 28.7s\tremaining: 7.49s\n",
      "793:\tlearn: 0.1939324\ttotal: 28.7s\tremaining: 7.46s\n",
      "794:\tlearn: 0.1936714\ttotal: 28.8s\tremaining: 7.42s\n",
      "795:\tlearn: 0.1935612\ttotal: 28.8s\tremaining: 7.39s\n",
      "796:\tlearn: 0.1934379\ttotal: 28.9s\tremaining: 7.35s\n",
      "797:\tlearn: 0.1932804\ttotal: 28.9s\tremaining: 7.31s\n",
      "798:\tlearn: 0.1931298\ttotal: 28.9s\tremaining: 7.28s\n",
      "799:\tlearn: 0.1929793\ttotal: 29s\tremaining: 7.24s\n",
      "800:\tlearn: 0.1927337\ttotal: 29s\tremaining: 7.21s\n",
      "801:\tlearn: 0.1926711\ttotal: 29s\tremaining: 7.17s\n",
      "802:\tlearn: 0.1925332\ttotal: 29.1s\tremaining: 7.13s\n",
      "803:\tlearn: 0.1924558\ttotal: 29.1s\tremaining: 7.1s\n",
      "804:\tlearn: 0.1922949\ttotal: 29.2s\tremaining: 7.06s\n",
      "805:\tlearn: 0.1922022\ttotal: 29.2s\tremaining: 7.03s\n",
      "806:\tlearn: 0.1921087\ttotal: 29.2s\tremaining: 6.99s\n",
      "807:\tlearn: 0.1919508\ttotal: 29.3s\tremaining: 6.95s\n",
      "808:\tlearn: 0.1918425\ttotal: 29.3s\tremaining: 6.92s\n",
      "809:\tlearn: 0.1917476\ttotal: 29.3s\tremaining: 6.88s\n",
      "810:\tlearn: 0.1916634\ttotal: 29.4s\tremaining: 6.84s\n",
      "811:\tlearn: 0.1915441\ttotal: 29.4s\tremaining: 6.81s\n",
      "812:\tlearn: 0.1912983\ttotal: 29.5s\tremaining: 6.77s\n",
      "813:\tlearn: 0.1910905\ttotal: 29.5s\tremaining: 6.74s\n",
      "814:\tlearn: 0.1908809\ttotal: 29.5s\tremaining: 6.7s\n",
      "815:\tlearn: 0.1907650\ttotal: 29.6s\tremaining: 6.66s\n",
      "816:\tlearn: 0.1905879\ttotal: 29.6s\tremaining: 6.63s\n",
      "817:\tlearn: 0.1904466\ttotal: 29.6s\tremaining: 6.59s\n",
      "818:\tlearn: 0.1902699\ttotal: 29.7s\tremaining: 6.56s\n",
      "819:\tlearn: 0.1901656\ttotal: 29.7s\tremaining: 6.52s\n",
      "820:\tlearn: 0.1901155\ttotal: 29.7s\tremaining: 6.48s\n",
      "821:\tlearn: 0.1899619\ttotal: 29.8s\tremaining: 6.45s\n",
      "822:\tlearn: 0.1898292\ttotal: 29.8s\tremaining: 6.41s\n",
      "823:\tlearn: 0.1897796\ttotal: 29.8s\tremaining: 6.37s\n",
      "824:\tlearn: 0.1897037\ttotal: 29.9s\tremaining: 6.34s\n",
      "825:\tlearn: 0.1896107\ttotal: 29.9s\tremaining: 6.3s\n",
      "826:\tlearn: 0.1894938\ttotal: 30s\tremaining: 6.27s\n",
      "827:\tlearn: 0.1893133\ttotal: 30s\tremaining: 6.23s\n",
      "828:\tlearn: 0.1891379\ttotal: 30s\tremaining: 6.2s\n",
      "829:\tlearn: 0.1889670\ttotal: 30.1s\tremaining: 6.16s\n",
      "830:\tlearn: 0.1887585\ttotal: 30.1s\tremaining: 6.12s\n",
      "831:\tlearn: 0.1887015\ttotal: 30.1s\tremaining: 6.08s\n",
      "832:\tlearn: 0.1885958\ttotal: 30.2s\tremaining: 6.05s\n",
      "833:\tlearn: 0.1885262\ttotal: 30.2s\tremaining: 6.01s\n",
      "834:\tlearn: 0.1883420\ttotal: 30.2s\tremaining: 5.97s\n",
      "835:\tlearn: 0.1882602\ttotal: 30.3s\tremaining: 5.94s\n",
      "836:\tlearn: 0.1881345\ttotal: 30.3s\tremaining: 5.9s\n",
      "837:\tlearn: 0.1879545\ttotal: 30.4s\tremaining: 5.87s\n",
      "838:\tlearn: 0.1877854\ttotal: 30.4s\tremaining: 5.83s\n",
      "839:\tlearn: 0.1876384\ttotal: 30.4s\tremaining: 5.79s\n",
      "840:\tlearn: 0.1875546\ttotal: 30.5s\tremaining: 5.76s\n",
      "841:\tlearn: 0.1874323\ttotal: 30.5s\tremaining: 5.72s\n",
      "842:\tlearn: 0.1873483\ttotal: 30.5s\tremaining: 5.69s\n",
      "843:\tlearn: 0.1872815\ttotal: 30.6s\tremaining: 5.65s\n",
      "844:\tlearn: 0.1871140\ttotal: 30.6s\tremaining: 5.62s\n",
      "845:\tlearn: 0.1869638\ttotal: 30.6s\tremaining: 5.58s\n",
      "846:\tlearn: 0.1868829\ttotal: 30.7s\tremaining: 5.54s\n",
      "847:\tlearn: 0.1867642\ttotal: 30.7s\tremaining: 5.5s\n",
      "848:\tlearn: 0.1865682\ttotal: 30.8s\tremaining: 5.47s\n",
      "849:\tlearn: 0.1864528\ttotal: 30.8s\tremaining: 5.43s\n",
      "850:\tlearn: 0.1863201\ttotal: 30.8s\tremaining: 5.4s\n",
      "851:\tlearn: 0.1861592\ttotal: 30.9s\tremaining: 5.36s\n",
      "852:\tlearn: 0.1859975\ttotal: 30.9s\tremaining: 5.33s\n",
      "853:\tlearn: 0.1857936\ttotal: 30.9s\tremaining: 5.29s\n",
      "854:\tlearn: 0.1856058\ttotal: 31s\tremaining: 5.25s\n",
      "855:\tlearn: 0.1855042\ttotal: 31s\tremaining: 5.22s\n",
      "856:\tlearn: 0.1854347\ttotal: 31s\tremaining: 5.18s\n",
      "857:\tlearn: 0.1853961\ttotal: 31.1s\tremaining: 5.14s\n",
      "858:\tlearn: 0.1853249\ttotal: 31.1s\tremaining: 5.11s\n",
      "859:\tlearn: 0.1852620\ttotal: 31.2s\tremaining: 5.07s\n",
      "860:\tlearn: 0.1852094\ttotal: 31.2s\tremaining: 5.04s\n",
      "861:\tlearn: 0.1851405\ttotal: 31.2s\tremaining: 5s\n",
      "862:\tlearn: 0.1850180\ttotal: 31.3s\tremaining: 4.96s\n",
      "863:\tlearn: 0.1849328\ttotal: 31.3s\tremaining: 4.93s\n",
      "864:\tlearn: 0.1847992\ttotal: 31.3s\tremaining: 4.89s\n",
      "865:\tlearn: 0.1847169\ttotal: 31.4s\tremaining: 4.85s\n",
      "866:\tlearn: 0.1845783\ttotal: 31.4s\tremaining: 4.82s\n",
      "867:\tlearn: 0.1845000\ttotal: 31.4s\tremaining: 4.78s\n",
      "868:\tlearn: 0.1844386\ttotal: 31.5s\tremaining: 4.75s\n",
      "869:\tlearn: 0.1843559\ttotal: 31.5s\tremaining: 4.71s\n",
      "870:\tlearn: 0.1842250\ttotal: 31.6s\tremaining: 4.67s\n",
      "871:\tlearn: 0.1841126\ttotal: 31.6s\tremaining: 4.64s\n",
      "872:\tlearn: 0.1840426\ttotal: 31.6s\tremaining: 4.6s\n",
      "873:\tlearn: 0.1839286\ttotal: 31.7s\tremaining: 4.56s\n",
      "874:\tlearn: 0.1838458\ttotal: 31.7s\tremaining: 4.53s\n",
      "875:\tlearn: 0.1836861\ttotal: 31.7s\tremaining: 4.49s\n",
      "876:\tlearn: 0.1836021\ttotal: 31.8s\tremaining: 4.46s\n",
      "877:\tlearn: 0.1834871\ttotal: 31.8s\tremaining: 4.42s\n",
      "878:\tlearn: 0.1834223\ttotal: 31.8s\tremaining: 4.38s\n",
      "879:\tlearn: 0.1833236\ttotal: 31.9s\tremaining: 4.35s\n",
      "880:\tlearn: 0.1832566\ttotal: 31.9s\tremaining: 4.31s\n",
      "881:\tlearn: 0.1831795\ttotal: 31.9s\tremaining: 4.27s\n",
      "882:\tlearn: 0.1831274\ttotal: 32s\tremaining: 4.24s\n",
      "883:\tlearn: 0.1830451\ttotal: 32s\tremaining: 4.2s\n",
      "884:\tlearn: 0.1829006\ttotal: 32.1s\tremaining: 4.17s\n",
      "885:\tlearn: 0.1827949\ttotal: 32.1s\tremaining: 4.13s\n",
      "886:\tlearn: 0.1826544\ttotal: 32.1s\tremaining: 4.09s\n",
      "887:\tlearn: 0.1825464\ttotal: 32.2s\tremaining: 4.06s\n",
      "888:\tlearn: 0.1823869\ttotal: 32.2s\tremaining: 4.02s\n",
      "889:\tlearn: 0.1822901\ttotal: 32.2s\tremaining: 3.98s\n",
      "890:\tlearn: 0.1822059\ttotal: 32.3s\tremaining: 3.95s\n",
      "891:\tlearn: 0.1820866\ttotal: 32.3s\tremaining: 3.91s\n",
      "892:\tlearn: 0.1818929\ttotal: 32.4s\tremaining: 3.88s\n",
      "893:\tlearn: 0.1817191\ttotal: 32.4s\tremaining: 3.84s\n",
      "894:\tlearn: 0.1816146\ttotal: 32.4s\tremaining: 3.8s\n",
      "895:\tlearn: 0.1815094\ttotal: 32.5s\tremaining: 3.77s\n",
      "896:\tlearn: 0.1814121\ttotal: 32.5s\tremaining: 3.73s\n",
      "897:\tlearn: 0.1812575\ttotal: 32.5s\tremaining: 3.69s\n",
      "898:\tlearn: 0.1811609\ttotal: 32.6s\tremaining: 3.66s\n",
      "899:\tlearn: 0.1810754\ttotal: 32.6s\tremaining: 3.62s\n",
      "900:\tlearn: 0.1810237\ttotal: 32.6s\tremaining: 3.58s\n",
      "901:\tlearn: 0.1808537\ttotal: 32.7s\tremaining: 3.55s\n",
      "902:\tlearn: 0.1807240\ttotal: 32.7s\tremaining: 3.51s\n",
      "903:\tlearn: 0.1806501\ttotal: 32.7s\tremaining: 3.48s\n",
      "904:\tlearn: 0.1804588\ttotal: 32.8s\tremaining: 3.44s\n",
      "905:\tlearn: 0.1803317\ttotal: 32.8s\tremaining: 3.4s\n",
      "906:\tlearn: 0.1802346\ttotal: 32.8s\tremaining: 3.37s\n",
      "907:\tlearn: 0.1801819\ttotal: 32.9s\tremaining: 3.33s\n",
      "908:\tlearn: 0.1800914\ttotal: 32.9s\tremaining: 3.29s\n",
      "909:\tlearn: 0.1798985\ttotal: 33s\tremaining: 3.26s\n",
      "910:\tlearn: 0.1798785\ttotal: 33s\tremaining: 3.22s\n",
      "911:\tlearn: 0.1797449\ttotal: 33s\tremaining: 3.19s\n",
      "912:\tlearn: 0.1797027\ttotal: 33.1s\tremaining: 3.15s\n",
      "913:\tlearn: 0.1796250\ttotal: 33.1s\tremaining: 3.11s\n",
      "914:\tlearn: 0.1795714\ttotal: 33.1s\tremaining: 3.08s\n",
      "915:\tlearn: 0.1794738\ttotal: 33.2s\tremaining: 3.04s\n",
      "916:\tlearn: 0.1794518\ttotal: 33.2s\tremaining: 3s\n",
      "917:\tlearn: 0.1792949\ttotal: 33.2s\tremaining: 2.97s\n",
      "918:\tlearn: 0.1792143\ttotal: 33.3s\tremaining: 2.93s\n",
      "919:\tlearn: 0.1790604\ttotal: 33.3s\tremaining: 2.9s\n",
      "920:\tlearn: 0.1789204\ttotal: 33.3s\tremaining: 2.86s\n",
      "921:\tlearn: 0.1788514\ttotal: 33.4s\tremaining: 2.82s\n",
      "922:\tlearn: 0.1787269\ttotal: 33.4s\tremaining: 2.79s\n",
      "923:\tlearn: 0.1786158\ttotal: 33.4s\tremaining: 2.75s\n",
      "924:\tlearn: 0.1785731\ttotal: 33.5s\tremaining: 2.71s\n",
      "925:\tlearn: 0.1784720\ttotal: 33.5s\tremaining: 2.68s\n",
      "926:\tlearn: 0.1783859\ttotal: 33.5s\tremaining: 2.64s\n",
      "927:\tlearn: 0.1782779\ttotal: 33.6s\tremaining: 2.6s\n",
      "928:\tlearn: 0.1782168\ttotal: 33.6s\tremaining: 2.57s\n",
      "929:\tlearn: 0.1780929\ttotal: 33.7s\tremaining: 2.53s\n",
      "930:\tlearn: 0.1780049\ttotal: 33.7s\tremaining: 2.5s\n",
      "931:\tlearn: 0.1778870\ttotal: 33.7s\tremaining: 2.46s\n",
      "932:\tlearn: 0.1777940\ttotal: 33.8s\tremaining: 2.42s\n",
      "933:\tlearn: 0.1776945\ttotal: 33.8s\tremaining: 2.39s\n",
      "934:\tlearn: 0.1776183\ttotal: 33.8s\tremaining: 2.35s\n",
      "935:\tlearn: 0.1774979\ttotal: 33.9s\tremaining: 2.32s\n",
      "936:\tlearn: 0.1774305\ttotal: 33.9s\tremaining: 2.28s\n",
      "937:\tlearn: 0.1773363\ttotal: 34s\tremaining: 2.24s\n",
      "938:\tlearn: 0.1773108\ttotal: 34s\tremaining: 2.21s\n",
      "939:\tlearn: 0.1772184\ttotal: 34s\tremaining: 2.17s\n",
      "940:\tlearn: 0.1771468\ttotal: 34.1s\tremaining: 2.13s\n",
      "941:\tlearn: 0.1769585\ttotal: 34.1s\tremaining: 2.1s\n",
      "942:\tlearn: 0.1768901\ttotal: 34.1s\tremaining: 2.06s\n",
      "943:\tlearn: 0.1768053\ttotal: 34.2s\tremaining: 2.03s\n",
      "944:\tlearn: 0.1766992\ttotal: 34.2s\tremaining: 1.99s\n",
      "945:\tlearn: 0.1765774\ttotal: 34.2s\tremaining: 1.95s\n",
      "946:\tlearn: 0.1765206\ttotal: 34.3s\tremaining: 1.92s\n",
      "947:\tlearn: 0.1763339\ttotal: 34.3s\tremaining: 1.88s\n",
      "948:\tlearn: 0.1762411\ttotal: 34.4s\tremaining: 1.85s\n",
      "949:\tlearn: 0.1760719\ttotal: 34.4s\tremaining: 1.81s\n",
      "950:\tlearn: 0.1759859\ttotal: 34.4s\tremaining: 1.77s\n",
      "951:\tlearn: 0.1758754\ttotal: 34.4s\tremaining: 1.74s\n",
      "952:\tlearn: 0.1758191\ttotal: 34.5s\tremaining: 1.7s\n",
      "953:\tlearn: 0.1757184\ttotal: 34.5s\tremaining: 1.66s\n",
      "954:\tlearn: 0.1755730\ttotal: 34.6s\tremaining: 1.63s\n",
      "955:\tlearn: 0.1754836\ttotal: 34.6s\tremaining: 1.59s\n",
      "956:\tlearn: 0.1754141\ttotal: 34.6s\tremaining: 1.55s\n",
      "957:\tlearn: 0.1753710\ttotal: 34.7s\tremaining: 1.52s\n",
      "958:\tlearn: 0.1751981\ttotal: 34.7s\tremaining: 1.48s\n",
      "959:\tlearn: 0.1751356\ttotal: 34.7s\tremaining: 1.45s\n",
      "960:\tlearn: 0.1751212\ttotal: 34.8s\tremaining: 1.41s\n",
      "961:\tlearn: 0.1749736\ttotal: 34.8s\tremaining: 1.37s\n",
      "962:\tlearn: 0.1748432\ttotal: 34.8s\tremaining: 1.34s\n",
      "963:\tlearn: 0.1747354\ttotal: 34.9s\tremaining: 1.3s\n",
      "964:\tlearn: 0.1747014\ttotal: 34.9s\tremaining: 1.27s\n",
      "965:\tlearn: 0.1745797\ttotal: 35s\tremaining: 1.23s\n",
      "966:\tlearn: 0.1744423\ttotal: 35s\tremaining: 1.19s\n",
      "967:\tlearn: 0.1744064\ttotal: 35s\tremaining: 1.16s\n",
      "968:\tlearn: 0.1743569\ttotal: 35.1s\tremaining: 1.12s\n",
      "969:\tlearn: 0.1742830\ttotal: 35.1s\tremaining: 1.08s\n",
      "970:\tlearn: 0.1741853\ttotal: 35.1s\tremaining: 1.05s\n",
      "971:\tlearn: 0.1741586\ttotal: 35.2s\tremaining: 1.01s\n",
      "972:\tlearn: 0.1741180\ttotal: 35.2s\tremaining: 977ms\n",
      "973:\tlearn: 0.1740669\ttotal: 35.2s\tremaining: 941ms\n",
      "974:\tlearn: 0.1740437\ttotal: 35.3s\tremaining: 905ms\n",
      "975:\tlearn: 0.1739667\ttotal: 35.3s\tremaining: 868ms\n",
      "976:\tlearn: 0.1738101\ttotal: 35.3s\tremaining: 832ms\n",
      "977:\tlearn: 0.1737282\ttotal: 35.4s\tremaining: 796ms\n",
      "978:\tlearn: 0.1736643\ttotal: 35.4s\tremaining: 759ms\n",
      "979:\tlearn: 0.1736269\ttotal: 35.4s\tremaining: 723ms\n",
      "980:\tlearn: 0.1734920\ttotal: 35.5s\tremaining: 687ms\n",
      "981:\tlearn: 0.1733547\ttotal: 35.5s\tremaining: 651ms\n",
      "982:\tlearn: 0.1732725\ttotal: 35.6s\tremaining: 615ms\n",
      "983:\tlearn: 0.1732281\ttotal: 35.6s\tremaining: 579ms\n",
      "984:\tlearn: 0.1731435\ttotal: 35.6s\tremaining: 543ms\n",
      "985:\tlearn: 0.1731160\ttotal: 35.7s\tremaining: 506ms\n",
      "986:\tlearn: 0.1730851\ttotal: 35.7s\tremaining: 470ms\n",
      "987:\tlearn: 0.1729022\ttotal: 35.7s\tremaining: 434ms\n",
      "988:\tlearn: 0.1727013\ttotal: 35.8s\tremaining: 398ms\n",
      "989:\tlearn: 0.1725605\ttotal: 35.8s\tremaining: 362ms\n",
      "990:\tlearn: 0.1724314\ttotal: 35.8s\tremaining: 326ms\n",
      "991:\tlearn: 0.1723801\ttotal: 35.9s\tremaining: 289ms\n",
      "992:\tlearn: 0.1722211\ttotal: 35.9s\tremaining: 253ms\n",
      "993:\tlearn: 0.1721598\ttotal: 35.9s\tremaining: 217ms\n",
      "994:\tlearn: 0.1721021\ttotal: 36s\tremaining: 181ms\n",
      "995:\tlearn: 0.1720347\ttotal: 36s\tremaining: 145ms\n",
      "996:\tlearn: 0.1719427\ttotal: 36s\tremaining: 108ms\n",
      "997:\tlearn: 0.1718017\ttotal: 36.1s\tremaining: 72.3ms\n",
      "998:\tlearn: 0.1717594\ttotal: 36.1s\tremaining: 36.1ms\n",
      "999:\tlearn: 0.1716846\ttotal: 36.1s\tremaining: 0us\n",
      "Learning rate set to 0.091926\n",
      "0:\tlearn: 1.8351102\ttotal: 45.6ms\tremaining: 45.6s\n",
      "1:\tlearn: 1.6266459\ttotal: 85.2ms\tremaining: 42.5s\n",
      "2:\tlearn: 1.4725505\ttotal: 118ms\tremaining: 39.1s\n",
      "3:\tlearn: 1.3591596\ttotal: 152ms\tremaining: 37.9s\n",
      "4:\tlearn: 1.2726125\ttotal: 186ms\tremaining: 37.1s\n",
      "5:\tlearn: 1.2079082\ttotal: 224ms\tremaining: 37.1s\n",
      "6:\tlearn: 1.1508966\ttotal: 267ms\tremaining: 37.8s\n",
      "7:\tlearn: 1.1003921\ttotal: 311ms\tremaining: 38.6s\n",
      "8:\tlearn: 1.0405783\ttotal: 349ms\tremaining: 38.4s\n",
      "9:\tlearn: 0.9994176\ttotal: 383ms\tremaining: 37.9s\n",
      "10:\tlearn: 0.9559823\ttotal: 417ms\tremaining: 37.5s\n",
      "11:\tlearn: 0.9181646\ttotal: 451ms\tremaining: 37.1s\n",
      "12:\tlearn: 0.8906604\ttotal: 485ms\tremaining: 36.8s\n",
      "13:\tlearn: 0.8616968\ttotal: 521ms\tremaining: 36.7s\n",
      "14:\tlearn: 0.8368131\ttotal: 558ms\tremaining: 36.7s\n",
      "15:\tlearn: 0.8131828\ttotal: 595ms\tremaining: 36.6s\n",
      "16:\tlearn: 0.7931996\ttotal: 635ms\tremaining: 36.7s\n",
      "17:\tlearn: 0.7706194\ttotal: 680ms\tremaining: 37.1s\n",
      "18:\tlearn: 0.7485175\ttotal: 714ms\tremaining: 36.9s\n",
      "19:\tlearn: 0.7333724\ttotal: 748ms\tremaining: 36.7s\n",
      "20:\tlearn: 0.7138266\ttotal: 784ms\tremaining: 36.6s\n",
      "21:\tlearn: 0.6995496\ttotal: 816ms\tremaining: 36.3s\n",
      "22:\tlearn: 0.6854142\ttotal: 850ms\tremaining: 36.1s\n",
      "23:\tlearn: 0.6726605\ttotal: 892ms\tremaining: 36.3s\n",
      "24:\tlearn: 0.6612263\ttotal: 935ms\tremaining: 36.5s\n",
      "25:\tlearn: 0.6471218\ttotal: 985ms\tremaining: 36.9s\n",
      "26:\tlearn: 0.6377858\ttotal: 1.02s\tremaining: 36.7s\n",
      "27:\tlearn: 0.6245258\ttotal: 1.05s\tremaining: 36.6s\n",
      "28:\tlearn: 0.6169962\ttotal: 1.09s\tremaining: 36.4s\n",
      "29:\tlearn: 0.6068908\ttotal: 1.12s\tremaining: 36.1s\n",
      "30:\tlearn: 0.5975366\ttotal: 1.15s\tremaining: 36s\n",
      "31:\tlearn: 0.5886268\ttotal: 1.19s\tremaining: 35.9s\n",
      "32:\tlearn: 0.5818264\ttotal: 1.23s\tremaining: 35.9s\n",
      "33:\tlearn: 0.5744273\ttotal: 1.26s\tremaining: 35.7s\n",
      "34:\tlearn: 0.5708047\ttotal: 1.29s\tremaining: 35.7s\n",
      "35:\tlearn: 0.5615540\ttotal: 1.34s\tremaining: 35.8s\n",
      "36:\tlearn: 0.5559432\ttotal: 1.37s\tremaining: 35.7s\n",
      "37:\tlearn: 0.5480279\ttotal: 1.41s\tremaining: 35.6s\n",
      "38:\tlearn: 0.5421493\ttotal: 1.44s\tremaining: 35.4s\n",
      "39:\tlearn: 0.5359944\ttotal: 1.48s\tremaining: 35.4s\n",
      "40:\tlearn: 0.5310739\ttotal: 1.51s\tremaining: 35.3s\n",
      "41:\tlearn: 0.5265812\ttotal: 1.55s\tremaining: 35.4s\n",
      "42:\tlearn: 0.5244504\ttotal: 1.6s\tremaining: 35.5s\n",
      "43:\tlearn: 0.5201963\ttotal: 1.64s\tremaining: 35.5s\n",
      "44:\tlearn: 0.5159938\ttotal: 1.67s\tremaining: 35.4s\n",
      "45:\tlearn: 0.5115827\ttotal: 1.71s\tremaining: 35.5s\n",
      "46:\tlearn: 0.5070914\ttotal: 1.75s\tremaining: 35.5s\n",
      "47:\tlearn: 0.5041815\ttotal: 1.78s\tremaining: 35.4s\n",
      "48:\tlearn: 0.4998300\ttotal: 1.82s\tremaining: 35.2s\n",
      "49:\tlearn: 0.4955966\ttotal: 1.85s\tremaining: 35.1s\n",
      "50:\tlearn: 0.4927297\ttotal: 1.88s\tremaining: 35s\n",
      "51:\tlearn: 0.4900973\ttotal: 1.91s\tremaining: 34.9s\n",
      "52:\tlearn: 0.4871346\ttotal: 1.97s\tremaining: 35.1s\n",
      "53:\tlearn: 0.4836092\ttotal: 2.01s\tremaining: 35.2s\n",
      "54:\tlearn: 0.4812475\ttotal: 2.04s\tremaining: 35.1s\n",
      "55:\tlearn: 0.4779574\ttotal: 2.08s\tremaining: 35s\n",
      "56:\tlearn: 0.4747875\ttotal: 2.11s\tremaining: 34.9s\n",
      "57:\tlearn: 0.4712498\ttotal: 2.14s\tremaining: 34.8s\n",
      "58:\tlearn: 0.4697405\ttotal: 2.17s\tremaining: 34.7s\n",
      "59:\tlearn: 0.4659573\ttotal: 2.21s\tremaining: 34.7s\n",
      "60:\tlearn: 0.4641016\ttotal: 2.25s\tremaining: 34.6s\n",
      "61:\tlearn: 0.4614464\ttotal: 2.28s\tremaining: 34.6s\n",
      "62:\tlearn: 0.4601324\ttotal: 2.33s\tremaining: 34.6s\n",
      "63:\tlearn: 0.4568660\ttotal: 2.36s\tremaining: 34.5s\n",
      "64:\tlearn: 0.4539507\ttotal: 2.39s\tremaining: 34.4s\n",
      "65:\tlearn: 0.4523531\ttotal: 2.42s\tremaining: 34.3s\n",
      "66:\tlearn: 0.4506405\ttotal: 2.46s\tremaining: 34.3s\n",
      "67:\tlearn: 0.4473539\ttotal: 2.49s\tremaining: 34.2s\n",
      "68:\tlearn: 0.4445490\ttotal: 2.53s\tremaining: 34.1s\n",
      "69:\tlearn: 0.4417856\ttotal: 2.58s\tremaining: 34.3s\n",
      "70:\tlearn: 0.4399411\ttotal: 2.62s\tremaining: 34.3s\n",
      "71:\tlearn: 0.4380220\ttotal: 2.65s\tremaining: 34.1s\n",
      "72:\tlearn: 0.4356890\ttotal: 2.68s\tremaining: 34.1s\n",
      "73:\tlearn: 0.4336024\ttotal: 2.71s\tremaining: 33.9s\n",
      "74:\tlearn: 0.4318485\ttotal: 2.74s\tremaining: 33.8s\n",
      "75:\tlearn: 0.4298671\ttotal: 2.78s\tremaining: 33.8s\n",
      "76:\tlearn: 0.4285402\ttotal: 2.81s\tremaining: 33.7s\n",
      "77:\tlearn: 0.4277363\ttotal: 2.85s\tremaining: 33.7s\n",
      "78:\tlearn: 0.4263672\ttotal: 2.88s\tremaining: 33.6s\n",
      "79:\tlearn: 0.4253005\ttotal: 2.93s\tremaining: 33.7s\n",
      "80:\tlearn: 0.4236508\ttotal: 2.97s\tremaining: 33.7s\n",
      "81:\tlearn: 0.4222996\ttotal: 3s\tremaining: 33.6s\n",
      "82:\tlearn: 0.4198852\ttotal: 3.04s\tremaining: 33.6s\n",
      "83:\tlearn: 0.4183083\ttotal: 3.07s\tremaining: 33.5s\n",
      "84:\tlearn: 0.4163748\ttotal: 3.11s\tremaining: 33.5s\n",
      "85:\tlearn: 0.4149827\ttotal: 3.14s\tremaining: 33.4s\n",
      "86:\tlearn: 0.4140248\ttotal: 3.19s\tremaining: 33.4s\n",
      "87:\tlearn: 0.4124428\ttotal: 3.23s\tremaining: 33.4s\n",
      "88:\tlearn: 0.4113974\ttotal: 3.26s\tremaining: 33.4s\n",
      "89:\tlearn: 0.4096325\ttotal: 3.29s\tremaining: 33.3s\n",
      "90:\tlearn: 0.4085553\ttotal: 3.32s\tremaining: 33.2s\n",
      "91:\tlearn: 0.4068262\ttotal: 3.35s\tremaining: 33.1s\n",
      "92:\tlearn: 0.4054647\ttotal: 3.39s\tremaining: 33.1s\n",
      "93:\tlearn: 0.4032645\ttotal: 3.43s\tremaining: 33.1s\n",
      "94:\tlearn: 0.4010035\ttotal: 3.47s\tremaining: 33s\n",
      "95:\tlearn: 0.3999978\ttotal: 3.5s\tremaining: 33s\n",
      "96:\tlearn: 0.3993179\ttotal: 3.54s\tremaining: 33s\n",
      "97:\tlearn: 0.3979229\ttotal: 3.59s\tremaining: 33s\n",
      "98:\tlearn: 0.3966298\ttotal: 3.62s\tremaining: 32.9s\n",
      "99:\tlearn: 0.3946298\ttotal: 3.65s\tremaining: 32.9s\n",
      "100:\tlearn: 0.3934957\ttotal: 3.69s\tremaining: 32.8s\n",
      "101:\tlearn: 0.3913893\ttotal: 3.72s\tremaining: 32.8s\n",
      "102:\tlearn: 0.3897545\ttotal: 3.76s\tremaining: 32.7s\n",
      "103:\tlearn: 0.3882480\ttotal: 3.8s\tremaining: 32.7s\n",
      "104:\tlearn: 0.3872153\ttotal: 3.85s\tremaining: 32.8s\n",
      "105:\tlearn: 0.3866030\ttotal: 3.88s\tremaining: 32.7s\n",
      "106:\tlearn: 0.3855540\ttotal: 3.92s\tremaining: 32.7s\n",
      "107:\tlearn: 0.3847353\ttotal: 3.95s\tremaining: 32.6s\n",
      "108:\tlearn: 0.3843436\ttotal: 3.98s\tremaining: 32.5s\n",
      "109:\tlearn: 0.3826326\ttotal: 4.01s\tremaining: 32.5s\n",
      "110:\tlearn: 0.3812934\ttotal: 4.05s\tremaining: 32.4s\n",
      "111:\tlearn: 0.3803024\ttotal: 4.09s\tremaining: 32.4s\n",
      "112:\tlearn: 0.3794714\ttotal: 4.12s\tremaining: 32.4s\n",
      "113:\tlearn: 0.3790258\ttotal: 4.16s\tremaining: 32.3s\n",
      "114:\tlearn: 0.3782341\ttotal: 4.2s\tremaining: 32.3s\n",
      "115:\tlearn: 0.3772326\ttotal: 4.24s\tremaining: 32.3s\n",
      "116:\tlearn: 0.3765442\ttotal: 4.27s\tremaining: 32.2s\n",
      "117:\tlearn: 0.3760342\ttotal: 4.3s\tremaining: 32.2s\n",
      "118:\tlearn: 0.3749612\ttotal: 4.33s\tremaining: 32.1s\n",
      "119:\tlearn: 0.3738937\ttotal: 4.37s\tremaining: 32s\n",
      "120:\tlearn: 0.3727834\ttotal: 4.4s\tremaining: 32s\n",
      "121:\tlearn: 0.3720011\ttotal: 4.45s\tremaining: 32s\n",
      "122:\tlearn: 0.3713703\ttotal: 4.5s\tremaining: 32.1s\n",
      "123:\tlearn: 0.3706175\ttotal: 4.53s\tremaining: 32s\n",
      "124:\tlearn: 0.3699411\ttotal: 4.56s\tremaining: 31.9s\n",
      "125:\tlearn: 0.3688988\ttotal: 4.59s\tremaining: 31.8s\n",
      "126:\tlearn: 0.3679066\ttotal: 4.62s\tremaining: 31.8s\n",
      "127:\tlearn: 0.3672117\ttotal: 4.65s\tremaining: 31.7s\n",
      "128:\tlearn: 0.3666253\ttotal: 4.69s\tremaining: 31.6s\n",
      "129:\tlearn: 0.3656414\ttotal: 4.72s\tremaining: 31.6s\n",
      "130:\tlearn: 0.3651589\ttotal: 4.76s\tremaining: 31.6s\n",
      "131:\tlearn: 0.3639367\ttotal: 4.8s\tremaining: 31.5s\n",
      "132:\tlearn: 0.3628997\ttotal: 4.84s\tremaining: 31.5s\n",
      "133:\tlearn: 0.3616564\ttotal: 4.87s\tremaining: 31.5s\n",
      "134:\tlearn: 0.3611137\ttotal: 4.91s\tremaining: 31.4s\n",
      "135:\tlearn: 0.3609506\ttotal: 4.93s\tremaining: 31.4s\n",
      "136:\tlearn: 0.3599827\ttotal: 4.97s\tremaining: 31.3s\n",
      "137:\tlearn: 0.3587565\ttotal: 5s\tremaining: 31.3s\n",
      "138:\tlearn: 0.3573572\ttotal: 5.04s\tremaining: 31.2s\n",
      "139:\tlearn: 0.3568448\ttotal: 5.08s\tremaining: 31.2s\n",
      "140:\tlearn: 0.3565974\ttotal: 5.13s\tremaining: 31.2s\n",
      "141:\tlearn: 0.3564297\ttotal: 5.16s\tremaining: 31.2s\n",
      "142:\tlearn: 0.3560792\ttotal: 5.19s\tremaining: 31.1s\n",
      "143:\tlearn: 0.3558670\ttotal: 5.22s\tremaining: 31s\n",
      "144:\tlearn: 0.3555182\ttotal: 5.25s\tremaining: 30.9s\n",
      "145:\tlearn: 0.3546681\ttotal: 5.28s\tremaining: 30.9s\n",
      "146:\tlearn: 0.3536952\ttotal: 5.31s\tremaining: 30.8s\n",
      "147:\tlearn: 0.3527351\ttotal: 5.35s\tremaining: 30.8s\n",
      "148:\tlearn: 0.3523605\ttotal: 5.39s\tremaining: 30.8s\n",
      "149:\tlearn: 0.3517776\ttotal: 5.42s\tremaining: 30.7s\n",
      "150:\tlearn: 0.3511944\ttotal: 5.46s\tremaining: 30.7s\n",
      "151:\tlearn: 0.3504285\ttotal: 5.49s\tremaining: 30.6s\n",
      "152:\tlearn: 0.3498708\ttotal: 5.52s\tremaining: 30.6s\n",
      "153:\tlearn: 0.3493727\ttotal: 5.56s\tremaining: 30.5s\n",
      "154:\tlearn: 0.3491663\ttotal: 5.59s\tremaining: 30.5s\n",
      "155:\tlearn: 0.3485598\ttotal: 5.62s\tremaining: 30.4s\n",
      "156:\tlearn: 0.3478865\ttotal: 5.65s\tremaining: 30.4s\n",
      "157:\tlearn: 0.3467987\ttotal: 5.69s\tremaining: 30.3s\n",
      "158:\tlearn: 0.3460140\ttotal: 5.73s\tremaining: 30.3s\n",
      "159:\tlearn: 0.3457837\ttotal: 5.77s\tremaining: 30.3s\n",
      "160:\tlearn: 0.3449034\ttotal: 5.81s\tremaining: 30.3s\n",
      "161:\tlearn: 0.3445875\ttotal: 5.84s\tremaining: 30.2s\n",
      "162:\tlearn: 0.3440481\ttotal: 5.87s\tremaining: 30.2s\n",
      "163:\tlearn: 0.3436387\ttotal: 5.9s\tremaining: 30.1s\n",
      "164:\tlearn: 0.3432572\ttotal: 5.93s\tremaining: 30s\n",
      "165:\tlearn: 0.3426850\ttotal: 5.97s\tremaining: 30s\n",
      "166:\tlearn: 0.3423822\ttotal: 6s\tremaining: 29.9s\n",
      "167:\tlearn: 0.3420999\ttotal: 6.04s\tremaining: 29.9s\n",
      "168:\tlearn: 0.3413454\ttotal: 6.08s\tremaining: 29.9s\n",
      "169:\tlearn: 0.3407624\ttotal: 6.12s\tremaining: 29.9s\n",
      "170:\tlearn: 0.3404627\ttotal: 6.15s\tremaining: 29.8s\n",
      "171:\tlearn: 0.3396402\ttotal: 6.18s\tremaining: 29.8s\n",
      "172:\tlearn: 0.3385071\ttotal: 6.22s\tremaining: 29.7s\n",
      "173:\tlearn: 0.3379189\ttotal: 6.25s\tremaining: 29.7s\n",
      "174:\tlearn: 0.3370827\ttotal: 6.29s\tremaining: 29.6s\n",
      "175:\tlearn: 0.3369902\ttotal: 6.33s\tremaining: 29.6s\n",
      "176:\tlearn: 0.3362421\ttotal: 6.38s\tremaining: 29.7s\n",
      "177:\tlearn: 0.3357583\ttotal: 6.41s\tremaining: 29.6s\n",
      "178:\tlearn: 0.3351603\ttotal: 6.44s\tremaining: 29.6s\n",
      "179:\tlearn: 0.3340997\ttotal: 6.48s\tremaining: 29.5s\n",
      "180:\tlearn: 0.3338209\ttotal: 6.51s\tremaining: 29.5s\n",
      "181:\tlearn: 0.3333364\ttotal: 6.54s\tremaining: 29.4s\n",
      "182:\tlearn: 0.3331744\ttotal: 6.57s\tremaining: 29.3s\n",
      "183:\tlearn: 0.3329436\ttotal: 6.61s\tremaining: 29.3s\n",
      "184:\tlearn: 0.3322475\ttotal: 6.64s\tremaining: 29.3s\n",
      "185:\tlearn: 0.3316291\ttotal: 6.69s\tremaining: 29.3s\n",
      "186:\tlearn: 0.3309712\ttotal: 6.72s\tremaining: 29.2s\n",
      "187:\tlearn: 0.3308526\ttotal: 6.75s\tremaining: 29.2s\n",
      "188:\tlearn: 0.3304637\ttotal: 6.79s\tremaining: 29.1s\n",
      "189:\tlearn: 0.3296669\ttotal: 6.82s\tremaining: 29.1s\n",
      "190:\tlearn: 0.3291259\ttotal: 6.85s\tremaining: 29s\n",
      "191:\tlearn: 0.3289607\ttotal: 6.88s\tremaining: 29s\n",
      "192:\tlearn: 0.3284288\ttotal: 6.92s\tremaining: 28.9s\n",
      "193:\tlearn: 0.3279835\ttotal: 6.96s\tremaining: 28.9s\n",
      "194:\tlearn: 0.3271859\ttotal: 7.01s\tremaining: 28.9s\n",
      "195:\tlearn: 0.3262645\ttotal: 7.05s\tremaining: 28.9s\n",
      "196:\tlearn: 0.3257581\ttotal: 7.08s\tremaining: 28.9s\n",
      "197:\tlearn: 0.3255492\ttotal: 7.12s\tremaining: 28.9s\n",
      "198:\tlearn: 0.3240916\ttotal: 7.16s\tremaining: 28.8s\n",
      "199:\tlearn: 0.3233848\ttotal: 7.2s\tremaining: 28.8s\n",
      "200:\tlearn: 0.3226950\ttotal: 7.23s\tremaining: 28.8s\n",
      "201:\tlearn: 0.3224685\ttotal: 7.26s\tremaining: 28.7s\n",
      "202:\tlearn: 0.3219768\ttotal: 7.3s\tremaining: 28.6s\n",
      "203:\tlearn: 0.3217211\ttotal: 7.34s\tremaining: 28.6s\n",
      "204:\tlearn: 0.3212842\ttotal: 7.38s\tremaining: 28.6s\n",
      "205:\tlearn: 0.3207039\ttotal: 7.42s\tremaining: 28.6s\n",
      "206:\tlearn: 0.3202093\ttotal: 7.45s\tremaining: 28.5s\n",
      "207:\tlearn: 0.3199157\ttotal: 7.49s\tremaining: 28.5s\n",
      "208:\tlearn: 0.3196723\ttotal: 7.52s\tremaining: 28.4s\n",
      "209:\tlearn: 0.3193556\ttotal: 7.55s\tremaining: 28.4s\n",
      "210:\tlearn: 0.3185822\ttotal: 7.58s\tremaining: 28.4s\n",
      "211:\tlearn: 0.3185488\ttotal: 7.62s\tremaining: 28.3s\n",
      "212:\tlearn: 0.3183650\ttotal: 7.65s\tremaining: 28.3s\n",
      "213:\tlearn: 0.3182033\ttotal: 7.68s\tremaining: 28.2s\n",
      "214:\tlearn: 0.3173689\ttotal: 7.73s\tremaining: 28.2s\n",
      "215:\tlearn: 0.3167621\ttotal: 7.76s\tremaining: 28.2s\n",
      "216:\tlearn: 0.3164406\ttotal: 7.8s\tremaining: 28.1s\n",
      "217:\tlearn: 0.3158691\ttotal: 7.83s\tremaining: 28.1s\n",
      "218:\tlearn: 0.3153894\ttotal: 7.86s\tremaining: 28s\n",
      "219:\tlearn: 0.3150514\ttotal: 7.89s\tremaining: 28s\n",
      "220:\tlearn: 0.3149851\ttotal: 7.92s\tremaining: 27.9s\n",
      "221:\tlearn: 0.3144833\ttotal: 7.97s\tremaining: 27.9s\n",
      "222:\tlearn: 0.3137016\ttotal: 8.03s\tremaining: 28s\n",
      "223:\tlearn: 0.3130207\ttotal: 8.06s\tremaining: 27.9s\n",
      "224:\tlearn: 0.3127183\ttotal: 8.1s\tremaining: 27.9s\n",
      "225:\tlearn: 0.3123558\ttotal: 8.14s\tremaining: 27.9s\n",
      "226:\tlearn: 0.3120672\ttotal: 8.17s\tremaining: 27.8s\n",
      "227:\tlearn: 0.3117026\ttotal: 8.21s\tremaining: 27.8s\n",
      "228:\tlearn: 0.3115111\ttotal: 8.23s\tremaining: 27.7s\n",
      "229:\tlearn: 0.3110486\ttotal: 8.27s\tremaining: 27.7s\n",
      "230:\tlearn: 0.3106255\ttotal: 8.3s\tremaining: 27.6s\n",
      "231:\tlearn: 0.3103576\ttotal: 8.33s\tremaining: 27.6s\n",
      "232:\tlearn: 0.3100762\ttotal: 8.38s\tremaining: 27.6s\n",
      "233:\tlearn: 0.3098510\ttotal: 8.43s\tremaining: 27.6s\n",
      "234:\tlearn: 0.3094999\ttotal: 8.46s\tremaining: 27.5s\n",
      "235:\tlearn: 0.3093839\ttotal: 8.49s\tremaining: 27.5s\n",
      "236:\tlearn: 0.3086839\ttotal: 8.52s\tremaining: 27.4s\n",
      "237:\tlearn: 0.3083865\ttotal: 8.55s\tremaining: 27.4s\n",
      "238:\tlearn: 0.3079423\ttotal: 8.59s\tremaining: 27.3s\n",
      "239:\tlearn: 0.3073241\ttotal: 8.62s\tremaining: 27.3s\n",
      "240:\tlearn: 0.3070776\ttotal: 8.66s\tremaining: 27.3s\n",
      "241:\tlearn: 0.3065997\ttotal: 8.69s\tremaining: 27.2s\n",
      "242:\tlearn: 0.3062529\ttotal: 8.73s\tremaining: 27.2s\n",
      "243:\tlearn: 0.3056872\ttotal: 8.77s\tremaining: 27.2s\n",
      "244:\tlearn: 0.3049912\ttotal: 8.8s\tremaining: 27.1s\n",
      "245:\tlearn: 0.3045919\ttotal: 8.84s\tremaining: 27.1s\n",
      "246:\tlearn: 0.3044887\ttotal: 8.87s\tremaining: 27s\n",
      "247:\tlearn: 0.3042210\ttotal: 8.9s\tremaining: 27s\n",
      "248:\tlearn: 0.3036398\ttotal: 8.93s\tremaining: 26.9s\n",
      "249:\tlearn: 0.3034907\ttotal: 8.98s\tremaining: 26.9s\n",
      "250:\tlearn: 0.3027702\ttotal: 9.03s\tremaining: 27s\n",
      "251:\tlearn: 0.3022911\ttotal: 9.07s\tremaining: 26.9s\n",
      "252:\tlearn: 0.3020108\ttotal: 9.1s\tremaining: 26.9s\n",
      "253:\tlearn: 0.3015879\ttotal: 9.13s\tremaining: 26.8s\n",
      "254:\tlearn: 0.3013302\ttotal: 9.16s\tremaining: 26.8s\n",
      "255:\tlearn: 0.3008612\ttotal: 9.2s\tremaining: 26.7s\n",
      "256:\tlearn: 0.3005953\ttotal: 9.24s\tremaining: 26.7s\n",
      "257:\tlearn: 0.2999539\ttotal: 9.28s\tremaining: 26.7s\n",
      "258:\tlearn: 0.2998070\ttotal: 9.31s\tremaining: 26.6s\n",
      "259:\tlearn: 0.2991128\ttotal: 9.35s\tremaining: 26.6s\n",
      "260:\tlearn: 0.2989772\ttotal: 9.39s\tremaining: 26.6s\n",
      "261:\tlearn: 0.2987404\ttotal: 9.42s\tremaining: 26.5s\n",
      "262:\tlearn: 0.2983191\ttotal: 9.45s\tremaining: 26.5s\n",
      "263:\tlearn: 0.2980943\ttotal: 9.48s\tremaining: 26.4s\n",
      "264:\tlearn: 0.2976150\ttotal: 9.52s\tremaining: 26.4s\n",
      "265:\tlearn: 0.2973242\ttotal: 9.56s\tremaining: 26.4s\n",
      "266:\tlearn: 0.2968583\ttotal: 9.6s\tremaining: 26.4s\n",
      "267:\tlearn: 0.2964262\ttotal: 9.64s\tremaining: 26.3s\n",
      "268:\tlearn: 0.2960824\ttotal: 9.68s\tremaining: 26.3s\n",
      "269:\tlearn: 0.2957814\ttotal: 9.71s\tremaining: 26.2s\n",
      "270:\tlearn: 0.2954648\ttotal: 9.74s\tremaining: 26.2s\n",
      "271:\tlearn: 0.2952346\ttotal: 9.77s\tremaining: 26.1s\n",
      "272:\tlearn: 0.2948828\ttotal: 9.8s\tremaining: 26.1s\n",
      "273:\tlearn: 0.2947500\ttotal: 9.83s\tremaining: 26.1s\n",
      "274:\tlearn: 0.2939954\ttotal: 9.87s\tremaining: 26s\n",
      "275:\tlearn: 0.2938807\ttotal: 9.9s\tremaining: 26s\n",
      "276:\tlearn: 0.2933694\ttotal: 9.94s\tremaining: 25.9s\n",
      "277:\tlearn: 0.2931069\ttotal: 9.98s\tremaining: 25.9s\n",
      "278:\tlearn: 0.2929676\ttotal: 10s\tremaining: 25.9s\n",
      "279:\tlearn: 0.2926424\ttotal: 10s\tremaining: 25.8s\n",
      "280:\tlearn: 0.2925093\ttotal: 10.1s\tremaining: 25.8s\n",
      "281:\tlearn: 0.2920298\ttotal: 10.1s\tremaining: 25.8s\n",
      "282:\tlearn: 0.2917443\ttotal: 10.1s\tremaining: 25.7s\n",
      "283:\tlearn: 0.2915786\ttotal: 10.2s\tremaining: 25.7s\n",
      "284:\tlearn: 0.2912701\ttotal: 10.2s\tremaining: 25.7s\n",
      "285:\tlearn: 0.2907144\ttotal: 10.3s\tremaining: 25.6s\n",
      "286:\tlearn: 0.2904883\ttotal: 10.3s\tremaining: 25.6s\n",
      "287:\tlearn: 0.2902189\ttotal: 10.3s\tremaining: 25.6s\n",
      "288:\tlearn: 0.2900422\ttotal: 10.4s\tremaining: 25.5s\n",
      "289:\tlearn: 0.2897120\ttotal: 10.4s\tremaining: 25.5s\n",
      "290:\tlearn: 0.2896601\ttotal: 10.4s\tremaining: 25.4s\n",
      "291:\tlearn: 0.2893800\ttotal: 10.5s\tremaining: 25.4s\n",
      "292:\tlearn: 0.2889050\ttotal: 10.5s\tremaining: 25.3s\n",
      "293:\tlearn: 0.2887469\ttotal: 10.5s\tremaining: 25.3s\n",
      "294:\tlearn: 0.2884570\ttotal: 10.6s\tremaining: 25.2s\n",
      "295:\tlearn: 0.2882083\ttotal: 10.6s\tremaining: 25.2s\n",
      "296:\tlearn: 0.2877587\ttotal: 10.6s\tremaining: 25.2s\n",
      "297:\tlearn: 0.2871547\ttotal: 10.7s\tremaining: 25.1s\n",
      "298:\tlearn: 0.2869928\ttotal: 10.7s\tremaining: 25.1s\n",
      "299:\tlearn: 0.2868193\ttotal: 10.7s\tremaining: 25.1s\n",
      "300:\tlearn: 0.2866949\ttotal: 10.8s\tremaining: 25s\n",
      "301:\tlearn: 0.2861238\ttotal: 10.8s\tremaining: 25s\n",
      "302:\tlearn: 0.2859120\ttotal: 10.8s\tremaining: 24.9s\n",
      "303:\tlearn: 0.2856865\ttotal: 10.9s\tremaining: 24.9s\n",
      "304:\tlearn: 0.2853033\ttotal: 10.9s\tremaining: 24.9s\n",
      "305:\tlearn: 0.2846837\ttotal: 11s\tremaining: 24.8s\n",
      "306:\tlearn: 0.2844844\ttotal: 11s\tremaining: 24.8s\n",
      "307:\tlearn: 0.2840444\ttotal: 11s\tremaining: 24.8s\n",
      "308:\tlearn: 0.2837704\ttotal: 11.1s\tremaining: 24.7s\n",
      "309:\tlearn: 0.2833808\ttotal: 11.1s\tremaining: 24.7s\n",
      "310:\tlearn: 0.2828064\ttotal: 11.1s\tremaining: 24.7s\n",
      "311:\tlearn: 0.2823808\ttotal: 11.2s\tremaining: 24.6s\n",
      "312:\tlearn: 0.2823291\ttotal: 11.2s\tremaining: 24.6s\n",
      "313:\tlearn: 0.2817672\ttotal: 11.2s\tremaining: 24.5s\n",
      "314:\tlearn: 0.2814010\ttotal: 11.3s\tremaining: 24.5s\n",
      "315:\tlearn: 0.2808168\ttotal: 11.3s\tremaining: 24.5s\n",
      "316:\tlearn: 0.2806121\ttotal: 11.3s\tremaining: 24.4s\n",
      "317:\tlearn: 0.2805480\ttotal: 11.4s\tremaining: 24.4s\n",
      "318:\tlearn: 0.2802330\ttotal: 11.4s\tremaining: 24.4s\n",
      "319:\tlearn: 0.2799812\ttotal: 11.5s\tremaining: 24.4s\n",
      "320:\tlearn: 0.2797769\ttotal: 11.5s\tremaining: 24.3s\n",
      "321:\tlearn: 0.2795963\ttotal: 11.5s\tremaining: 24.3s\n",
      "322:\tlearn: 0.2795023\ttotal: 11.6s\tremaining: 24.2s\n",
      "323:\tlearn: 0.2792029\ttotal: 11.6s\tremaining: 24.2s\n",
      "324:\tlearn: 0.2788037\ttotal: 11.6s\tremaining: 24.1s\n",
      "325:\tlearn: 0.2786680\ttotal: 11.7s\tremaining: 24.1s\n",
      "326:\tlearn: 0.2785572\ttotal: 11.7s\tremaining: 24.1s\n",
      "327:\tlearn: 0.2782954\ttotal: 11.7s\tremaining: 24s\n",
      "328:\tlearn: 0.2778546\ttotal: 11.8s\tremaining: 24s\n",
      "329:\tlearn: 0.2777383\ttotal: 11.8s\tremaining: 24s\n",
      "330:\tlearn: 0.2775035\ttotal: 11.8s\tremaining: 23.9s\n",
      "331:\tlearn: 0.2770393\ttotal: 11.9s\tremaining: 23.9s\n",
      "332:\tlearn: 0.2766275\ttotal: 11.9s\tremaining: 23.9s\n",
      "333:\tlearn: 0.2763601\ttotal: 11.9s\tremaining: 23.8s\n",
      "334:\tlearn: 0.2760471\ttotal: 12s\tremaining: 23.8s\n",
      "335:\tlearn: 0.2756142\ttotal: 12s\tremaining: 23.8s\n",
      "336:\tlearn: 0.2753326\ttotal: 12.1s\tremaining: 23.7s\n",
      "337:\tlearn: 0.2750032\ttotal: 12.1s\tremaining: 23.7s\n",
      "338:\tlearn: 0.2746904\ttotal: 12.1s\tremaining: 23.7s\n",
      "339:\tlearn: 0.2744183\ttotal: 12.2s\tremaining: 23.6s\n",
      "340:\tlearn: 0.2742414\ttotal: 12.2s\tremaining: 23.6s\n",
      "341:\tlearn: 0.2740338\ttotal: 12.2s\tremaining: 23.6s\n",
      "342:\tlearn: 0.2734908\ttotal: 12.3s\tremaining: 23.5s\n",
      "343:\tlearn: 0.2732165\ttotal: 12.3s\tremaining: 23.5s\n",
      "344:\tlearn: 0.2730548\ttotal: 12.3s\tremaining: 23.4s\n",
      "345:\tlearn: 0.2727434\ttotal: 12.4s\tremaining: 23.4s\n",
      "346:\tlearn: 0.2725793\ttotal: 12.4s\tremaining: 23.4s\n",
      "347:\tlearn: 0.2723678\ttotal: 12.5s\tremaining: 23.3s\n",
      "348:\tlearn: 0.2720877\ttotal: 12.5s\tremaining: 23.3s\n",
      "349:\tlearn: 0.2716925\ttotal: 12.5s\tremaining: 23.3s\n",
      "350:\tlearn: 0.2712887\ttotal: 12.6s\tremaining: 23.2s\n",
      "351:\tlearn: 0.2709519\ttotal: 12.6s\tremaining: 23.2s\n",
      "352:\tlearn: 0.2704332\ttotal: 12.6s\tremaining: 23.2s\n",
      "353:\tlearn: 0.2702754\ttotal: 12.7s\tremaining: 23.1s\n",
      "354:\tlearn: 0.2699493\ttotal: 12.7s\tremaining: 23.1s\n",
      "355:\tlearn: 0.2695794\ttotal: 12.7s\tremaining: 23s\n",
      "356:\tlearn: 0.2694036\ttotal: 12.8s\tremaining: 23s\n",
      "357:\tlearn: 0.2691512\ttotal: 12.8s\tremaining: 23s\n",
      "358:\tlearn: 0.2689980\ttotal: 12.8s\tremaining: 22.9s\n",
      "359:\tlearn: 0.2689324\ttotal: 12.9s\tremaining: 22.9s\n",
      "360:\tlearn: 0.2688163\ttotal: 12.9s\tremaining: 22.9s\n",
      "361:\tlearn: 0.2683874\ttotal: 12.9s\tremaining: 22.8s\n",
      "362:\tlearn: 0.2682036\ttotal: 13s\tremaining: 22.8s\n",
      "363:\tlearn: 0.2680282\ttotal: 13s\tremaining: 22.7s\n",
      "364:\tlearn: 0.2677241\ttotal: 13s\tremaining: 22.7s\n",
      "365:\tlearn: 0.2675966\ttotal: 13.1s\tremaining: 22.7s\n",
      "366:\tlearn: 0.2671417\ttotal: 13.1s\tremaining: 22.7s\n",
      "367:\tlearn: 0.2668005\ttotal: 13.2s\tremaining: 22.6s\n",
      "368:\tlearn: 0.2664588\ttotal: 13.2s\tremaining: 22.6s\n",
      "369:\tlearn: 0.2661503\ttotal: 13.2s\tremaining: 22.5s\n",
      "370:\tlearn: 0.2658808\ttotal: 13.3s\tremaining: 22.5s\n",
      "371:\tlearn: 0.2656248\ttotal: 13.3s\tremaining: 22.5s\n",
      "372:\tlearn: 0.2654644\ttotal: 13.3s\tremaining: 22.4s\n",
      "373:\tlearn: 0.2654271\ttotal: 13.4s\tremaining: 22.4s\n",
      "374:\tlearn: 0.2651687\ttotal: 13.4s\tremaining: 22.3s\n",
      "375:\tlearn: 0.2648727\ttotal: 13.4s\tremaining: 22.3s\n",
      "376:\tlearn: 0.2647357\ttotal: 13.5s\tremaining: 22.3s\n",
      "377:\tlearn: 0.2645439\ttotal: 13.5s\tremaining: 22.2s\n",
      "378:\tlearn: 0.2641688\ttotal: 13.5s\tremaining: 22.2s\n",
      "379:\tlearn: 0.2639239\ttotal: 13.6s\tremaining: 22.2s\n",
      "380:\tlearn: 0.2636846\ttotal: 13.6s\tremaining: 22.1s\n",
      "381:\tlearn: 0.2636136\ttotal: 13.6s\tremaining: 22.1s\n",
      "382:\tlearn: 0.2634547\ttotal: 13.7s\tremaining: 22s\n",
      "383:\tlearn: 0.2633815\ttotal: 13.7s\tremaining: 22s\n",
      "384:\tlearn: 0.2632050\ttotal: 13.8s\tremaining: 22s\n",
      "385:\tlearn: 0.2629695\ttotal: 13.8s\tremaining: 21.9s\n",
      "386:\tlearn: 0.2627430\ttotal: 13.8s\tremaining: 21.9s\n",
      "387:\tlearn: 0.2625851\ttotal: 13.9s\tremaining: 21.9s\n",
      "388:\tlearn: 0.2621368\ttotal: 13.9s\tremaining: 21.8s\n",
      "389:\tlearn: 0.2619273\ttotal: 13.9s\tremaining: 21.8s\n",
      "390:\tlearn: 0.2614902\ttotal: 14s\tremaining: 21.8s\n",
      "391:\tlearn: 0.2613713\ttotal: 14s\tremaining: 21.7s\n",
      "392:\tlearn: 0.2610669\ttotal: 14s\tremaining: 21.7s\n",
      "393:\tlearn: 0.2609018\ttotal: 14.1s\tremaining: 21.7s\n",
      "394:\tlearn: 0.2606806\ttotal: 14.1s\tremaining: 21.6s\n",
      "395:\tlearn: 0.2606089\ttotal: 14.2s\tremaining: 21.6s\n",
      "396:\tlearn: 0.2604673\ttotal: 14.2s\tremaining: 21.5s\n",
      "397:\tlearn: 0.2603262\ttotal: 14.2s\tremaining: 21.5s\n",
      "398:\tlearn: 0.2600686\ttotal: 14.3s\tremaining: 21.5s\n",
      "399:\tlearn: 0.2598285\ttotal: 14.3s\tremaining: 21.4s\n",
      "400:\tlearn: 0.2596887\ttotal: 14.3s\tremaining: 21.4s\n",
      "401:\tlearn: 0.2592297\ttotal: 14.4s\tremaining: 21.4s\n",
      "402:\tlearn: 0.2590654\ttotal: 14.4s\tremaining: 21.3s\n",
      "403:\tlearn: 0.2590235\ttotal: 14.4s\tremaining: 21.3s\n",
      "404:\tlearn: 0.2588750\ttotal: 14.5s\tremaining: 21.3s\n",
      "405:\tlearn: 0.2584442\ttotal: 14.5s\tremaining: 21.2s\n",
      "406:\tlearn: 0.2581920\ttotal: 14.5s\tremaining: 21.2s\n",
      "407:\tlearn: 0.2580668\ttotal: 14.6s\tremaining: 21.2s\n",
      "408:\tlearn: 0.2579753\ttotal: 14.6s\tremaining: 21.1s\n",
      "409:\tlearn: 0.2577342\ttotal: 14.6s\tremaining: 21.1s\n",
      "410:\tlearn: 0.2574321\ttotal: 14.7s\tremaining: 21s\n",
      "411:\tlearn: 0.2573486\ttotal: 14.7s\tremaining: 21s\n",
      "412:\tlearn: 0.2571978\ttotal: 14.8s\tremaining: 21s\n",
      "413:\tlearn: 0.2570345\ttotal: 14.8s\tremaining: 20.9s\n",
      "414:\tlearn: 0.2568357\ttotal: 14.8s\tremaining: 20.9s\n",
      "415:\tlearn: 0.2567585\ttotal: 14.9s\tremaining: 20.9s\n",
      "416:\tlearn: 0.2565234\ttotal: 14.9s\tremaining: 20.8s\n",
      "417:\tlearn: 0.2564355\ttotal: 14.9s\tremaining: 20.8s\n",
      "418:\tlearn: 0.2560846\ttotal: 15s\tremaining: 20.8s\n",
      "419:\tlearn: 0.2559973\ttotal: 15s\tremaining: 20.7s\n",
      "420:\tlearn: 0.2557692\ttotal: 15s\tremaining: 20.7s\n",
      "421:\tlearn: 0.2555948\ttotal: 15.1s\tremaining: 20.7s\n",
      "422:\tlearn: 0.2551309\ttotal: 15.1s\tremaining: 20.6s\n",
      "423:\tlearn: 0.2549540\ttotal: 15.2s\tremaining: 20.6s\n",
      "424:\tlearn: 0.2547733\ttotal: 15.2s\tremaining: 20.6s\n",
      "425:\tlearn: 0.2545880\ttotal: 15.2s\tremaining: 20.5s\n",
      "426:\tlearn: 0.2543229\ttotal: 15.3s\tremaining: 20.5s\n",
      "427:\tlearn: 0.2540777\ttotal: 15.3s\tremaining: 20.4s\n",
      "428:\tlearn: 0.2536414\ttotal: 15.3s\tremaining: 20.4s\n",
      "429:\tlearn: 0.2535502\ttotal: 15.4s\tremaining: 20.4s\n",
      "430:\tlearn: 0.2533736\ttotal: 15.4s\tremaining: 20.3s\n",
      "431:\tlearn: 0.2532581\ttotal: 15.4s\tremaining: 20.3s\n",
      "432:\tlearn: 0.2529941\ttotal: 15.5s\tremaining: 20.3s\n",
      "433:\tlearn: 0.2528493\ttotal: 15.5s\tremaining: 20.2s\n",
      "434:\tlearn: 0.2527821\ttotal: 15.5s\tremaining: 20.2s\n",
      "435:\tlearn: 0.2526290\ttotal: 15.6s\tremaining: 20.2s\n",
      "436:\tlearn: 0.2525433\ttotal: 15.6s\tremaining: 20.1s\n",
      "437:\tlearn: 0.2522522\ttotal: 15.6s\tremaining: 20.1s\n",
      "438:\tlearn: 0.2521485\ttotal: 15.7s\tremaining: 20s\n",
      "439:\tlearn: 0.2518751\ttotal: 15.7s\tremaining: 20s\n",
      "440:\tlearn: 0.2516374\ttotal: 15.8s\tremaining: 20s\n",
      "441:\tlearn: 0.2513867\ttotal: 15.8s\tremaining: 19.9s\n",
      "442:\tlearn: 0.2512876\ttotal: 15.8s\tremaining: 19.9s\n",
      "443:\tlearn: 0.2511711\ttotal: 15.9s\tremaining: 19.9s\n",
      "444:\tlearn: 0.2509339\ttotal: 15.9s\tremaining: 19.8s\n",
      "445:\tlearn: 0.2506639\ttotal: 15.9s\tremaining: 19.8s\n",
      "446:\tlearn: 0.2505645\ttotal: 16s\tremaining: 19.7s\n",
      "447:\tlearn: 0.2504717\ttotal: 16s\tremaining: 19.7s\n",
      "448:\tlearn: 0.2501851\ttotal: 16s\tremaining: 19.7s\n",
      "449:\tlearn: 0.2498500\ttotal: 16.1s\tremaining: 19.6s\n",
      "450:\tlearn: 0.2494596\ttotal: 16.1s\tremaining: 19.6s\n",
      "451:\tlearn: 0.2493649\ttotal: 16.2s\tremaining: 19.6s\n",
      "452:\tlearn: 0.2490373\ttotal: 16.2s\tremaining: 19.5s\n",
      "453:\tlearn: 0.2489312\ttotal: 16.2s\tremaining: 19.5s\n",
      "454:\tlearn: 0.2488834\ttotal: 16.3s\tremaining: 19.5s\n",
      "455:\tlearn: 0.2484687\ttotal: 16.3s\tremaining: 19.4s\n",
      "456:\tlearn: 0.2481793\ttotal: 16.3s\tremaining: 19.4s\n",
      "457:\tlearn: 0.2479435\ttotal: 16.4s\tremaining: 19.4s\n",
      "458:\tlearn: 0.2476228\ttotal: 16.4s\tremaining: 19.3s\n",
      "459:\tlearn: 0.2474308\ttotal: 16.4s\tremaining: 19.3s\n",
      "460:\tlearn: 0.2472905\ttotal: 16.5s\tremaining: 19.2s\n",
      "461:\tlearn: 0.2471364\ttotal: 16.5s\tremaining: 19.2s\n",
      "462:\tlearn: 0.2470666\ttotal: 16.5s\tremaining: 19.2s\n",
      "463:\tlearn: 0.2467677\ttotal: 16.6s\tremaining: 19.1s\n",
      "464:\tlearn: 0.2466494\ttotal: 16.6s\tremaining: 19.1s\n",
      "465:\tlearn: 0.2463969\ttotal: 16.6s\tremaining: 19.1s\n",
      "466:\tlearn: 0.2461473\ttotal: 16.7s\tremaining: 19s\n",
      "467:\tlearn: 0.2459131\ttotal: 16.7s\tremaining: 19s\n",
      "468:\tlearn: 0.2456264\ttotal: 16.8s\tremaining: 19s\n",
      "469:\tlearn: 0.2455010\ttotal: 16.8s\tremaining: 19s\n",
      "470:\tlearn: 0.2452684\ttotal: 16.8s\tremaining: 18.9s\n",
      "471:\tlearn: 0.2450475\ttotal: 16.9s\tremaining: 18.9s\n",
      "472:\tlearn: 0.2449084\ttotal: 16.9s\tremaining: 18.8s\n",
      "473:\tlearn: 0.2443932\ttotal: 16.9s\tremaining: 18.8s\n",
      "474:\tlearn: 0.2441398\ttotal: 17s\tremaining: 18.8s\n",
      "475:\tlearn: 0.2437918\ttotal: 17s\tremaining: 18.7s\n",
      "476:\tlearn: 0.2434397\ttotal: 17s\tremaining: 18.7s\n",
      "477:\tlearn: 0.2432948\ttotal: 17.1s\tremaining: 18.7s\n",
      "478:\tlearn: 0.2431971\ttotal: 17.1s\tremaining: 18.6s\n",
      "479:\tlearn: 0.2430012\ttotal: 17.2s\tremaining: 18.6s\n",
      "480:\tlearn: 0.2426987\ttotal: 17.2s\tremaining: 18.6s\n",
      "481:\tlearn: 0.2426364\ttotal: 17.2s\tremaining: 18.5s\n",
      "482:\tlearn: 0.2425618\ttotal: 17.3s\tremaining: 18.5s\n",
      "483:\tlearn: 0.2424789\ttotal: 17.3s\tremaining: 18.4s\n",
      "484:\tlearn: 0.2423953\ttotal: 17.3s\tremaining: 18.4s\n",
      "485:\tlearn: 0.2421593\ttotal: 17.4s\tremaining: 18.4s\n",
      "486:\tlearn: 0.2419073\ttotal: 17.4s\tremaining: 18.3s\n",
      "487:\tlearn: 0.2416017\ttotal: 17.4s\tremaining: 18.3s\n",
      "488:\tlearn: 0.2413873\ttotal: 17.5s\tremaining: 18.3s\n",
      "489:\tlearn: 0.2411914\ttotal: 17.5s\tremaining: 18.2s\n",
      "490:\tlearn: 0.2409993\ttotal: 17.6s\tremaining: 18.2s\n",
      "491:\tlearn: 0.2407886\ttotal: 17.6s\tremaining: 18.2s\n",
      "492:\tlearn: 0.2406337\ttotal: 17.6s\tremaining: 18.1s\n",
      "493:\tlearn: 0.2404216\ttotal: 17.7s\tremaining: 18.1s\n",
      "494:\tlearn: 0.2403474\ttotal: 17.7s\tremaining: 18.1s\n",
      "495:\tlearn: 0.2402724\ttotal: 17.7s\tremaining: 18s\n",
      "496:\tlearn: 0.2401299\ttotal: 17.8s\tremaining: 18s\n",
      "497:\tlearn: 0.2398608\ttotal: 17.8s\tremaining: 18s\n",
      "498:\tlearn: 0.2396260\ttotal: 17.8s\tremaining: 17.9s\n",
      "499:\tlearn: 0.2393005\ttotal: 17.9s\tremaining: 17.9s\n",
      "500:\tlearn: 0.2392244\ttotal: 17.9s\tremaining: 17.9s\n",
      "501:\tlearn: 0.2390312\ttotal: 18s\tremaining: 17.8s\n",
      "502:\tlearn: 0.2389594\ttotal: 18s\tremaining: 17.8s\n",
      "503:\tlearn: 0.2388297\ttotal: 18s\tremaining: 17.8s\n",
      "504:\tlearn: 0.2386834\ttotal: 18.1s\tremaining: 17.7s\n",
      "505:\tlearn: 0.2384924\ttotal: 18.1s\tremaining: 17.7s\n",
      "506:\tlearn: 0.2381898\ttotal: 18.1s\tremaining: 17.6s\n",
      "507:\tlearn: 0.2378663\ttotal: 18.2s\tremaining: 17.6s\n",
      "508:\tlearn: 0.2376945\ttotal: 18.2s\tremaining: 17.6s\n",
      "509:\tlearn: 0.2373407\ttotal: 18.3s\tremaining: 17.5s\n",
      "510:\tlearn: 0.2372198\ttotal: 18.3s\tremaining: 17.5s\n",
      "511:\tlearn: 0.2369807\ttotal: 18.3s\tremaining: 17.5s\n",
      "512:\tlearn: 0.2366976\ttotal: 18.4s\tremaining: 17.4s\n",
      "513:\tlearn: 0.2365364\ttotal: 18.4s\tremaining: 17.4s\n",
      "514:\tlearn: 0.2363708\ttotal: 18.4s\tremaining: 17.4s\n",
      "515:\tlearn: 0.2362265\ttotal: 18.5s\tremaining: 17.3s\n",
      "516:\tlearn: 0.2360185\ttotal: 18.5s\tremaining: 17.3s\n",
      "517:\tlearn: 0.2357650\ttotal: 18.6s\tremaining: 17.3s\n",
      "518:\tlearn: 0.2355224\ttotal: 18.6s\tremaining: 17.2s\n",
      "519:\tlearn: 0.2352260\ttotal: 18.6s\tremaining: 17.2s\n",
      "520:\tlearn: 0.2349567\ttotal: 18.7s\tremaining: 17.2s\n",
      "521:\tlearn: 0.2346611\ttotal: 18.7s\tremaining: 17.1s\n",
      "522:\tlearn: 0.2342311\ttotal: 18.7s\tremaining: 17.1s\n",
      "523:\tlearn: 0.2338976\ttotal: 18.8s\tremaining: 17.1s\n",
      "524:\tlearn: 0.2335975\ttotal: 18.8s\tremaining: 17s\n",
      "525:\tlearn: 0.2334540\ttotal: 18.9s\tremaining: 17s\n",
      "526:\tlearn: 0.2332232\ttotal: 18.9s\tremaining: 17s\n",
      "527:\tlearn: 0.2330603\ttotal: 18.9s\tremaining: 16.9s\n",
      "528:\tlearn: 0.2328579\ttotal: 19s\tremaining: 16.9s\n",
      "529:\tlearn: 0.2326424\ttotal: 19s\tremaining: 16.9s\n",
      "530:\tlearn: 0.2325525\ttotal: 19s\tremaining: 16.8s\n",
      "531:\tlearn: 0.2324248\ttotal: 19.1s\tremaining: 16.8s\n",
      "532:\tlearn: 0.2322442\ttotal: 19.1s\tremaining: 16.7s\n",
      "533:\tlearn: 0.2321081\ttotal: 19.1s\tremaining: 16.7s\n",
      "534:\tlearn: 0.2318048\ttotal: 19.2s\tremaining: 16.7s\n",
      "535:\tlearn: 0.2317302\ttotal: 19.2s\tremaining: 16.6s\n",
      "536:\tlearn: 0.2315270\ttotal: 19.3s\tremaining: 16.6s\n",
      "537:\tlearn: 0.2314460\ttotal: 19.3s\tremaining: 16.6s\n",
      "538:\tlearn: 0.2312393\ttotal: 19.3s\tremaining: 16.5s\n",
      "539:\tlearn: 0.2311069\ttotal: 19.4s\tremaining: 16.5s\n",
      "540:\tlearn: 0.2310322\ttotal: 19.4s\tremaining: 16.5s\n",
      "541:\tlearn: 0.2307778\ttotal: 19.5s\tremaining: 16.4s\n",
      "542:\tlearn: 0.2306212\ttotal: 19.5s\tremaining: 16.4s\n",
      "543:\tlearn: 0.2303328\ttotal: 19.5s\tremaining: 16.4s\n",
      "544:\tlearn: 0.2302267\ttotal: 19.5s\tremaining: 16.3s\n",
      "545:\tlearn: 0.2300891\ttotal: 19.6s\tremaining: 16.3s\n",
      "546:\tlearn: 0.2298688\ttotal: 19.6s\tremaining: 16.2s\n",
      "547:\tlearn: 0.2296640\ttotal: 19.7s\tremaining: 16.2s\n",
      "548:\tlearn: 0.2295660\ttotal: 19.7s\tremaining: 16.2s\n",
      "549:\tlearn: 0.2292679\ttotal: 19.7s\tremaining: 16.2s\n",
      "550:\tlearn: 0.2289893\ttotal: 19.8s\tremaining: 16.1s\n",
      "551:\tlearn: 0.2287731\ttotal: 19.8s\tremaining: 16.1s\n",
      "552:\tlearn: 0.2285073\ttotal: 19.9s\tremaining: 16.1s\n",
      "553:\tlearn: 0.2283904\ttotal: 19.9s\tremaining: 16s\n",
      "554:\tlearn: 0.2281133\ttotal: 19.9s\tremaining: 16s\n",
      "555:\tlearn: 0.2280039\ttotal: 20s\tremaining: 15.9s\n",
      "556:\tlearn: 0.2277732\ttotal: 20s\tremaining: 15.9s\n",
      "557:\tlearn: 0.2276597\ttotal: 20s\tremaining: 15.9s\n",
      "558:\tlearn: 0.2273472\ttotal: 20.1s\tremaining: 15.8s\n",
      "559:\tlearn: 0.2271775\ttotal: 20.1s\tremaining: 15.8s\n",
      "560:\tlearn: 0.2270069\ttotal: 20.2s\tremaining: 15.8s\n",
      "561:\tlearn: 0.2269084\ttotal: 20.2s\tremaining: 15.7s\n",
      "562:\tlearn: 0.2267304\ttotal: 20.2s\tremaining: 15.7s\n",
      "563:\tlearn: 0.2266580\ttotal: 20.3s\tremaining: 15.7s\n",
      "564:\tlearn: 0.2265676\ttotal: 20.3s\tremaining: 15.6s\n",
      "565:\tlearn: 0.2263933\ttotal: 20.3s\tremaining: 15.6s\n",
      "566:\tlearn: 0.2261838\ttotal: 20.4s\tremaining: 15.5s\n",
      "567:\tlearn: 0.2258422\ttotal: 20.4s\tremaining: 15.5s\n",
      "568:\tlearn: 0.2256340\ttotal: 20.4s\tremaining: 15.5s\n",
      "569:\tlearn: 0.2253800\ttotal: 20.5s\tremaining: 15.4s\n",
      "570:\tlearn: 0.2250896\ttotal: 20.5s\tremaining: 15.4s\n",
      "571:\tlearn: 0.2249198\ttotal: 20.5s\tremaining: 15.4s\n",
      "572:\tlearn: 0.2247554\ttotal: 20.6s\tremaining: 15.3s\n",
      "573:\tlearn: 0.2246708\ttotal: 20.6s\tremaining: 15.3s\n",
      "574:\tlearn: 0.2245903\ttotal: 20.6s\tremaining: 15.3s\n",
      "575:\tlearn: 0.2243793\ttotal: 20.7s\tremaining: 15.2s\n",
      "576:\tlearn: 0.2242247\ttotal: 20.7s\tremaining: 15.2s\n",
      "577:\tlearn: 0.2240554\ttotal: 20.8s\tremaining: 15.2s\n",
      "578:\tlearn: 0.2239148\ttotal: 20.8s\tremaining: 15.1s\n",
      "579:\tlearn: 0.2237185\ttotal: 20.8s\tremaining: 15.1s\n",
      "580:\tlearn: 0.2236589\ttotal: 20.9s\tremaining: 15s\n",
      "581:\tlearn: 0.2234550\ttotal: 20.9s\tremaining: 15s\n",
      "582:\tlearn: 0.2232703\ttotal: 20.9s\tremaining: 15s\n",
      "583:\tlearn: 0.2230934\ttotal: 21s\tremaining: 14.9s\n",
      "584:\tlearn: 0.2230050\ttotal: 21s\tremaining: 14.9s\n",
      "585:\tlearn: 0.2228080\ttotal: 21s\tremaining: 14.9s\n",
      "586:\tlearn: 0.2226717\ttotal: 21.1s\tremaining: 14.8s\n",
      "587:\tlearn: 0.2224389\ttotal: 21.1s\tremaining: 14.8s\n",
      "588:\tlearn: 0.2223244\ttotal: 21.1s\tremaining: 14.8s\n",
      "589:\tlearn: 0.2222140\ttotal: 21.2s\tremaining: 14.7s\n",
      "590:\tlearn: 0.2220790\ttotal: 21.2s\tremaining: 14.7s\n",
      "591:\tlearn: 0.2219278\ttotal: 21.2s\tremaining: 14.6s\n",
      "592:\tlearn: 0.2217060\ttotal: 21.3s\tremaining: 14.6s\n",
      "593:\tlearn: 0.2216164\ttotal: 21.3s\tremaining: 14.6s\n",
      "594:\tlearn: 0.2214459\ttotal: 21.3s\tremaining: 14.5s\n",
      "595:\tlearn: 0.2212957\ttotal: 21.4s\tremaining: 14.5s\n",
      "596:\tlearn: 0.2212162\ttotal: 21.4s\tremaining: 14.5s\n",
      "597:\tlearn: 0.2210920\ttotal: 21.5s\tremaining: 14.4s\n",
      "598:\tlearn: 0.2207833\ttotal: 21.5s\tremaining: 14.4s\n",
      "599:\tlearn: 0.2205853\ttotal: 21.5s\tremaining: 14.4s\n",
      "600:\tlearn: 0.2205072\ttotal: 21.6s\tremaining: 14.3s\n",
      "601:\tlearn: 0.2204036\ttotal: 21.6s\tremaining: 14.3s\n",
      "602:\tlearn: 0.2201866\ttotal: 21.6s\tremaining: 14.2s\n",
      "603:\tlearn: 0.2200063\ttotal: 21.7s\tremaining: 14.2s\n",
      "604:\tlearn: 0.2196925\ttotal: 21.7s\tremaining: 14.2s\n",
      "605:\tlearn: 0.2194457\ttotal: 21.7s\tremaining: 14.1s\n",
      "606:\tlearn: 0.2191944\ttotal: 21.8s\tremaining: 14.1s\n",
      "607:\tlearn: 0.2191421\ttotal: 21.8s\tremaining: 14.1s\n",
      "608:\tlearn: 0.2189754\ttotal: 21.9s\tremaining: 14s\n",
      "609:\tlearn: 0.2187773\ttotal: 21.9s\tremaining: 14s\n",
      "610:\tlearn: 0.2186771\ttotal: 21.9s\tremaining: 14s\n",
      "611:\tlearn: 0.2184911\ttotal: 22s\tremaining: 13.9s\n",
      "612:\tlearn: 0.2184538\ttotal: 22s\tremaining: 13.9s\n",
      "613:\tlearn: 0.2183201\ttotal: 22s\tremaining: 13.8s\n",
      "614:\tlearn: 0.2182126\ttotal: 22.1s\tremaining: 13.8s\n",
      "615:\tlearn: 0.2181141\ttotal: 22.1s\tremaining: 13.8s\n",
      "616:\tlearn: 0.2180162\ttotal: 22.1s\tremaining: 13.7s\n",
      "617:\tlearn: 0.2177915\ttotal: 22.2s\tremaining: 13.7s\n",
      "618:\tlearn: 0.2176564\ttotal: 22.2s\tremaining: 13.7s\n",
      "619:\tlearn: 0.2175206\ttotal: 22.2s\tremaining: 13.6s\n",
      "620:\tlearn: 0.2173029\ttotal: 22.3s\tremaining: 13.6s\n",
      "621:\tlearn: 0.2170050\ttotal: 22.3s\tremaining: 13.6s\n",
      "622:\tlearn: 0.2168215\ttotal: 22.4s\tremaining: 13.5s\n",
      "623:\tlearn: 0.2167075\ttotal: 22.4s\tremaining: 13.5s\n",
      "624:\tlearn: 0.2166211\ttotal: 22.4s\tremaining: 13.5s\n",
      "625:\tlearn: 0.2165163\ttotal: 22.5s\tremaining: 13.4s\n",
      "626:\tlearn: 0.2163242\ttotal: 22.5s\tremaining: 13.4s\n",
      "627:\tlearn: 0.2161085\ttotal: 22.6s\tremaining: 13.4s\n",
      "628:\tlearn: 0.2159313\ttotal: 22.6s\tremaining: 13.3s\n",
      "629:\tlearn: 0.2157764\ttotal: 22.6s\tremaining: 13.3s\n",
      "630:\tlearn: 0.2155231\ttotal: 22.7s\tremaining: 13.2s\n",
      "631:\tlearn: 0.2153512\ttotal: 22.7s\tremaining: 13.2s\n",
      "632:\tlearn: 0.2152793\ttotal: 22.7s\tremaining: 13.2s\n",
      "633:\tlearn: 0.2151490\ttotal: 22.8s\tremaining: 13.1s\n",
      "634:\tlearn: 0.2150611\ttotal: 22.8s\tremaining: 13.1s\n",
      "635:\tlearn: 0.2148784\ttotal: 22.9s\tremaining: 13.1s\n",
      "636:\tlearn: 0.2147053\ttotal: 22.9s\tremaining: 13s\n",
      "637:\tlearn: 0.2145015\ttotal: 22.9s\tremaining: 13s\n",
      "638:\tlearn: 0.2142583\ttotal: 22.9s\tremaining: 13s\n",
      "639:\tlearn: 0.2141632\ttotal: 23s\tremaining: 12.9s\n",
      "640:\tlearn: 0.2140937\ttotal: 23s\tremaining: 12.9s\n",
      "641:\tlearn: 0.2139138\ttotal: 23s\tremaining: 12.8s\n",
      "642:\tlearn: 0.2138483\ttotal: 23.1s\tremaining: 12.8s\n",
      "643:\tlearn: 0.2136521\ttotal: 23.1s\tremaining: 12.8s\n",
      "644:\tlearn: 0.2133839\ttotal: 23.2s\tremaining: 12.7s\n",
      "645:\tlearn: 0.2131553\ttotal: 23.2s\tremaining: 12.7s\n",
      "646:\tlearn: 0.2129716\ttotal: 23.2s\tremaining: 12.7s\n",
      "647:\tlearn: 0.2128628\ttotal: 23.3s\tremaining: 12.6s\n",
      "648:\tlearn: 0.2128108\ttotal: 23.3s\tremaining: 12.6s\n",
      "649:\tlearn: 0.2126288\ttotal: 23.3s\tremaining: 12.6s\n",
      "650:\tlearn: 0.2124997\ttotal: 23.4s\tremaining: 12.5s\n",
      "651:\tlearn: 0.2122965\ttotal: 23.4s\tremaining: 12.5s\n",
      "652:\tlearn: 0.2121967\ttotal: 23.4s\tremaining: 12.5s\n",
      "653:\tlearn: 0.2120961\ttotal: 23.5s\tremaining: 12.4s\n",
      "654:\tlearn: 0.2119605\ttotal: 23.5s\tremaining: 12.4s\n",
      "655:\tlearn: 0.2118634\ttotal: 23.5s\tremaining: 12.3s\n",
      "656:\tlearn: 0.2117392\ttotal: 23.6s\tremaining: 12.3s\n",
      "657:\tlearn: 0.2115093\ttotal: 23.6s\tremaining: 12.3s\n",
      "658:\tlearn: 0.2113729\ttotal: 23.7s\tremaining: 12.2s\n",
      "659:\tlearn: 0.2111653\ttotal: 23.7s\tremaining: 12.2s\n",
      "660:\tlearn: 0.2109425\ttotal: 23.7s\tremaining: 12.2s\n",
      "661:\tlearn: 0.2107699\ttotal: 23.8s\tremaining: 12.1s\n",
      "662:\tlearn: 0.2105833\ttotal: 23.8s\tremaining: 12.1s\n",
      "663:\tlearn: 0.2103851\ttotal: 23.8s\tremaining: 12.1s\n",
      "664:\tlearn: 0.2103209\ttotal: 23.9s\tremaining: 12s\n",
      "665:\tlearn: 0.2101408\ttotal: 23.9s\tremaining: 12s\n",
      "666:\tlearn: 0.2100409\ttotal: 24s\tremaining: 12s\n",
      "667:\tlearn: 0.2098787\ttotal: 24s\tremaining: 11.9s\n",
      "668:\tlearn: 0.2096629\ttotal: 24s\tremaining: 11.9s\n",
      "669:\tlearn: 0.2095708\ttotal: 24.1s\tremaining: 11.9s\n",
      "670:\tlearn: 0.2094076\ttotal: 24.1s\tremaining: 11.8s\n",
      "671:\tlearn: 0.2092389\ttotal: 24.1s\tremaining: 11.8s\n",
      "672:\tlearn: 0.2091257\ttotal: 24.2s\tremaining: 11.7s\n",
      "673:\tlearn: 0.2088253\ttotal: 24.2s\tremaining: 11.7s\n",
      "674:\tlearn: 0.2087624\ttotal: 24.3s\tremaining: 11.7s\n",
      "675:\tlearn: 0.2086522\ttotal: 24.3s\tremaining: 11.6s\n",
      "676:\tlearn: 0.2085222\ttotal: 24.3s\tremaining: 11.6s\n",
      "677:\tlearn: 0.2082926\ttotal: 24.4s\tremaining: 11.6s\n",
      "678:\tlearn: 0.2078373\ttotal: 24.4s\tremaining: 11.5s\n",
      "679:\tlearn: 0.2076221\ttotal: 24.4s\tremaining: 11.5s\n",
      "680:\tlearn: 0.2074939\ttotal: 24.5s\tremaining: 11.5s\n",
      "681:\tlearn: 0.2074139\ttotal: 24.5s\tremaining: 11.4s\n",
      "682:\tlearn: 0.2072555\ttotal: 24.5s\tremaining: 11.4s\n",
      "683:\tlearn: 0.2071403\ttotal: 24.6s\tremaining: 11.3s\n",
      "684:\tlearn: 0.2070473\ttotal: 24.6s\tremaining: 11.3s\n",
      "685:\tlearn: 0.2070104\ttotal: 24.6s\tremaining: 11.3s\n",
      "686:\tlearn: 0.2068498\ttotal: 24.7s\tremaining: 11.2s\n",
      "687:\tlearn: 0.2068029\ttotal: 24.7s\tremaining: 11.2s\n",
      "688:\tlearn: 0.2066284\ttotal: 24.8s\tremaining: 11.2s\n",
      "689:\tlearn: 0.2064532\ttotal: 24.8s\tremaining: 11.1s\n",
      "690:\tlearn: 0.2063459\ttotal: 24.8s\tremaining: 11.1s\n",
      "691:\tlearn: 0.2061498\ttotal: 24.9s\tremaining: 11.1s\n",
      "692:\tlearn: 0.2060123\ttotal: 24.9s\tremaining: 11s\n",
      "693:\tlearn: 0.2059665\ttotal: 25s\tremaining: 11s\n",
      "694:\tlearn: 0.2058407\ttotal: 25s\tremaining: 11s\n",
      "695:\tlearn: 0.2056589\ttotal: 25.1s\tremaining: 10.9s\n",
      "696:\tlearn: 0.2054228\ttotal: 25.1s\tremaining: 10.9s\n",
      "697:\tlearn: 0.2051464\ttotal: 25.1s\tremaining: 10.9s\n",
      "698:\tlearn: 0.2049798\ttotal: 25.2s\tremaining: 10.8s\n",
      "699:\tlearn: 0.2049096\ttotal: 25.2s\tremaining: 10.8s\n",
      "700:\tlearn: 0.2048203\ttotal: 25.2s\tremaining: 10.8s\n",
      "701:\tlearn: 0.2045188\ttotal: 25.3s\tremaining: 10.7s\n",
      "702:\tlearn: 0.2043846\ttotal: 25.3s\tremaining: 10.7s\n",
      "703:\tlearn: 0.2040972\ttotal: 25.3s\tremaining: 10.7s\n",
      "704:\tlearn: 0.2039982\ttotal: 25.4s\tremaining: 10.6s\n",
      "705:\tlearn: 0.2039217\ttotal: 25.4s\tremaining: 10.6s\n",
      "706:\tlearn: 0.2037593\ttotal: 25.5s\tremaining: 10.6s\n",
      "707:\tlearn: 0.2036174\ttotal: 25.5s\tremaining: 10.5s\n",
      "708:\tlearn: 0.2034635\ttotal: 25.5s\tremaining: 10.5s\n",
      "709:\tlearn: 0.2033799\ttotal: 25.6s\tremaining: 10.4s\n",
      "710:\tlearn: 0.2032620\ttotal: 25.6s\tremaining: 10.4s\n",
      "711:\tlearn: 0.2031504\ttotal: 25.6s\tremaining: 10.4s\n",
      "712:\tlearn: 0.2030049\ttotal: 25.7s\tremaining: 10.3s\n",
      "713:\tlearn: 0.2029180\ttotal: 25.7s\tremaining: 10.3s\n",
      "714:\tlearn: 0.2026922\ttotal: 25.8s\tremaining: 10.3s\n",
      "715:\tlearn: 0.2023930\ttotal: 25.8s\tremaining: 10.2s\n",
      "716:\tlearn: 0.2022251\ttotal: 25.8s\tremaining: 10.2s\n",
      "717:\tlearn: 0.2021478\ttotal: 25.9s\tremaining: 10.2s\n",
      "718:\tlearn: 0.2019777\ttotal: 25.9s\tremaining: 10.1s\n",
      "719:\tlearn: 0.2018722\ttotal: 25.9s\tremaining: 10.1s\n",
      "720:\tlearn: 0.2016836\ttotal: 26s\tremaining: 10s\n",
      "721:\tlearn: 0.2015268\ttotal: 26s\tremaining: 10s\n",
      "722:\tlearn: 0.2014204\ttotal: 26s\tremaining: 9.98s\n",
      "723:\tlearn: 0.2013229\ttotal: 26.1s\tremaining: 9.95s\n",
      "724:\tlearn: 0.2011786\ttotal: 26.1s\tremaining: 9.91s\n",
      "725:\tlearn: 0.2009780\ttotal: 26.2s\tremaining: 9.88s\n",
      "726:\tlearn: 0.2008464\ttotal: 26.2s\tremaining: 9.85s\n",
      "727:\tlearn: 0.2006103\ttotal: 26.3s\tremaining: 9.81s\n",
      "728:\tlearn: 0.2003177\ttotal: 26.3s\tremaining: 9.77s\n",
      "729:\tlearn: 0.2001706\ttotal: 26.3s\tremaining: 9.74s\n",
      "730:\tlearn: 0.2000302\ttotal: 26.4s\tremaining: 9.7s\n",
      "731:\tlearn: 0.1997984\ttotal: 26.4s\tremaining: 9.66s\n",
      "732:\tlearn: 0.1996748\ttotal: 26.4s\tremaining: 9.63s\n",
      "733:\tlearn: 0.1995252\ttotal: 26.5s\tremaining: 9.6s\n",
      "734:\tlearn: 0.1993178\ttotal: 26.5s\tremaining: 9.56s\n",
      "735:\tlearn: 0.1992105\ttotal: 26.6s\tremaining: 9.53s\n",
      "736:\tlearn: 0.1990656\ttotal: 26.6s\tremaining: 9.49s\n",
      "737:\tlearn: 0.1989277\ttotal: 26.6s\tremaining: 9.46s\n",
      "738:\tlearn: 0.1988055\ttotal: 26.7s\tremaining: 9.42s\n",
      "739:\tlearn: 0.1987557\ttotal: 26.7s\tremaining: 9.39s\n",
      "740:\tlearn: 0.1986086\ttotal: 26.7s\tremaining: 9.35s\n",
      "741:\tlearn: 0.1984042\ttotal: 26.8s\tremaining: 9.31s\n",
      "742:\tlearn: 0.1982563\ttotal: 26.8s\tremaining: 9.27s\n",
      "743:\tlearn: 0.1981544\ttotal: 26.9s\tremaining: 9.24s\n",
      "744:\tlearn: 0.1980011\ttotal: 26.9s\tremaining: 9.21s\n",
      "745:\tlearn: 0.1978835\ttotal: 26.9s\tremaining: 9.17s\n",
      "746:\tlearn: 0.1978508\ttotal: 27s\tremaining: 9.13s\n",
      "747:\tlearn: 0.1977613\ttotal: 27s\tremaining: 9.1s\n",
      "748:\tlearn: 0.1976385\ttotal: 27s\tremaining: 9.06s\n",
      "749:\tlearn: 0.1974343\ttotal: 27.1s\tremaining: 9.02s\n",
      "750:\tlearn: 0.1973098\ttotal: 27.1s\tremaining: 8.98s\n",
      "751:\tlearn: 0.1972351\ttotal: 27.1s\tremaining: 8.95s\n",
      "752:\tlearn: 0.1970719\ttotal: 27.2s\tremaining: 8.91s\n",
      "753:\tlearn: 0.1969009\ttotal: 27.2s\tremaining: 8.88s\n",
      "754:\tlearn: 0.1967671\ttotal: 27.3s\tremaining: 8.84s\n",
      "755:\tlearn: 0.1965050\ttotal: 27.3s\tremaining: 8.81s\n",
      "756:\tlearn: 0.1963491\ttotal: 27.3s\tremaining: 8.77s\n",
      "757:\tlearn: 0.1961528\ttotal: 27.4s\tremaining: 8.74s\n",
      "758:\tlearn: 0.1959384\ttotal: 27.4s\tremaining: 8.7s\n",
      "759:\tlearn: 0.1958267\ttotal: 27.4s\tremaining: 8.66s\n",
      "760:\tlearn: 0.1957341\ttotal: 27.5s\tremaining: 8.63s\n",
      "761:\tlearn: 0.1956544\ttotal: 27.5s\tremaining: 8.59s\n",
      "762:\tlearn: 0.1955331\ttotal: 27.6s\tremaining: 8.56s\n",
      "763:\tlearn: 0.1953670\ttotal: 27.6s\tremaining: 8.52s\n",
      "764:\tlearn: 0.1953023\ttotal: 27.6s\tremaining: 8.49s\n",
      "765:\tlearn: 0.1951342\ttotal: 27.7s\tremaining: 8.45s\n",
      "766:\tlearn: 0.1950688\ttotal: 27.7s\tremaining: 8.41s\n",
      "767:\tlearn: 0.1949876\ttotal: 27.7s\tremaining: 8.38s\n",
      "768:\tlearn: 0.1947451\ttotal: 27.8s\tremaining: 8.34s\n",
      "769:\tlearn: 0.1946282\ttotal: 27.8s\tremaining: 8.3s\n",
      "770:\tlearn: 0.1944913\ttotal: 27.8s\tremaining: 8.27s\n",
      "771:\tlearn: 0.1944144\ttotal: 27.9s\tremaining: 8.23s\n",
      "772:\tlearn: 0.1942165\ttotal: 27.9s\tremaining: 8.19s\n",
      "773:\tlearn: 0.1940513\ttotal: 27.9s\tremaining: 8.16s\n",
      "774:\tlearn: 0.1939866\ttotal: 28s\tremaining: 8.12s\n",
      "775:\tlearn: 0.1938827\ttotal: 28s\tremaining: 8.09s\n",
      "776:\tlearn: 0.1938090\ttotal: 28.1s\tremaining: 8.05s\n",
      "777:\tlearn: 0.1936698\ttotal: 28.1s\tremaining: 8.01s\n",
      "778:\tlearn: 0.1934556\ttotal: 28.1s\tremaining: 7.98s\n",
      "779:\tlearn: 0.1933468\ttotal: 28.2s\tremaining: 7.94s\n",
      "780:\tlearn: 0.1932202\ttotal: 28.2s\tremaining: 7.9s\n",
      "781:\tlearn: 0.1931509\ttotal: 28.2s\tremaining: 7.87s\n",
      "782:\tlearn: 0.1930696\ttotal: 28.3s\tremaining: 7.83s\n",
      "783:\tlearn: 0.1929994\ttotal: 28.3s\tremaining: 7.8s\n",
      "784:\tlearn: 0.1929408\ttotal: 28.3s\tremaining: 7.76s\n",
      "785:\tlearn: 0.1926523\ttotal: 28.4s\tremaining: 7.72s\n",
      "786:\tlearn: 0.1924381\ttotal: 28.4s\tremaining: 7.69s\n",
      "787:\tlearn: 0.1923770\ttotal: 28.4s\tremaining: 7.65s\n",
      "788:\tlearn: 0.1922484\ttotal: 28.5s\tremaining: 7.61s\n",
      "789:\tlearn: 0.1921296\ttotal: 28.5s\tremaining: 7.58s\n",
      "790:\tlearn: 0.1920188\ttotal: 28.5s\tremaining: 7.54s\n",
      "791:\tlearn: 0.1918433\ttotal: 28.6s\tremaining: 7.51s\n",
      "792:\tlearn: 0.1917381\ttotal: 28.6s\tremaining: 7.47s\n",
      "793:\tlearn: 0.1916045\ttotal: 28.7s\tremaining: 7.43s\n",
      "794:\tlearn: 0.1915041\ttotal: 28.7s\tremaining: 7.4s\n",
      "795:\tlearn: 0.1914174\ttotal: 28.7s\tremaining: 7.36s\n",
      "796:\tlearn: 0.1913213\ttotal: 28.8s\tremaining: 7.33s\n",
      "797:\tlearn: 0.1912459\ttotal: 28.8s\tremaining: 7.29s\n",
      "798:\tlearn: 0.1910843\ttotal: 28.8s\tremaining: 7.25s\n",
      "799:\tlearn: 0.1909326\ttotal: 28.9s\tremaining: 7.22s\n",
      "800:\tlearn: 0.1907599\ttotal: 28.9s\tremaining: 7.18s\n",
      "801:\tlearn: 0.1907174\ttotal: 29s\tremaining: 7.15s\n",
      "802:\tlearn: 0.1905310\ttotal: 29s\tremaining: 7.11s\n",
      "803:\tlearn: 0.1903998\ttotal: 29s\tremaining: 7.08s\n",
      "804:\tlearn: 0.1901862\ttotal: 29.1s\tremaining: 7.04s\n",
      "805:\tlearn: 0.1900105\ttotal: 29.1s\tremaining: 7s\n",
      "806:\tlearn: 0.1898972\ttotal: 29.1s\tremaining: 6.97s\n",
      "807:\tlearn: 0.1897503\ttotal: 29.2s\tremaining: 6.93s\n",
      "808:\tlearn: 0.1894825\ttotal: 29.2s\tremaining: 6.9s\n",
      "809:\tlearn: 0.1893094\ttotal: 29.3s\tremaining: 6.86s\n",
      "810:\tlearn: 0.1891672\ttotal: 29.3s\tremaining: 6.83s\n",
      "811:\tlearn: 0.1890076\ttotal: 29.3s\tremaining: 6.79s\n",
      "812:\tlearn: 0.1888581\ttotal: 29.4s\tremaining: 6.75s\n",
      "813:\tlearn: 0.1888233\ttotal: 29.4s\tremaining: 6.72s\n",
      "814:\tlearn: 0.1887112\ttotal: 29.4s\tremaining: 6.68s\n",
      "815:\tlearn: 0.1885790\ttotal: 29.5s\tremaining: 6.64s\n",
      "816:\tlearn: 0.1885125\ttotal: 29.5s\tremaining: 6.61s\n",
      "817:\tlearn: 0.1883122\ttotal: 29.5s\tremaining: 6.57s\n",
      "818:\tlearn: 0.1881692\ttotal: 29.6s\tremaining: 6.54s\n",
      "819:\tlearn: 0.1879889\ttotal: 29.6s\tremaining: 6.5s\n",
      "820:\tlearn: 0.1878291\ttotal: 29.7s\tremaining: 6.47s\n",
      "821:\tlearn: 0.1877109\ttotal: 29.7s\tremaining: 6.43s\n",
      "822:\tlearn: 0.1875705\ttotal: 29.7s\tremaining: 6.39s\n",
      "823:\tlearn: 0.1874649\ttotal: 29.8s\tremaining: 6.36s\n",
      "824:\tlearn: 0.1872841\ttotal: 29.8s\tremaining: 6.32s\n",
      "825:\tlearn: 0.1871086\ttotal: 29.8s\tremaining: 6.29s\n",
      "826:\tlearn: 0.1869547\ttotal: 29.9s\tremaining: 6.25s\n",
      "827:\tlearn: 0.1868780\ttotal: 29.9s\tremaining: 6.21s\n",
      "828:\tlearn: 0.1867178\ttotal: 29.9s\tremaining: 6.18s\n",
      "829:\tlearn: 0.1865985\ttotal: 30s\tremaining: 6.14s\n",
      "830:\tlearn: 0.1865657\ttotal: 30s\tremaining: 6.1s\n",
      "831:\tlearn: 0.1864386\ttotal: 30.1s\tremaining: 6.07s\n",
      "832:\tlearn: 0.1862514\ttotal: 30.1s\tremaining: 6.03s\n",
      "833:\tlearn: 0.1860456\ttotal: 30.1s\tremaining: 6s\n",
      "834:\tlearn: 0.1859159\ttotal: 30.2s\tremaining: 5.96s\n",
      "835:\tlearn: 0.1858697\ttotal: 30.2s\tremaining: 5.92s\n",
      "836:\tlearn: 0.1857845\ttotal: 30.2s\tremaining: 5.89s\n",
      "837:\tlearn: 0.1857200\ttotal: 30.3s\tremaining: 5.85s\n",
      "838:\tlearn: 0.1856375\ttotal: 30.3s\tremaining: 5.81s\n",
      "839:\tlearn: 0.1855086\ttotal: 30.3s\tremaining: 5.78s\n",
      "840:\tlearn: 0.1854185\ttotal: 30.4s\tremaining: 5.74s\n",
      "841:\tlearn: 0.1853142\ttotal: 30.4s\tremaining: 5.71s\n",
      "842:\tlearn: 0.1851774\ttotal: 30.5s\tremaining: 5.67s\n",
      "843:\tlearn: 0.1850535\ttotal: 30.5s\tremaining: 5.63s\n",
      "844:\tlearn: 0.1847792\ttotal: 30.5s\tremaining: 5.6s\n",
      "845:\tlearn: 0.1847313\ttotal: 30.6s\tremaining: 5.56s\n",
      "846:\tlearn: 0.1846373\ttotal: 30.6s\tremaining: 5.53s\n",
      "847:\tlearn: 0.1844917\ttotal: 30.6s\tremaining: 5.49s\n",
      "848:\tlearn: 0.1843041\ttotal: 30.7s\tremaining: 5.45s\n",
      "849:\tlearn: 0.1842144\ttotal: 30.7s\tremaining: 5.42s\n",
      "850:\tlearn: 0.1840997\ttotal: 30.7s\tremaining: 5.38s\n",
      "851:\tlearn: 0.1839959\ttotal: 30.8s\tremaining: 5.35s\n",
      "852:\tlearn: 0.1839003\ttotal: 30.8s\tremaining: 5.31s\n",
      "853:\tlearn: 0.1837621\ttotal: 30.9s\tremaining: 5.27s\n",
      "854:\tlearn: 0.1836382\ttotal: 30.9s\tremaining: 5.24s\n",
      "855:\tlearn: 0.1835327\ttotal: 30.9s\tremaining: 5.2s\n",
      "856:\tlearn: 0.1834123\ttotal: 31s\tremaining: 5.16s\n",
      "857:\tlearn: 0.1832372\ttotal: 31s\tremaining: 5.13s\n",
      "858:\tlearn: 0.1830339\ttotal: 31s\tremaining: 5.09s\n",
      "859:\tlearn: 0.1829863\ttotal: 31.1s\tremaining: 5.06s\n",
      "860:\tlearn: 0.1828379\ttotal: 31.1s\tremaining: 5.02s\n",
      "861:\tlearn: 0.1826486\ttotal: 31.1s\tremaining: 4.99s\n",
      "862:\tlearn: 0.1825746\ttotal: 31.2s\tremaining: 4.95s\n",
      "863:\tlearn: 0.1825355\ttotal: 31.2s\tremaining: 4.91s\n",
      "864:\tlearn: 0.1823840\ttotal: 31.2s\tremaining: 4.88s\n",
      "865:\tlearn: 0.1822477\ttotal: 31.3s\tremaining: 4.84s\n",
      "866:\tlearn: 0.1820662\ttotal: 31.3s\tremaining: 4.8s\n",
      "867:\tlearn: 0.1819811\ttotal: 31.4s\tremaining: 4.77s\n",
      "868:\tlearn: 0.1819380\ttotal: 31.4s\tremaining: 4.73s\n",
      "869:\tlearn: 0.1817728\ttotal: 31.4s\tremaining: 4.7s\n",
      "870:\tlearn: 0.1817290\ttotal: 31.5s\tremaining: 4.66s\n",
      "871:\tlearn: 0.1816647\ttotal: 31.5s\tremaining: 4.62s\n",
      "872:\tlearn: 0.1815816\ttotal: 31.5s\tremaining: 4.59s\n",
      "873:\tlearn: 0.1815110\ttotal: 31.6s\tremaining: 4.55s\n",
      "874:\tlearn: 0.1814252\ttotal: 31.6s\tremaining: 4.51s\n",
      "875:\tlearn: 0.1813116\ttotal: 31.6s\tremaining: 4.48s\n",
      "876:\tlearn: 0.1811791\ttotal: 31.7s\tremaining: 4.44s\n",
      "877:\tlearn: 0.1810815\ttotal: 31.7s\tremaining: 4.41s\n",
      "878:\tlearn: 0.1809291\ttotal: 31.8s\tremaining: 4.37s\n",
      "879:\tlearn: 0.1807817\ttotal: 31.8s\tremaining: 4.33s\n",
      "880:\tlearn: 0.1807478\ttotal: 31.8s\tremaining: 4.3s\n",
      "881:\tlearn: 0.1806468\ttotal: 31.9s\tremaining: 4.26s\n",
      "882:\tlearn: 0.1805392\ttotal: 31.9s\tremaining: 4.23s\n",
      "883:\tlearn: 0.1803984\ttotal: 31.9s\tremaining: 4.19s\n",
      "884:\tlearn: 0.1802432\ttotal: 32s\tremaining: 4.16s\n",
      "885:\tlearn: 0.1801205\ttotal: 32s\tremaining: 4.12s\n",
      "886:\tlearn: 0.1800348\ttotal: 32s\tremaining: 4.08s\n",
      "887:\tlearn: 0.1798964\ttotal: 32.1s\tremaining: 4.04s\n",
      "888:\tlearn: 0.1797573\ttotal: 32.1s\tremaining: 4.01s\n",
      "889:\tlearn: 0.1797043\ttotal: 32.2s\tremaining: 3.97s\n",
      "890:\tlearn: 0.1796027\ttotal: 32.2s\tremaining: 3.94s\n",
      "891:\tlearn: 0.1795201\ttotal: 32.2s\tremaining: 3.9s\n",
      "892:\tlearn: 0.1793165\ttotal: 32.3s\tremaining: 3.87s\n",
      "893:\tlearn: 0.1792814\ttotal: 32.3s\tremaining: 3.83s\n",
      "894:\tlearn: 0.1791030\ttotal: 32.4s\tremaining: 3.8s\n",
      "895:\tlearn: 0.1790160\ttotal: 32.4s\tremaining: 3.76s\n",
      "896:\tlearn: 0.1789450\ttotal: 32.4s\tremaining: 3.72s\n",
      "897:\tlearn: 0.1788102\ttotal: 32.5s\tremaining: 3.69s\n",
      "898:\tlearn: 0.1786861\ttotal: 32.5s\tremaining: 3.65s\n",
      "899:\tlearn: 0.1785607\ttotal: 32.5s\tremaining: 3.61s\n",
      "900:\tlearn: 0.1784588\ttotal: 32.6s\tremaining: 3.58s\n",
      "901:\tlearn: 0.1783506\ttotal: 32.6s\tremaining: 3.54s\n",
      "902:\tlearn: 0.1781769\ttotal: 32.7s\tremaining: 3.51s\n",
      "903:\tlearn: 0.1779738\ttotal: 32.7s\tremaining: 3.47s\n",
      "904:\tlearn: 0.1778549\ttotal: 32.7s\tremaining: 3.44s\n",
      "905:\tlearn: 0.1777236\ttotal: 32.8s\tremaining: 3.4s\n",
      "906:\tlearn: 0.1775777\ttotal: 32.8s\tremaining: 3.37s\n",
      "907:\tlearn: 0.1774881\ttotal: 32.9s\tremaining: 3.33s\n",
      "908:\tlearn: 0.1773845\ttotal: 32.9s\tremaining: 3.29s\n",
      "909:\tlearn: 0.1772792\ttotal: 32.9s\tremaining: 3.25s\n",
      "910:\tlearn: 0.1772055\ttotal: 33s\tremaining: 3.22s\n",
      "911:\tlearn: 0.1771710\ttotal: 33s\tremaining: 3.18s\n",
      "912:\tlearn: 0.1771043\ttotal: 33s\tremaining: 3.15s\n",
      "913:\tlearn: 0.1770002\ttotal: 33.1s\tremaining: 3.11s\n",
      "914:\tlearn: 0.1769280\ttotal: 33.1s\tremaining: 3.08s\n",
      "915:\tlearn: 0.1766922\ttotal: 33.1s\tremaining: 3.04s\n",
      "916:\tlearn: 0.1765898\ttotal: 33.2s\tremaining: 3s\n",
      "917:\tlearn: 0.1764841\ttotal: 33.2s\tremaining: 2.97s\n",
      "918:\tlearn: 0.1764623\ttotal: 33.2s\tremaining: 2.93s\n",
      "919:\tlearn: 0.1763894\ttotal: 33.3s\tremaining: 2.89s\n",
      "920:\tlearn: 0.1763171\ttotal: 33.3s\tremaining: 2.86s\n",
      "921:\tlearn: 0.1762008\ttotal: 33.3s\tremaining: 2.82s\n",
      "922:\tlearn: 0.1761432\ttotal: 33.4s\tremaining: 2.78s\n",
      "923:\tlearn: 0.1760518\ttotal: 33.4s\tremaining: 2.75s\n",
      "924:\tlearn: 0.1759941\ttotal: 33.5s\tremaining: 2.71s\n",
      "925:\tlearn: 0.1758639\ttotal: 33.5s\tremaining: 2.68s\n",
      "926:\tlearn: 0.1757710\ttotal: 33.5s\tremaining: 2.64s\n",
      "927:\tlearn: 0.1757296\ttotal: 33.6s\tremaining: 2.6s\n",
      "928:\tlearn: 0.1754829\ttotal: 33.6s\tremaining: 2.57s\n",
      "929:\tlearn: 0.1754334\ttotal: 33.6s\tremaining: 2.53s\n",
      "930:\tlearn: 0.1753500\ttotal: 33.7s\tremaining: 2.5s\n",
      "931:\tlearn: 0.1752090\ttotal: 33.7s\tremaining: 2.46s\n",
      "932:\tlearn: 0.1751046\ttotal: 33.8s\tremaining: 2.42s\n",
      "933:\tlearn: 0.1749533\ttotal: 33.8s\tremaining: 2.39s\n",
      "934:\tlearn: 0.1748471\ttotal: 33.8s\tremaining: 2.35s\n",
      "935:\tlearn: 0.1747860\ttotal: 33.9s\tremaining: 2.31s\n",
      "936:\tlearn: 0.1747474\ttotal: 33.9s\tremaining: 2.28s\n",
      "937:\tlearn: 0.1746872\ttotal: 33.9s\tremaining: 2.24s\n",
      "938:\tlearn: 0.1745992\ttotal: 34s\tremaining: 2.21s\n",
      "939:\tlearn: 0.1745353\ttotal: 34s\tremaining: 2.17s\n",
      "940:\tlearn: 0.1744026\ttotal: 34s\tremaining: 2.13s\n",
      "941:\tlearn: 0.1742856\ttotal: 34.1s\tremaining: 2.1s\n",
      "942:\tlearn: 0.1741550\ttotal: 34.1s\tremaining: 2.06s\n",
      "943:\tlearn: 0.1740601\ttotal: 34.2s\tremaining: 2.03s\n",
      "944:\tlearn: 0.1740032\ttotal: 34.2s\tremaining: 1.99s\n",
      "945:\tlearn: 0.1739344\ttotal: 34.2s\tremaining: 1.95s\n",
      "946:\tlearn: 0.1738669\ttotal: 34.3s\tremaining: 1.92s\n",
      "947:\tlearn: 0.1737730\ttotal: 34.3s\tremaining: 1.88s\n",
      "948:\tlearn: 0.1737453\ttotal: 34.3s\tremaining: 1.84s\n",
      "949:\tlearn: 0.1736267\ttotal: 34.4s\tremaining: 1.81s\n",
      "950:\tlearn: 0.1735131\ttotal: 34.4s\tremaining: 1.77s\n",
      "951:\tlearn: 0.1734315\ttotal: 34.5s\tremaining: 1.74s\n",
      "952:\tlearn: 0.1733495\ttotal: 34.5s\tremaining: 1.7s\n",
      "953:\tlearn: 0.1731841\ttotal: 34.5s\tremaining: 1.66s\n",
      "954:\tlearn: 0.1730656\ttotal: 34.6s\tremaining: 1.63s\n",
      "955:\tlearn: 0.1729516\ttotal: 34.6s\tremaining: 1.59s\n",
      "956:\tlearn: 0.1728129\ttotal: 34.6s\tremaining: 1.55s\n",
      "957:\tlearn: 0.1726712\ttotal: 34.7s\tremaining: 1.52s\n",
      "958:\tlearn: 0.1725819\ttotal: 34.7s\tremaining: 1.48s\n",
      "959:\tlearn: 0.1725064\ttotal: 34.7s\tremaining: 1.45s\n",
      "960:\tlearn: 0.1723660\ttotal: 34.8s\tremaining: 1.41s\n",
      "961:\tlearn: 0.1722981\ttotal: 34.8s\tremaining: 1.38s\n",
      "962:\tlearn: 0.1721784\ttotal: 34.9s\tremaining: 1.34s\n",
      "963:\tlearn: 0.1721522\ttotal: 34.9s\tremaining: 1.3s\n",
      "964:\tlearn: 0.1720903\ttotal: 34.9s\tremaining: 1.27s\n",
      "965:\tlearn: 0.1719989\ttotal: 35s\tremaining: 1.23s\n",
      "966:\tlearn: 0.1719285\ttotal: 35s\tremaining: 1.19s\n",
      "967:\tlearn: 0.1717439\ttotal: 35s\tremaining: 1.16s\n",
      "968:\tlearn: 0.1716726\ttotal: 35.1s\tremaining: 1.12s\n",
      "969:\tlearn: 0.1716043\ttotal: 35.1s\tremaining: 1.08s\n",
      "970:\tlearn: 0.1714894\ttotal: 35.2s\tremaining: 1.05s\n",
      "971:\tlearn: 0.1713431\ttotal: 35.2s\tremaining: 1.01s\n",
      "972:\tlearn: 0.1712861\ttotal: 35.2s\tremaining: 977ms\n",
      "973:\tlearn: 0.1711954\ttotal: 35.3s\tremaining: 941ms\n",
      "974:\tlearn: 0.1710577\ttotal: 35.3s\tremaining: 905ms\n",
      "975:\tlearn: 0.1709372\ttotal: 35.3s\tremaining: 869ms\n",
      "976:\tlearn: 0.1707654\ttotal: 35.4s\tremaining: 832ms\n",
      "977:\tlearn: 0.1707061\ttotal: 35.4s\tremaining: 796ms\n",
      "978:\tlearn: 0.1705874\ttotal: 35.4s\tremaining: 760ms\n",
      "979:\tlearn: 0.1704780\ttotal: 35.5s\tremaining: 724ms\n",
      "980:\tlearn: 0.1704400\ttotal: 35.5s\tremaining: 688ms\n",
      "981:\tlearn: 0.1703553\ttotal: 35.5s\tremaining: 652ms\n",
      "982:\tlearn: 0.1702333\ttotal: 35.6s\tremaining: 615ms\n",
      "983:\tlearn: 0.1701477\ttotal: 35.6s\tremaining: 579ms\n",
      "984:\tlearn: 0.1700259\ttotal: 35.6s\tremaining: 543ms\n",
      "985:\tlearn: 0.1699384\ttotal: 35.7s\tremaining: 507ms\n",
      "986:\tlearn: 0.1698155\ttotal: 35.7s\tremaining: 470ms\n",
      "987:\tlearn: 0.1697327\ttotal: 35.8s\tremaining: 434ms\n",
      "988:\tlearn: 0.1696377\ttotal: 35.8s\tremaining: 398ms\n",
      "989:\tlearn: 0.1694954\ttotal: 35.9s\tremaining: 362ms\n",
      "990:\tlearn: 0.1694139\ttotal: 35.9s\tremaining: 326ms\n",
      "991:\tlearn: 0.1693523\ttotal: 35.9s\tremaining: 290ms\n",
      "992:\tlearn: 0.1692549\ttotal: 36s\tremaining: 254ms\n",
      "993:\tlearn: 0.1692125\ttotal: 36s\tremaining: 217ms\n",
      "994:\tlearn: 0.1690678\ttotal: 36s\tremaining: 181ms\n",
      "995:\tlearn: 0.1689456\ttotal: 36.1s\tremaining: 145ms\n",
      "996:\tlearn: 0.1687786\ttotal: 36.1s\tremaining: 109ms\n",
      "997:\tlearn: 0.1686637\ttotal: 36.2s\tremaining: 72.5ms\n",
      "998:\tlearn: 0.1685488\ttotal: 36.2s\tremaining: 36.2ms\n",
      "999:\tlearn: 0.1683471\ttotal: 36.2s\tremaining: 0us\n",
      "Learning rate set to 0.091926\n",
      "0:\tlearn: 1.8323637\ttotal: 38.4ms\tremaining: 38.3s\n",
      "1:\tlearn: 1.6277900\ttotal: 73.9ms\tremaining: 36.9s\n",
      "2:\tlearn: 1.4746262\ttotal: 107ms\tremaining: 35.6s\n",
      "3:\tlearn: 1.3709049\ttotal: 142ms\tremaining: 35.4s\n",
      "4:\tlearn: 1.2802063\ttotal: 177ms\tremaining: 35.1s\n",
      "5:\tlearn: 1.2066273\ttotal: 213ms\tremaining: 35.2s\n",
      "6:\tlearn: 1.1472513\ttotal: 257ms\tremaining: 36.5s\n",
      "7:\tlearn: 1.0970789\ttotal: 302ms\tremaining: 37.4s\n",
      "8:\tlearn: 1.0390456\ttotal: 346ms\tremaining: 38.1s\n",
      "9:\tlearn: 0.9967536\ttotal: 380ms\tremaining: 37.6s\n",
      "10:\tlearn: 0.9586478\ttotal: 416ms\tremaining: 37.4s\n",
      "11:\tlearn: 0.9248376\ttotal: 449ms\tremaining: 37s\n",
      "12:\tlearn: 0.8890521\ttotal: 484ms\tremaining: 36.8s\n",
      "13:\tlearn: 0.8580815\ttotal: 521ms\tremaining: 36.7s\n",
      "14:\tlearn: 0.8352098\ttotal: 555ms\tremaining: 36.5s\n",
      "15:\tlearn: 0.8118319\ttotal: 588ms\tremaining: 36.2s\n",
      "16:\tlearn: 0.7863642\ttotal: 624ms\tremaining: 36.1s\n",
      "17:\tlearn: 0.7653943\ttotal: 661ms\tremaining: 36.1s\n",
      "18:\tlearn: 0.7464856\ttotal: 695ms\tremaining: 35.9s\n",
      "19:\tlearn: 0.7324956\ttotal: 739ms\tremaining: 36.2s\n",
      "20:\tlearn: 0.7122389\ttotal: 777ms\tremaining: 36.2s\n",
      "21:\tlearn: 0.6995310\ttotal: 810ms\tremaining: 36s\n",
      "22:\tlearn: 0.6847958\ttotal: 845ms\tremaining: 35.9s\n",
      "23:\tlearn: 0.6758721\ttotal: 879ms\tremaining: 35.8s\n",
      "24:\tlearn: 0.6651031\ttotal: 911ms\tremaining: 35.5s\n",
      "25:\tlearn: 0.6557193\ttotal: 946ms\tremaining: 35.4s\n",
      "26:\tlearn: 0.6436395\ttotal: 981ms\tremaining: 35.3s\n",
      "27:\tlearn: 0.6340974\ttotal: 1.02s\tremaining: 35.5s\n",
      "28:\tlearn: 0.6229689\ttotal: 1.06s\tremaining: 35.6s\n",
      "29:\tlearn: 0.6102095\ttotal: 1.11s\tremaining: 35.9s\n",
      "30:\tlearn: 0.6029404\ttotal: 1.14s\tremaining: 35.8s\n",
      "31:\tlearn: 0.5918402\ttotal: 1.18s\tremaining: 35.6s\n",
      "32:\tlearn: 0.5852791\ttotal: 1.21s\tremaining: 35.5s\n",
      "33:\tlearn: 0.5762235\ttotal: 1.24s\tremaining: 35.2s\n",
      "34:\tlearn: 0.5706989\ttotal: 1.27s\tremaining: 35.1s\n",
      "35:\tlearn: 0.5640579\ttotal: 1.31s\tremaining: 35.1s\n",
      "36:\tlearn: 0.5567817\ttotal: 1.34s\tremaining: 35s\n",
      "37:\tlearn: 0.5533868\ttotal: 1.38s\tremaining: 34.9s\n",
      "38:\tlearn: 0.5502661\ttotal: 1.42s\tremaining: 35s\n",
      "39:\tlearn: 0.5453971\ttotal: 1.45s\tremaining: 34.9s\n",
      "40:\tlearn: 0.5419351\ttotal: 1.49s\tremaining: 34.9s\n",
      "41:\tlearn: 0.5370026\ttotal: 1.53s\tremaining: 34.9s\n",
      "42:\tlearn: 0.5327174\ttotal: 1.56s\tremaining: 34.8s\n",
      "43:\tlearn: 0.5263784\ttotal: 1.6s\tremaining: 34.7s\n",
      "44:\tlearn: 0.5214738\ttotal: 1.63s\tremaining: 34.6s\n",
      "45:\tlearn: 0.5161169\ttotal: 1.66s\tremaining: 34.5s\n",
      "46:\tlearn: 0.5127494\ttotal: 1.7s\tremaining: 34.4s\n",
      "47:\tlearn: 0.5110093\ttotal: 1.73s\tremaining: 34.3s\n",
      "48:\tlearn: 0.5073384\ttotal: 1.77s\tremaining: 34.3s\n",
      "49:\tlearn: 0.5005719\ttotal: 1.81s\tremaining: 34.4s\n",
      "50:\tlearn: 0.4964083\ttotal: 1.85s\tremaining: 34.4s\n",
      "51:\tlearn: 0.4936970\ttotal: 1.89s\tremaining: 34.5s\n",
      "52:\tlearn: 0.4886733\ttotal: 1.93s\tremaining: 34.5s\n",
      "53:\tlearn: 0.4846679\ttotal: 1.97s\tremaining: 34.5s\n",
      "54:\tlearn: 0.4808342\ttotal: 2s\tremaining: 34.5s\n",
      "55:\tlearn: 0.4772226\ttotal: 2.04s\tremaining: 34.5s\n",
      "56:\tlearn: 0.4753896\ttotal: 2.08s\tremaining: 34.4s\n",
      "57:\tlearn: 0.4723640\ttotal: 2.11s\tremaining: 34.3s\n",
      "58:\tlearn: 0.4699181\ttotal: 2.14s\tremaining: 34.2s\n",
      "59:\tlearn: 0.4666362\ttotal: 2.17s\tremaining: 34.1s\n",
      "60:\tlearn: 0.4635944\ttotal: 2.21s\tremaining: 34.1s\n",
      "61:\tlearn: 0.4605198\ttotal: 2.25s\tremaining: 34s\n",
      "62:\tlearn: 0.4581930\ttotal: 2.29s\tremaining: 34.1s\n",
      "63:\tlearn: 0.4563392\ttotal: 2.34s\tremaining: 34.2s\n",
      "64:\tlearn: 0.4547710\ttotal: 2.38s\tremaining: 34.2s\n",
      "65:\tlearn: 0.4530833\ttotal: 2.41s\tremaining: 34.1s\n",
      "66:\tlearn: 0.4490958\ttotal: 2.45s\tremaining: 34.1s\n",
      "67:\tlearn: 0.4465119\ttotal: 2.49s\tremaining: 34.2s\n",
      "68:\tlearn: 0.4444748\ttotal: 2.53s\tremaining: 34.2s\n",
      "69:\tlearn: 0.4420727\ttotal: 2.57s\tremaining: 34.1s\n",
      "70:\tlearn: 0.4404415\ttotal: 2.6s\tremaining: 34s\n",
      "71:\tlearn: 0.4391182\ttotal: 2.63s\tremaining: 33.9s\n",
      "72:\tlearn: 0.4365565\ttotal: 2.67s\tremaining: 33.9s\n",
      "73:\tlearn: 0.4347369\ttotal: 2.7s\tremaining: 33.8s\n",
      "74:\tlearn: 0.4331457\ttotal: 2.75s\tremaining: 33.9s\n",
      "75:\tlearn: 0.4311926\ttotal: 2.79s\tremaining: 34s\n",
      "76:\tlearn: 0.4286356\ttotal: 2.83s\tremaining: 33.9s\n",
      "77:\tlearn: 0.4260837\ttotal: 2.86s\tremaining: 33.9s\n",
      "78:\tlearn: 0.4242486\ttotal: 2.9s\tremaining: 33.8s\n",
      "79:\tlearn: 0.4226802\ttotal: 2.93s\tremaining: 33.8s\n",
      "80:\tlearn: 0.4213023\ttotal: 2.98s\tremaining: 33.8s\n",
      "81:\tlearn: 0.4204413\ttotal: 3.02s\tremaining: 33.8s\n",
      "82:\tlearn: 0.4188155\ttotal: 3.05s\tremaining: 33.7s\n",
      "83:\tlearn: 0.4171136\ttotal: 3.08s\tremaining: 33.6s\n",
      "84:\tlearn: 0.4154421\ttotal: 3.12s\tremaining: 33.6s\n",
      "85:\tlearn: 0.4137597\ttotal: 3.16s\tremaining: 33.5s\n",
      "86:\tlearn: 0.4128833\ttotal: 3.19s\tremaining: 33.5s\n",
      "87:\tlearn: 0.4108260\ttotal: 3.24s\tremaining: 33.6s\n",
      "88:\tlearn: 0.4096263\ttotal: 3.28s\tremaining: 33.5s\n",
      "89:\tlearn: 0.4082440\ttotal: 3.31s\tremaining: 33.5s\n",
      "90:\tlearn: 0.4065381\ttotal: 3.35s\tremaining: 33.4s\n",
      "91:\tlearn: 0.4050462\ttotal: 3.38s\tremaining: 33.3s\n",
      "92:\tlearn: 0.4042819\ttotal: 3.41s\tremaining: 33.2s\n",
      "93:\tlearn: 0.4034041\ttotal: 3.44s\tremaining: 33.2s\n",
      "94:\tlearn: 0.4025566\ttotal: 3.47s\tremaining: 33.1s\n",
      "95:\tlearn: 0.4020207\ttotal: 3.51s\tremaining: 33s\n",
      "96:\tlearn: 0.4012451\ttotal: 3.54s\tremaining: 33s\n",
      "97:\tlearn: 0.4003197\ttotal: 3.58s\tremaining: 32.9s\n",
      "98:\tlearn: 0.3985127\ttotal: 3.62s\tremaining: 32.9s\n",
      "99:\tlearn: 0.3976319\ttotal: 3.66s\tremaining: 32.9s\n",
      "100:\tlearn: 0.3966453\ttotal: 3.69s\tremaining: 32.9s\n",
      "101:\tlearn: 0.3956216\ttotal: 3.73s\tremaining: 32.8s\n",
      "102:\tlearn: 0.3941800\ttotal: 3.76s\tremaining: 32.7s\n",
      "103:\tlearn: 0.3933996\ttotal: 3.79s\tremaining: 32.7s\n",
      "104:\tlearn: 0.3929014\ttotal: 3.83s\tremaining: 32.6s\n",
      "105:\tlearn: 0.3924125\ttotal: 3.86s\tremaining: 32.6s\n",
      "106:\tlearn: 0.3906787\ttotal: 3.9s\tremaining: 32.6s\n",
      "107:\tlearn: 0.3895655\ttotal: 3.95s\tremaining: 32.6s\n",
      "108:\tlearn: 0.3885981\ttotal: 3.99s\tremaining: 32.6s\n",
      "109:\tlearn: 0.3880552\ttotal: 4.02s\tremaining: 32.5s\n",
      "110:\tlearn: 0.3871411\ttotal: 4.05s\tremaining: 32.5s\n",
      "111:\tlearn: 0.3864772\ttotal: 4.08s\tremaining: 32.4s\n",
      "112:\tlearn: 0.3858137\ttotal: 4.11s\tremaining: 32.3s\n",
      "113:\tlearn: 0.3844937\ttotal: 4.14s\tremaining: 32.2s\n",
      "114:\tlearn: 0.3834482\ttotal: 4.17s\tremaining: 32.1s\n",
      "115:\tlearn: 0.3823434\ttotal: 4.21s\tremaining: 32.1s\n",
      "116:\tlearn: 0.3814196\ttotal: 4.24s\tremaining: 32s\n",
      "117:\tlearn: 0.3803297\ttotal: 4.28s\tremaining: 32s\n",
      "118:\tlearn: 0.3793550\ttotal: 4.31s\tremaining: 31.9s\n",
      "119:\tlearn: 0.3789421\ttotal: 4.35s\tremaining: 31.9s\n",
      "120:\tlearn: 0.3780625\ttotal: 4.39s\tremaining: 31.9s\n",
      "121:\tlearn: 0.3771894\ttotal: 4.42s\tremaining: 31.8s\n",
      "122:\tlearn: 0.3764791\ttotal: 4.45s\tremaining: 31.8s\n",
      "123:\tlearn: 0.3755206\ttotal: 4.49s\tremaining: 31.7s\n",
      "124:\tlearn: 0.3741277\ttotal: 4.52s\tremaining: 31.6s\n",
      "125:\tlearn: 0.3729902\ttotal: 4.55s\tremaining: 31.6s\n",
      "126:\tlearn: 0.3720132\ttotal: 4.59s\tremaining: 31.5s\n",
      "127:\tlearn: 0.3715482\ttotal: 4.62s\tremaining: 31.5s\n",
      "128:\tlearn: 0.3708633\ttotal: 4.67s\tremaining: 31.6s\n",
      "129:\tlearn: 0.3697749\ttotal: 4.71s\tremaining: 31.5s\n",
      "130:\tlearn: 0.3691495\ttotal: 4.75s\tremaining: 31.5s\n",
      "131:\tlearn: 0.3688114\ttotal: 4.78s\tremaining: 31.4s\n",
      "132:\tlearn: 0.3680136\ttotal: 4.82s\tremaining: 31.4s\n",
      "133:\tlearn: 0.3668100\ttotal: 4.85s\tremaining: 31.4s\n",
      "134:\tlearn: 0.3663974\ttotal: 4.89s\tremaining: 31.3s\n",
      "135:\tlearn: 0.3656270\ttotal: 4.92s\tremaining: 31.3s\n",
      "136:\tlearn: 0.3652199\ttotal: 4.95s\tremaining: 31.2s\n",
      "137:\tlearn: 0.3640970\ttotal: 4.99s\tremaining: 31.1s\n",
      "138:\tlearn: 0.3634084\ttotal: 5.02s\tremaining: 31.1s\n",
      "139:\tlearn: 0.3630306\ttotal: 5.06s\tremaining: 31.1s\n",
      "140:\tlearn: 0.3626061\ttotal: 5.1s\tremaining: 31.1s\n",
      "141:\tlearn: 0.3612281\ttotal: 5.15s\tremaining: 31.1s\n",
      "142:\tlearn: 0.3605334\ttotal: 5.18s\tremaining: 31s\n",
      "143:\tlearn: 0.3600845\ttotal: 5.21s\tremaining: 31s\n",
      "144:\tlearn: 0.3596608\ttotal: 5.24s\tremaining: 30.9s\n",
      "145:\tlearn: 0.3587817\ttotal: 5.27s\tremaining: 30.8s\n",
      "146:\tlearn: 0.3585358\ttotal: 5.3s\tremaining: 30.8s\n",
      "147:\tlearn: 0.3579553\ttotal: 5.34s\tremaining: 30.7s\n",
      "148:\tlearn: 0.3576122\ttotal: 5.37s\tremaining: 30.7s\n",
      "149:\tlearn: 0.3570118\ttotal: 5.4s\tremaining: 30.6s\n",
      "150:\tlearn: 0.3566384\ttotal: 5.44s\tremaining: 30.6s\n",
      "151:\tlearn: 0.3562123\ttotal: 5.47s\tremaining: 30.5s\n",
      "152:\tlearn: 0.3558165\ttotal: 5.51s\tremaining: 30.5s\n",
      "153:\tlearn: 0.3549719\ttotal: 5.55s\tremaining: 30.5s\n",
      "154:\tlearn: 0.3544966\ttotal: 5.58s\tremaining: 30.4s\n",
      "155:\tlearn: 0.3542463\ttotal: 5.61s\tremaining: 30.4s\n",
      "156:\tlearn: 0.3534193\ttotal: 5.64s\tremaining: 30.3s\n",
      "157:\tlearn: 0.3529709\ttotal: 5.68s\tremaining: 30.3s\n",
      "158:\tlearn: 0.3516138\ttotal: 5.71s\tremaining: 30.2s\n",
      "159:\tlearn: 0.3514396\ttotal: 5.74s\tremaining: 30.1s\n",
      "160:\tlearn: 0.3508866\ttotal: 5.78s\tremaining: 30.1s\n",
      "161:\tlearn: 0.3497887\ttotal: 5.82s\tremaining: 30.1s\n",
      "162:\tlearn: 0.3493075\ttotal: 5.87s\tremaining: 30.2s\n",
      "163:\tlearn: 0.3484859\ttotal: 5.91s\tremaining: 30.1s\n",
      "164:\tlearn: 0.3481454\ttotal: 5.94s\tremaining: 30s\n",
      "165:\tlearn: 0.3478686\ttotal: 5.97s\tremaining: 30s\n",
      "166:\tlearn: 0.3473112\ttotal: 6s\tremaining: 29.9s\n",
      "167:\tlearn: 0.3462960\ttotal: 6.04s\tremaining: 29.9s\n",
      "168:\tlearn: 0.3454832\ttotal: 6.07s\tremaining: 29.8s\n",
      "169:\tlearn: 0.3451483\ttotal: 6.1s\tremaining: 29.8s\n",
      "170:\tlearn: 0.3445695\ttotal: 6.14s\tremaining: 29.8s\n",
      "171:\tlearn: 0.3443237\ttotal: 6.17s\tremaining: 29.7s\n",
      "172:\tlearn: 0.3437865\ttotal: 6.21s\tremaining: 29.7s\n",
      "173:\tlearn: 0.3432619\ttotal: 6.25s\tremaining: 29.7s\n",
      "174:\tlearn: 0.3428547\ttotal: 6.28s\tremaining: 29.6s\n",
      "175:\tlearn: 0.3426110\ttotal: 6.31s\tremaining: 29.6s\n",
      "176:\tlearn: 0.3418881\ttotal: 6.35s\tremaining: 29.5s\n",
      "177:\tlearn: 0.3410630\ttotal: 6.38s\tremaining: 29.5s\n",
      "178:\tlearn: 0.3409016\ttotal: 6.41s\tremaining: 29.4s\n",
      "179:\tlearn: 0.3405059\ttotal: 6.44s\tremaining: 29.4s\n",
      "180:\tlearn: 0.3392940\ttotal: 6.48s\tremaining: 29.3s\n",
      "181:\tlearn: 0.3389671\ttotal: 6.52s\tremaining: 29.3s\n",
      "182:\tlearn: 0.3378275\ttotal: 6.57s\tremaining: 29.3s\n",
      "183:\tlearn: 0.3371828\ttotal: 6.61s\tremaining: 29.3s\n",
      "184:\tlearn: 0.3367029\ttotal: 6.63s\tremaining: 29.2s\n",
      "185:\tlearn: 0.3363661\ttotal: 6.67s\tremaining: 29.2s\n",
      "186:\tlearn: 0.3358437\ttotal: 6.7s\tremaining: 29.1s\n",
      "187:\tlearn: 0.3355682\ttotal: 6.73s\tremaining: 29.1s\n",
      "188:\tlearn: 0.3350530\ttotal: 6.76s\tremaining: 29s\n",
      "189:\tlearn: 0.3344947\ttotal: 6.8s\tremaining: 29s\n",
      "190:\tlearn: 0.3341174\ttotal: 6.84s\tremaining: 29s\n",
      "191:\tlearn: 0.3338132\ttotal: 6.88s\tremaining: 28.9s\n",
      "192:\tlearn: 0.3334043\ttotal: 6.91s\tremaining: 28.9s\n",
      "193:\tlearn: 0.3329757\ttotal: 6.95s\tremaining: 28.9s\n",
      "194:\tlearn: 0.3328180\ttotal: 6.98s\tremaining: 28.8s\n",
      "195:\tlearn: 0.3324504\ttotal: 7.02s\tremaining: 28.8s\n",
      "196:\tlearn: 0.3321489\ttotal: 7.05s\tremaining: 28.7s\n",
      "197:\tlearn: 0.3315756\ttotal: 7.08s\tremaining: 28.7s\n",
      "198:\tlearn: 0.3312566\ttotal: 7.11s\tremaining: 28.6s\n",
      "199:\tlearn: 0.3306320\ttotal: 7.14s\tremaining: 28.6s\n",
      "200:\tlearn: 0.3302898\ttotal: 7.18s\tremaining: 28.5s\n",
      "201:\tlearn: 0.3298814\ttotal: 7.22s\tremaining: 28.5s\n",
      "202:\tlearn: 0.3294786\ttotal: 7.26s\tremaining: 28.5s\n",
      "203:\tlearn: 0.3286807\ttotal: 7.31s\tremaining: 28.5s\n",
      "204:\tlearn: 0.3282960\ttotal: 7.34s\tremaining: 28.5s\n",
      "205:\tlearn: 0.3277243\ttotal: 7.38s\tremaining: 28.5s\n",
      "206:\tlearn: 0.3271562\ttotal: 7.42s\tremaining: 28.4s\n",
      "207:\tlearn: 0.3269067\ttotal: 7.46s\tremaining: 28.4s\n",
      "208:\tlearn: 0.3262014\ttotal: 7.5s\tremaining: 28.4s\n",
      "209:\tlearn: 0.3258952\ttotal: 7.53s\tremaining: 28.3s\n",
      "210:\tlearn: 0.3256498\ttotal: 7.56s\tremaining: 28.3s\n",
      "211:\tlearn: 0.3249552\ttotal: 7.59s\tremaining: 28.2s\n",
      "212:\tlearn: 0.3247140\ttotal: 7.63s\tremaining: 28.2s\n",
      "213:\tlearn: 0.3246638\ttotal: 7.66s\tremaining: 28.1s\n",
      "214:\tlearn: 0.3242186\ttotal: 7.71s\tremaining: 28.1s\n",
      "215:\tlearn: 0.3234787\ttotal: 7.75s\tremaining: 28.1s\n",
      "216:\tlearn: 0.3234132\ttotal: 7.78s\tremaining: 28.1s\n",
      "217:\tlearn: 0.3231606\ttotal: 7.81s\tremaining: 28s\n",
      "218:\tlearn: 0.3229751\ttotal: 7.83s\tremaining: 27.9s\n",
      "219:\tlearn: 0.3225647\ttotal: 7.87s\tremaining: 27.9s\n",
      "220:\tlearn: 0.3222221\ttotal: 7.9s\tremaining: 27.8s\n",
      "221:\tlearn: 0.3220777\ttotal: 7.93s\tremaining: 27.8s\n",
      "222:\tlearn: 0.3212060\ttotal: 7.97s\tremaining: 27.8s\n",
      "223:\tlearn: 0.3207867\ttotal: 8s\tremaining: 27.7s\n",
      "224:\tlearn: 0.3205742\ttotal: 8.04s\tremaining: 27.7s\n",
      "225:\tlearn: 0.3204087\ttotal: 8.07s\tremaining: 27.6s\n",
      "226:\tlearn: 0.3197848\ttotal: 8.11s\tremaining: 27.6s\n",
      "227:\tlearn: 0.3192445\ttotal: 8.14s\tremaining: 27.6s\n",
      "228:\tlearn: 0.3188162\ttotal: 8.18s\tremaining: 27.5s\n",
      "229:\tlearn: 0.3186320\ttotal: 8.22s\tremaining: 27.5s\n",
      "230:\tlearn: 0.3180237\ttotal: 8.25s\tremaining: 27.5s\n",
      "231:\tlearn: 0.3177815\ttotal: 8.28s\tremaining: 27.4s\n",
      "232:\tlearn: 0.3176206\ttotal: 8.31s\tremaining: 27.4s\n",
      "233:\tlearn: 0.3169200\ttotal: 8.35s\tremaining: 27.3s\n",
      "234:\tlearn: 0.3166630\ttotal: 8.38s\tremaining: 27.3s\n",
      "235:\tlearn: 0.3161692\ttotal: 8.41s\tremaining: 27.2s\n",
      "236:\tlearn: 0.3157165\ttotal: 8.46s\tremaining: 27.2s\n",
      "237:\tlearn: 0.3150127\ttotal: 8.51s\tremaining: 27.2s\n",
      "238:\tlearn: 0.3146772\ttotal: 8.55s\tremaining: 27.2s\n",
      "239:\tlearn: 0.3138613\ttotal: 8.58s\tremaining: 27.2s\n",
      "240:\tlearn: 0.3134805\ttotal: 8.63s\tremaining: 27.2s\n",
      "241:\tlearn: 0.3125862\ttotal: 8.67s\tremaining: 27.1s\n",
      "242:\tlearn: 0.3122534\ttotal: 8.7s\tremaining: 27.1s\n",
      "243:\tlearn: 0.3119321\ttotal: 8.73s\tremaining: 27.1s\n",
      "244:\tlearn: 0.3113649\ttotal: 8.77s\tremaining: 27s\n",
      "245:\tlearn: 0.3112047\ttotal: 8.8s\tremaining: 27s\n",
      "246:\tlearn: 0.3105763\ttotal: 8.84s\tremaining: 26.9s\n",
      "247:\tlearn: 0.3102633\ttotal: 8.87s\tremaining: 26.9s\n",
      "248:\tlearn: 0.3098047\ttotal: 8.91s\tremaining: 26.9s\n",
      "249:\tlearn: 0.3090907\ttotal: 8.95s\tremaining: 26.9s\n",
      "250:\tlearn: 0.3089702\ttotal: 8.99s\tremaining: 26.8s\n",
      "251:\tlearn: 0.3088165\ttotal: 9.03s\tremaining: 26.8s\n",
      "252:\tlearn: 0.3080561\ttotal: 9.06s\tremaining: 26.8s\n",
      "253:\tlearn: 0.3078506\ttotal: 9.09s\tremaining: 26.7s\n",
      "254:\tlearn: 0.3074772\ttotal: 9.13s\tremaining: 26.7s\n",
      "255:\tlearn: 0.3072375\ttotal: 9.18s\tremaining: 26.7s\n",
      "256:\tlearn: 0.3066398\ttotal: 9.21s\tremaining: 26.6s\n",
      "257:\tlearn: 0.3057524\ttotal: 9.24s\tremaining: 26.6s\n",
      "258:\tlearn: 0.3055410\ttotal: 9.28s\tremaining: 26.5s\n",
      "259:\tlearn: 0.3053424\ttotal: 9.31s\tremaining: 26.5s\n",
      "260:\tlearn: 0.3047177\ttotal: 9.34s\tremaining: 26.5s\n",
      "261:\tlearn: 0.3042052\ttotal: 9.38s\tremaining: 26.4s\n",
      "262:\tlearn: 0.3039072\ttotal: 9.41s\tremaining: 26.4s\n",
      "263:\tlearn: 0.3037089\ttotal: 9.46s\tremaining: 26.4s\n",
      "264:\tlearn: 0.3034109\ttotal: 9.51s\tremaining: 26.4s\n",
      "265:\tlearn: 0.3029593\ttotal: 9.54s\tremaining: 26.3s\n",
      "266:\tlearn: 0.3027227\ttotal: 9.57s\tremaining: 26.3s\n",
      "267:\tlearn: 0.3026207\ttotal: 9.6s\tremaining: 26.2s\n",
      "268:\tlearn: 0.3021790\ttotal: 9.63s\tremaining: 26.2s\n",
      "269:\tlearn: 0.3016575\ttotal: 9.66s\tremaining: 26.1s\n",
      "270:\tlearn: 0.3013087\ttotal: 9.7s\tremaining: 26.1s\n",
      "271:\tlearn: 0.3011597\ttotal: 9.73s\tremaining: 26s\n",
      "272:\tlearn: 0.3010220\ttotal: 9.76s\tremaining: 26s\n",
      "273:\tlearn: 0.3005320\ttotal: 9.8s\tremaining: 26s\n",
      "274:\tlearn: 0.3004361\ttotal: 9.83s\tremaining: 25.9s\n",
      "275:\tlearn: 0.3001678\ttotal: 9.87s\tremaining: 25.9s\n",
      "276:\tlearn: 0.2999211\ttotal: 9.91s\tremaining: 25.9s\n",
      "277:\tlearn: 0.2995100\ttotal: 9.95s\tremaining: 25.8s\n",
      "278:\tlearn: 0.2993575\ttotal: 9.97s\tremaining: 25.8s\n",
      "279:\tlearn: 0.2990412\ttotal: 10s\tremaining: 25.7s\n",
      "280:\tlearn: 0.2989253\ttotal: 10s\tremaining: 25.7s\n",
      "281:\tlearn: 0.2987020\ttotal: 10.1s\tremaining: 25.6s\n",
      "282:\tlearn: 0.2983243\ttotal: 10.1s\tremaining: 25.6s\n",
      "283:\tlearn: 0.2978189\ttotal: 10.1s\tremaining: 25.6s\n",
      "284:\tlearn: 0.2974858\ttotal: 10.2s\tremaining: 25.6s\n",
      "285:\tlearn: 0.2970648\ttotal: 10.2s\tremaining: 25.5s\n",
      "286:\tlearn: 0.2967740\ttotal: 10.3s\tremaining: 25.5s\n",
      "287:\tlearn: 0.2964558\ttotal: 10.3s\tremaining: 25.5s\n",
      "288:\tlearn: 0.2959950\ttotal: 10.3s\tremaining: 25.4s\n",
      "289:\tlearn: 0.2957536\ttotal: 10.4s\tremaining: 25.4s\n",
      "290:\tlearn: 0.2955388\ttotal: 10.4s\tremaining: 25.3s\n",
      "291:\tlearn: 0.2950842\ttotal: 10.4s\tremaining: 25.3s\n",
      "292:\tlearn: 0.2948442\ttotal: 10.5s\tremaining: 25.2s\n",
      "293:\tlearn: 0.2945575\ttotal: 10.5s\tremaining: 25.2s\n",
      "294:\tlearn: 0.2941418\ttotal: 10.5s\tremaining: 25.2s\n",
      "295:\tlearn: 0.2939523\ttotal: 10.6s\tremaining: 25.2s\n",
      "296:\tlearn: 0.2934539\ttotal: 10.6s\tremaining: 25.2s\n",
      "297:\tlearn: 0.2931379\ttotal: 10.7s\tremaining: 25.1s\n",
      "298:\tlearn: 0.2930511\ttotal: 10.7s\tremaining: 25.1s\n",
      "299:\tlearn: 0.2927496\ttotal: 10.7s\tremaining: 25s\n",
      "300:\tlearn: 0.2923193\ttotal: 10.8s\tremaining: 25s\n",
      "301:\tlearn: 0.2920880\ttotal: 10.8s\tremaining: 24.9s\n",
      "302:\tlearn: 0.2915232\ttotal: 10.8s\tremaining: 24.9s\n",
      "303:\tlearn: 0.2908758\ttotal: 10.9s\tremaining: 24.9s\n",
      "304:\tlearn: 0.2905966\ttotal: 10.9s\tremaining: 24.8s\n",
      "305:\tlearn: 0.2899710\ttotal: 11s\tremaining: 24.8s\n",
      "306:\tlearn: 0.2897185\ttotal: 11s\tremaining: 24.8s\n",
      "307:\tlearn: 0.2888949\ttotal: 11s\tremaining: 24.8s\n",
      "308:\tlearn: 0.2884753\ttotal: 11.1s\tremaining: 24.7s\n",
      "309:\tlearn: 0.2882120\ttotal: 11.1s\tremaining: 24.7s\n",
      "310:\tlearn: 0.2880888\ttotal: 11.1s\tremaining: 24.6s\n",
      "311:\tlearn: 0.2879611\ttotal: 11.1s\tremaining: 24.6s\n",
      "312:\tlearn: 0.2875804\ttotal: 11.2s\tremaining: 24.5s\n",
      "313:\tlearn: 0.2873482\ttotal: 11.2s\tremaining: 24.5s\n",
      "314:\tlearn: 0.2868734\ttotal: 11.3s\tremaining: 24.5s\n",
      "315:\tlearn: 0.2866407\ttotal: 11.3s\tremaining: 24.5s\n",
      "316:\tlearn: 0.2864311\ttotal: 11.3s\tremaining: 24.4s\n",
      "317:\tlearn: 0.2861946\ttotal: 11.4s\tremaining: 24.4s\n",
      "318:\tlearn: 0.2860783\ttotal: 11.4s\tremaining: 24.4s\n",
      "319:\tlearn: 0.2853073\ttotal: 11.4s\tremaining: 24.3s\n",
      "320:\tlearn: 0.2849110\ttotal: 11.5s\tremaining: 24.3s\n",
      "321:\tlearn: 0.2846568\ttotal: 11.5s\tremaining: 24.2s\n",
      "322:\tlearn: 0.2844263\ttotal: 11.5s\tremaining: 24.2s\n",
      "323:\tlearn: 0.2842792\ttotal: 11.6s\tremaining: 24.2s\n",
      "324:\tlearn: 0.2840115\ttotal: 11.6s\tremaining: 24.1s\n",
      "325:\tlearn: 0.2835672\ttotal: 11.7s\tremaining: 24.1s\n",
      "326:\tlearn: 0.2833270\ttotal: 11.7s\tremaining: 24.1s\n",
      "327:\tlearn: 0.2828666\ttotal: 11.7s\tremaining: 24.1s\n",
      "328:\tlearn: 0.2824753\ttotal: 11.8s\tremaining: 24s\n",
      "329:\tlearn: 0.2820869\ttotal: 11.8s\tremaining: 24s\n",
      "330:\tlearn: 0.2817129\ttotal: 11.9s\tremaining: 24s\n",
      "331:\tlearn: 0.2814883\ttotal: 11.9s\tremaining: 23.9s\n",
      "332:\tlearn: 0.2810138\ttotal: 11.9s\tremaining: 23.9s\n",
      "333:\tlearn: 0.2805617\ttotal: 12s\tremaining: 23.9s\n",
      "334:\tlearn: 0.2802377\ttotal: 12s\tremaining: 23.8s\n",
      "335:\tlearn: 0.2801599\ttotal: 12s\tremaining: 23.8s\n",
      "336:\tlearn: 0.2794999\ttotal: 12.1s\tremaining: 23.8s\n",
      "337:\tlearn: 0.2793988\ttotal: 12.1s\tremaining: 23.8s\n",
      "338:\tlearn: 0.2792608\ttotal: 12.2s\tremaining: 23.7s\n",
      "339:\tlearn: 0.2790483\ttotal: 12.2s\tremaining: 23.7s\n",
      "340:\tlearn: 0.2789011\ttotal: 12.2s\tremaining: 23.6s\n",
      "341:\tlearn: 0.2786996\ttotal: 12.3s\tremaining: 23.6s\n",
      "342:\tlearn: 0.2783937\ttotal: 12.3s\tremaining: 23.6s\n",
      "343:\tlearn: 0.2781150\ttotal: 12.3s\tremaining: 23.5s\n",
      "344:\tlearn: 0.2778606\ttotal: 12.4s\tremaining: 23.5s\n",
      "345:\tlearn: 0.2776027\ttotal: 12.4s\tremaining: 23.5s\n",
      "346:\tlearn: 0.2771942\ttotal: 12.4s\tremaining: 23.4s\n",
      "347:\tlearn: 0.2769301\ttotal: 12.5s\tremaining: 23.4s\n",
      "348:\tlearn: 0.2766867\ttotal: 12.5s\tremaining: 23.4s\n",
      "349:\tlearn: 0.2764062\ttotal: 12.6s\tremaining: 23.4s\n",
      "350:\tlearn: 0.2761170\ttotal: 12.6s\tremaining: 23.3s\n",
      "351:\tlearn: 0.2758541\ttotal: 12.6s\tremaining: 23.3s\n",
      "352:\tlearn: 0.2754579\ttotal: 12.7s\tremaining: 23.2s\n",
      "353:\tlearn: 0.2752535\ttotal: 12.7s\tremaining: 23.2s\n",
      "354:\tlearn: 0.2750191\ttotal: 12.7s\tremaining: 23.1s\n",
      "355:\tlearn: 0.2747433\ttotal: 12.8s\tremaining: 23.1s\n",
      "356:\tlearn: 0.2744549\ttotal: 12.8s\tremaining: 23.1s\n",
      "357:\tlearn: 0.2741925\ttotal: 12.8s\tremaining: 23s\n",
      "358:\tlearn: 0.2739060\ttotal: 12.9s\tremaining: 23s\n",
      "359:\tlearn: 0.2736153\ttotal: 12.9s\tremaining: 23s\n",
      "360:\tlearn: 0.2734556\ttotal: 13s\tremaining: 22.9s\n",
      "361:\tlearn: 0.2730195\ttotal: 13s\tremaining: 22.9s\n",
      "362:\tlearn: 0.2726986\ttotal: 13s\tremaining: 22.9s\n",
      "363:\tlearn: 0.2725716\ttotal: 13.1s\tremaining: 22.8s\n",
      "364:\tlearn: 0.2725353\ttotal: 13.1s\tremaining: 22.8s\n",
      "365:\tlearn: 0.2722746\ttotal: 13.1s\tremaining: 22.7s\n",
      "366:\tlearn: 0.2722137\ttotal: 13.2s\tremaining: 22.7s\n",
      "367:\tlearn: 0.2720030\ttotal: 13.2s\tremaining: 22.7s\n",
      "368:\tlearn: 0.2716255\ttotal: 13.2s\tremaining: 22.6s\n",
      "369:\tlearn: 0.2714698\ttotal: 13.3s\tremaining: 22.6s\n",
      "370:\tlearn: 0.2712838\ttotal: 13.3s\tremaining: 22.6s\n",
      "371:\tlearn: 0.2708229\ttotal: 13.4s\tremaining: 22.6s\n",
      "372:\tlearn: 0.2703704\ttotal: 13.4s\tremaining: 22.5s\n",
      "373:\tlearn: 0.2701219\ttotal: 13.4s\tremaining: 22.5s\n",
      "374:\tlearn: 0.2698447\ttotal: 13.5s\tremaining: 22.5s\n",
      "375:\tlearn: 0.2695044\ttotal: 13.5s\tremaining: 22.4s\n",
      "376:\tlearn: 0.2693446\ttotal: 13.6s\tremaining: 22.4s\n",
      "377:\tlearn: 0.2689865\ttotal: 13.6s\tremaining: 22.4s\n",
      "378:\tlearn: 0.2687510\ttotal: 13.6s\tremaining: 22.3s\n",
      "379:\tlearn: 0.2685628\ttotal: 13.7s\tremaining: 22.3s\n",
      "380:\tlearn: 0.2682780\ttotal: 13.7s\tremaining: 22.2s\n",
      "381:\tlearn: 0.2680517\ttotal: 13.7s\tremaining: 22.2s\n",
      "382:\tlearn: 0.2677619\ttotal: 13.8s\tremaining: 22.2s\n",
      "383:\tlearn: 0.2675870\ttotal: 13.8s\tremaining: 22.2s\n",
      "384:\tlearn: 0.2674289\ttotal: 13.9s\tremaining: 22.1s\n",
      "385:\tlearn: 0.2670361\ttotal: 13.9s\tremaining: 22.1s\n",
      "386:\tlearn: 0.2669286\ttotal: 13.9s\tremaining: 22s\n",
      "387:\tlearn: 0.2664091\ttotal: 14s\tremaining: 22s\n",
      "388:\tlearn: 0.2663335\ttotal: 14s\tremaining: 22s\n",
      "389:\tlearn: 0.2662531\ttotal: 14s\tremaining: 21.9s\n",
      "390:\tlearn: 0.2658054\ttotal: 14s\tremaining: 21.9s\n",
      "391:\tlearn: 0.2654848\ttotal: 14.1s\tremaining: 21.9s\n",
      "392:\tlearn: 0.2651669\ttotal: 14.1s\tremaining: 21.8s\n",
      "393:\tlearn: 0.2650206\ttotal: 14.2s\tremaining: 21.8s\n",
      "394:\tlearn: 0.2647599\ttotal: 14.2s\tremaining: 21.8s\n",
      "395:\tlearn: 0.2646443\ttotal: 14.2s\tremaining: 21.7s\n",
      "396:\tlearn: 0.2642768\ttotal: 14.3s\tremaining: 21.7s\n",
      "397:\tlearn: 0.2639517\ttotal: 14.3s\tremaining: 21.6s\n",
      "398:\tlearn: 0.2637583\ttotal: 14.3s\tremaining: 21.6s\n",
      "399:\tlearn: 0.2635849\ttotal: 14.4s\tremaining: 21.6s\n",
      "400:\tlearn: 0.2635237\ttotal: 14.4s\tremaining: 21.5s\n",
      "401:\tlearn: 0.2634038\ttotal: 14.4s\tremaining: 21.5s\n",
      "402:\tlearn: 0.2632939\ttotal: 14.5s\tremaining: 21.5s\n",
      "403:\tlearn: 0.2632397\ttotal: 14.5s\tremaining: 21.4s\n",
      "404:\tlearn: 0.2627644\ttotal: 14.6s\tremaining: 21.4s\n",
      "405:\tlearn: 0.2625795\ttotal: 14.6s\tremaining: 21.4s\n",
      "406:\tlearn: 0.2623436\ttotal: 14.7s\tremaining: 21.3s\n",
      "407:\tlearn: 0.2621322\ttotal: 14.7s\tremaining: 21.3s\n",
      "408:\tlearn: 0.2617873\ttotal: 14.7s\tremaining: 21.3s\n",
      "409:\tlearn: 0.2616718\ttotal: 14.8s\tremaining: 21.2s\n",
      "410:\tlearn: 0.2615056\ttotal: 14.8s\tremaining: 21.2s\n",
      "411:\tlearn: 0.2611945\ttotal: 14.8s\tremaining: 21.2s\n",
      "412:\tlearn: 0.2608757\ttotal: 14.9s\tremaining: 21.1s\n",
      "413:\tlearn: 0.2605632\ttotal: 14.9s\tremaining: 21.1s\n",
      "414:\tlearn: 0.2603531\ttotal: 15s\tremaining: 21.1s\n",
      "415:\tlearn: 0.2599917\ttotal: 15s\tremaining: 21.1s\n",
      "416:\tlearn: 0.2596519\ttotal: 15s\tremaining: 21s\n",
      "417:\tlearn: 0.2592434\ttotal: 15.1s\tremaining: 21s\n",
      "418:\tlearn: 0.2588782\ttotal: 15.1s\tremaining: 20.9s\n",
      "419:\tlearn: 0.2586823\ttotal: 15.1s\tremaining: 20.9s\n",
      "420:\tlearn: 0.2585088\ttotal: 15.2s\tremaining: 20.9s\n",
      "421:\tlearn: 0.2582083\ttotal: 15.2s\tremaining: 20.8s\n",
      "422:\tlearn: 0.2577517\ttotal: 15.2s\tremaining: 20.8s\n",
      "423:\tlearn: 0.2576591\ttotal: 15.3s\tremaining: 20.8s\n",
      "424:\tlearn: 0.2573240\ttotal: 15.3s\tremaining: 20.7s\n",
      "425:\tlearn: 0.2572071\ttotal: 15.3s\tremaining: 20.7s\n",
      "426:\tlearn: 0.2571091\ttotal: 15.4s\tremaining: 20.6s\n",
      "427:\tlearn: 0.2568782\ttotal: 15.4s\tremaining: 20.6s\n",
      "428:\tlearn: 0.2564846\ttotal: 15.5s\tremaining: 20.6s\n",
      "429:\tlearn: 0.2560287\ttotal: 15.5s\tremaining: 20.6s\n",
      "430:\tlearn: 0.2556254\ttotal: 15.5s\tremaining: 20.5s\n",
      "431:\tlearn: 0.2554511\ttotal: 15.6s\tremaining: 20.5s\n",
      "432:\tlearn: 0.2551625\ttotal: 15.6s\tremaining: 20.4s\n",
      "433:\tlearn: 0.2545577\ttotal: 15.6s\tremaining: 20.4s\n",
      "434:\tlearn: 0.2542401\ttotal: 15.7s\tremaining: 20.4s\n",
      "435:\tlearn: 0.2539530\ttotal: 15.7s\tremaining: 20.3s\n",
      "436:\tlearn: 0.2538535\ttotal: 15.8s\tremaining: 20.3s\n",
      "437:\tlearn: 0.2536116\ttotal: 15.8s\tremaining: 20.3s\n",
      "438:\tlearn: 0.2534488\ttotal: 15.8s\tremaining: 20.2s\n",
      "439:\tlearn: 0.2532005\ttotal: 15.9s\tremaining: 20.2s\n",
      "440:\tlearn: 0.2530197\ttotal: 15.9s\tremaining: 20.1s\n",
      "441:\tlearn: 0.2529393\ttotal: 15.9s\tremaining: 20.1s\n",
      "442:\tlearn: 0.2526832\ttotal: 16s\tremaining: 20.1s\n",
      "443:\tlearn: 0.2524854\ttotal: 16s\tremaining: 20s\n",
      "444:\tlearn: 0.2522908\ttotal: 16s\tremaining: 20s\n",
      "445:\tlearn: 0.2520370\ttotal: 16.1s\tremaining: 20s\n",
      "446:\tlearn: 0.2517720\ttotal: 16.1s\tremaining: 19.9s\n",
      "447:\tlearn: 0.2515328\ttotal: 16.1s\tremaining: 19.9s\n",
      "448:\tlearn: 0.2513560\ttotal: 16.2s\tremaining: 19.8s\n",
      "449:\tlearn: 0.2510850\ttotal: 16.2s\tremaining: 19.8s\n",
      "450:\tlearn: 0.2509470\ttotal: 16.2s\tremaining: 19.8s\n",
      "451:\tlearn: 0.2506870\ttotal: 16.3s\tremaining: 19.8s\n",
      "452:\tlearn: 0.2506280\ttotal: 16.3s\tremaining: 19.7s\n",
      "453:\tlearn: 0.2502915\ttotal: 16.4s\tremaining: 19.7s\n",
      "454:\tlearn: 0.2500998\ttotal: 16.4s\tremaining: 19.6s\n",
      "455:\tlearn: 0.2500354\ttotal: 16.4s\tremaining: 19.6s\n",
      "456:\tlearn: 0.2499386\ttotal: 16.5s\tremaining: 19.6s\n",
      "457:\tlearn: 0.2497865\ttotal: 16.5s\tremaining: 19.5s\n",
      "458:\tlearn: 0.2496142\ttotal: 16.5s\tremaining: 19.5s\n",
      "459:\tlearn: 0.2494875\ttotal: 16.6s\tremaining: 19.4s\n",
      "460:\tlearn: 0.2491588\ttotal: 16.6s\tremaining: 19.4s\n",
      "461:\tlearn: 0.2491210\ttotal: 16.6s\tremaining: 19.4s\n",
      "462:\tlearn: 0.2489653\ttotal: 16.7s\tremaining: 19.3s\n",
      "463:\tlearn: 0.2487299\ttotal: 16.7s\tremaining: 19.3s\n",
      "464:\tlearn: 0.2484144\ttotal: 16.7s\tremaining: 19.3s\n",
      "465:\tlearn: 0.2481588\ttotal: 16.8s\tremaining: 19.2s\n",
      "466:\tlearn: 0.2480390\ttotal: 16.8s\tremaining: 19.2s\n",
      "467:\tlearn: 0.2479367\ttotal: 16.8s\tremaining: 19.1s\n",
      "468:\tlearn: 0.2478380\ttotal: 16.9s\tremaining: 19.1s\n",
      "469:\tlearn: 0.2476597\ttotal: 16.9s\tremaining: 19.1s\n",
      "470:\tlearn: 0.2474652\ttotal: 16.9s\tremaining: 19s\n",
      "471:\tlearn: 0.2473544\ttotal: 17s\tremaining: 19s\n",
      "472:\tlearn: 0.2471054\ttotal: 17s\tremaining: 19s\n",
      "473:\tlearn: 0.2470493\ttotal: 17.1s\tremaining: 18.9s\n",
      "474:\tlearn: 0.2468533\ttotal: 17.1s\tremaining: 18.9s\n",
      "475:\tlearn: 0.2467542\ttotal: 17.1s\tremaining: 18.9s\n",
      "476:\tlearn: 0.2466285\ttotal: 17.2s\tremaining: 18.8s\n",
      "477:\tlearn: 0.2464489\ttotal: 17.2s\tremaining: 18.8s\n",
      "478:\tlearn: 0.2461391\ttotal: 17.2s\tremaining: 18.7s\n",
      "479:\tlearn: 0.2460534\ttotal: 17.3s\tremaining: 18.7s\n",
      "480:\tlearn: 0.2458169\ttotal: 17.3s\tremaining: 18.7s\n",
      "481:\tlearn: 0.2455250\ttotal: 17.3s\tremaining: 18.6s\n",
      "482:\tlearn: 0.2452916\ttotal: 17.4s\tremaining: 18.6s\n",
      "483:\tlearn: 0.2449144\ttotal: 17.4s\tremaining: 18.6s\n",
      "484:\tlearn: 0.2447392\ttotal: 17.5s\tremaining: 18.5s\n",
      "485:\tlearn: 0.2444644\ttotal: 17.5s\tremaining: 18.5s\n",
      "486:\tlearn: 0.2441586\ttotal: 17.5s\tremaining: 18.5s\n",
      "487:\tlearn: 0.2439628\ttotal: 17.6s\tremaining: 18.4s\n",
      "488:\tlearn: 0.2438375\ttotal: 17.6s\tremaining: 18.4s\n",
      "489:\tlearn: 0.2435797\ttotal: 17.6s\tremaining: 18.3s\n",
      "490:\tlearn: 0.2434656\ttotal: 17.7s\tremaining: 18.3s\n",
      "491:\tlearn: 0.2431266\ttotal: 17.7s\tremaining: 18.3s\n",
      "492:\tlearn: 0.2429655\ttotal: 17.7s\tremaining: 18.2s\n",
      "493:\tlearn: 0.2426874\ttotal: 17.8s\tremaining: 18.2s\n",
      "494:\tlearn: 0.2426238\ttotal: 17.8s\tremaining: 18.2s\n",
      "495:\tlearn: 0.2422961\ttotal: 17.9s\tremaining: 18.1s\n",
      "496:\tlearn: 0.2421934\ttotal: 17.9s\tremaining: 18.1s\n",
      "497:\tlearn: 0.2419635\ttotal: 17.9s\tremaining: 18.1s\n",
      "498:\tlearn: 0.2417560\ttotal: 18s\tremaining: 18s\n",
      "499:\tlearn: 0.2416778\ttotal: 18s\tremaining: 18s\n",
      "500:\tlearn: 0.2413266\ttotal: 18s\tremaining: 18s\n",
      "501:\tlearn: 0.2410853\ttotal: 18.1s\tremaining: 17.9s\n",
      "502:\tlearn: 0.2408889\ttotal: 18.1s\tremaining: 17.9s\n",
      "503:\tlearn: 0.2405256\ttotal: 18.1s\tremaining: 17.9s\n",
      "504:\tlearn: 0.2404494\ttotal: 18.2s\tremaining: 17.8s\n",
      "505:\tlearn: 0.2403328\ttotal: 18.2s\tremaining: 17.8s\n",
      "506:\tlearn: 0.2401535\ttotal: 18.3s\tremaining: 17.8s\n",
      "507:\tlearn: 0.2398666\ttotal: 18.3s\tremaining: 17.7s\n",
      "508:\tlearn: 0.2396943\ttotal: 18.3s\tremaining: 17.7s\n",
      "509:\tlearn: 0.2394033\ttotal: 18.4s\tremaining: 17.7s\n",
      "510:\tlearn: 0.2389561\ttotal: 18.4s\tremaining: 17.6s\n",
      "511:\tlearn: 0.2388118\ttotal: 18.5s\tremaining: 17.6s\n",
      "512:\tlearn: 0.2386281\ttotal: 18.5s\tremaining: 17.6s\n",
      "513:\tlearn: 0.2384072\ttotal: 18.5s\tremaining: 17.5s\n",
      "514:\tlearn: 0.2382576\ttotal: 18.6s\tremaining: 17.5s\n",
      "515:\tlearn: 0.2381911\ttotal: 18.6s\tremaining: 17.4s\n",
      "516:\tlearn: 0.2381062\ttotal: 18.6s\tremaining: 17.4s\n",
      "517:\tlearn: 0.2379750\ttotal: 18.7s\tremaining: 17.4s\n",
      "518:\tlearn: 0.2378973\ttotal: 18.7s\tremaining: 17.3s\n",
      "519:\tlearn: 0.2376808\ttotal: 18.7s\tremaining: 17.3s\n",
      "520:\tlearn: 0.2375763\ttotal: 18.8s\tremaining: 17.3s\n",
      "521:\tlearn: 0.2374121\ttotal: 18.8s\tremaining: 17.2s\n",
      "522:\tlearn: 0.2372454\ttotal: 18.8s\tremaining: 17.2s\n",
      "523:\tlearn: 0.2371234\ttotal: 18.9s\tremaining: 17.1s\n",
      "524:\tlearn: 0.2368742\ttotal: 18.9s\tremaining: 17.1s\n",
      "525:\tlearn: 0.2366509\ttotal: 18.9s\tremaining: 17.1s\n",
      "526:\tlearn: 0.2365702\ttotal: 19s\tremaining: 17s\n",
      "527:\tlearn: 0.2364271\ttotal: 19s\tremaining: 17s\n",
      "528:\tlearn: 0.2361435\ttotal: 19.1s\tremaining: 17s\n",
      "529:\tlearn: 0.2360754\ttotal: 19.1s\tremaining: 16.9s\n",
      "530:\tlearn: 0.2358501\ttotal: 19.1s\tremaining: 16.9s\n",
      "531:\tlearn: 0.2356150\ttotal: 19.2s\tremaining: 16.9s\n",
      "532:\tlearn: 0.2354057\ttotal: 19.2s\tremaining: 16.8s\n",
      "533:\tlearn: 0.2352802\ttotal: 19.2s\tremaining: 16.8s\n",
      "534:\tlearn: 0.2349600\ttotal: 19.3s\tremaining: 16.7s\n",
      "535:\tlearn: 0.2348765\ttotal: 19.3s\tremaining: 16.7s\n",
      "536:\tlearn: 0.2345170\ttotal: 19.3s\tremaining: 16.7s\n",
      "537:\tlearn: 0.2344041\ttotal: 19.4s\tremaining: 16.6s\n",
      "538:\tlearn: 0.2341530\ttotal: 19.4s\tremaining: 16.6s\n",
      "539:\tlearn: 0.2339842\ttotal: 19.4s\tremaining: 16.6s\n",
      "540:\tlearn: 0.2338437\ttotal: 19.5s\tremaining: 16.5s\n",
      "541:\tlearn: 0.2337099\ttotal: 19.5s\tremaining: 16.5s\n",
      "542:\tlearn: 0.2334492\ttotal: 19.6s\tremaining: 16.5s\n",
      "543:\tlearn: 0.2333188\ttotal: 19.6s\tremaining: 16.4s\n",
      "544:\tlearn: 0.2330724\ttotal: 19.6s\tremaining: 16.4s\n",
      "545:\tlearn: 0.2328412\ttotal: 19.7s\tremaining: 16.3s\n",
      "546:\tlearn: 0.2328120\ttotal: 19.7s\tremaining: 16.3s\n",
      "547:\tlearn: 0.2327206\ttotal: 19.7s\tremaining: 16.3s\n",
      "548:\tlearn: 0.2323922\ttotal: 19.8s\tremaining: 16.2s\n",
      "549:\tlearn: 0.2322385\ttotal: 19.8s\tremaining: 16.2s\n",
      "550:\tlearn: 0.2321296\ttotal: 19.8s\tremaining: 16.2s\n",
      "551:\tlearn: 0.2319453\ttotal: 19.9s\tremaining: 16.1s\n",
      "552:\tlearn: 0.2319058\ttotal: 19.9s\tremaining: 16.1s\n",
      "553:\tlearn: 0.2315778\ttotal: 19.9s\tremaining: 16.1s\n",
      "554:\tlearn: 0.2312725\ttotal: 20s\tremaining: 16s\n",
      "555:\tlearn: 0.2311829\ttotal: 20s\tremaining: 16s\n",
      "556:\tlearn: 0.2310317\ttotal: 20s\tremaining: 15.9s\n",
      "557:\tlearn: 0.2309206\ttotal: 20.1s\tremaining: 15.9s\n",
      "558:\tlearn: 0.2308191\ttotal: 20.1s\tremaining: 15.9s\n",
      "559:\tlearn: 0.2307723\ttotal: 20.1s\tremaining: 15.8s\n",
      "560:\tlearn: 0.2305184\ttotal: 20.2s\tremaining: 15.8s\n",
      "561:\tlearn: 0.2303678\ttotal: 20.2s\tremaining: 15.7s\n",
      "562:\tlearn: 0.2302221\ttotal: 20.3s\tremaining: 15.7s\n",
      "563:\tlearn: 0.2299732\ttotal: 20.3s\tremaining: 15.7s\n",
      "564:\tlearn: 0.2298398\ttotal: 20.3s\tremaining: 15.7s\n",
      "565:\tlearn: 0.2296742\ttotal: 20.4s\tremaining: 15.6s\n",
      "566:\tlearn: 0.2295326\ttotal: 20.4s\tremaining: 15.6s\n",
      "567:\tlearn: 0.2293728\ttotal: 20.4s\tremaining: 15.5s\n",
      "568:\tlearn: 0.2291962\ttotal: 20.5s\tremaining: 15.5s\n",
      "569:\tlearn: 0.2290212\ttotal: 20.5s\tremaining: 15.5s\n",
      "570:\tlearn: 0.2288656\ttotal: 20.5s\tremaining: 15.4s\n",
      "571:\tlearn: 0.2285513\ttotal: 20.6s\tremaining: 15.4s\n",
      "572:\tlearn: 0.2281874\ttotal: 20.6s\tremaining: 15.4s\n",
      "573:\tlearn: 0.2278826\ttotal: 20.6s\tremaining: 15.3s\n",
      "574:\tlearn: 0.2276167\ttotal: 20.7s\tremaining: 15.3s\n",
      "575:\tlearn: 0.2274437\ttotal: 20.7s\tremaining: 15.2s\n",
      "576:\tlearn: 0.2272510\ttotal: 20.8s\tremaining: 15.2s\n",
      "577:\tlearn: 0.2271036\ttotal: 20.8s\tremaining: 15.2s\n",
      "578:\tlearn: 0.2268426\ttotal: 20.8s\tremaining: 15.1s\n",
      "579:\tlearn: 0.2265092\ttotal: 20.9s\tremaining: 15.1s\n",
      "580:\tlearn: 0.2263271\ttotal: 20.9s\tremaining: 15.1s\n",
      "581:\tlearn: 0.2261766\ttotal: 20.9s\tremaining: 15s\n",
      "582:\tlearn: 0.2259822\ttotal: 21s\tremaining: 15s\n",
      "583:\tlearn: 0.2257135\ttotal: 21s\tremaining: 15s\n",
      "584:\tlearn: 0.2256362\ttotal: 21s\tremaining: 14.9s\n",
      "585:\tlearn: 0.2253151\ttotal: 21.1s\tremaining: 14.9s\n",
      "586:\tlearn: 0.2250719\ttotal: 21.1s\tremaining: 14.9s\n",
      "587:\tlearn: 0.2249669\ttotal: 21.2s\tremaining: 14.8s\n",
      "588:\tlearn: 0.2247725\ttotal: 21.2s\tremaining: 14.8s\n",
      "589:\tlearn: 0.2245326\ttotal: 21.2s\tremaining: 14.8s\n",
      "590:\tlearn: 0.2242986\ttotal: 21.3s\tremaining: 14.7s\n",
      "591:\tlearn: 0.2240812\ttotal: 21.3s\tremaining: 14.7s\n",
      "592:\tlearn: 0.2237917\ttotal: 21.3s\tremaining: 14.7s\n",
      "593:\tlearn: 0.2235861\ttotal: 21.4s\tremaining: 14.6s\n",
      "594:\tlearn: 0.2234052\ttotal: 21.4s\tremaining: 14.6s\n",
      "595:\tlearn: 0.2232199\ttotal: 21.5s\tremaining: 14.5s\n",
      "596:\tlearn: 0.2230546\ttotal: 21.5s\tremaining: 14.5s\n",
      "597:\tlearn: 0.2228955\ttotal: 21.5s\tremaining: 14.5s\n",
      "598:\tlearn: 0.2228134\ttotal: 21.6s\tremaining: 14.4s\n",
      "599:\tlearn: 0.2226239\ttotal: 21.6s\tremaining: 14.4s\n",
      "600:\tlearn: 0.2225161\ttotal: 21.6s\tremaining: 14.4s\n",
      "601:\tlearn: 0.2224095\ttotal: 21.7s\tremaining: 14.3s\n",
      "602:\tlearn: 0.2222596\ttotal: 21.7s\tremaining: 14.3s\n",
      "603:\tlearn: 0.2220962\ttotal: 21.7s\tremaining: 14.3s\n",
      "604:\tlearn: 0.2219266\ttotal: 21.8s\tremaining: 14.2s\n",
      "605:\tlearn: 0.2217231\ttotal: 21.8s\tremaining: 14.2s\n",
      "606:\tlearn: 0.2213866\ttotal: 21.8s\tremaining: 14.1s\n",
      "607:\tlearn: 0.2213203\ttotal: 21.9s\tremaining: 14.1s\n",
      "608:\tlearn: 0.2212464\ttotal: 21.9s\tremaining: 14.1s\n",
      "609:\tlearn: 0.2210839\ttotal: 22s\tremaining: 14s\n",
      "610:\tlearn: 0.2209324\ttotal: 22s\tremaining: 14s\n",
      "611:\tlearn: 0.2208819\ttotal: 22s\tremaining: 14s\n",
      "612:\tlearn: 0.2205768\ttotal: 22.1s\tremaining: 13.9s\n",
      "613:\tlearn: 0.2204440\ttotal: 22.1s\tremaining: 13.9s\n",
      "614:\tlearn: 0.2203321\ttotal: 22.1s\tremaining: 13.9s\n",
      "615:\tlearn: 0.2202303\ttotal: 22.2s\tremaining: 13.8s\n",
      "616:\tlearn: 0.2200968\ttotal: 22.2s\tremaining: 13.8s\n",
      "617:\tlearn: 0.2199590\ttotal: 22.2s\tremaining: 13.8s\n",
      "618:\tlearn: 0.2198111\ttotal: 22.3s\tremaining: 13.7s\n",
      "619:\tlearn: 0.2197131\ttotal: 22.3s\tremaining: 13.7s\n",
      "620:\tlearn: 0.2195658\ttotal: 22.4s\tremaining: 13.7s\n",
      "621:\tlearn: 0.2193987\ttotal: 22.4s\tremaining: 13.6s\n",
      "622:\tlearn: 0.2192434\ttotal: 22.4s\tremaining: 13.6s\n",
      "623:\tlearn: 0.2190612\ttotal: 22.5s\tremaining: 13.5s\n",
      "624:\tlearn: 0.2189789\ttotal: 22.5s\tremaining: 13.5s\n",
      "625:\tlearn: 0.2189023\ttotal: 22.5s\tremaining: 13.5s\n",
      "626:\tlearn: 0.2187489\ttotal: 22.6s\tremaining: 13.4s\n",
      "627:\tlearn: 0.2186611\ttotal: 22.6s\tremaining: 13.4s\n",
      "628:\tlearn: 0.2185314\ttotal: 22.6s\tremaining: 13.4s\n",
      "629:\tlearn: 0.2184561\ttotal: 22.7s\tremaining: 13.3s\n",
      "630:\tlearn: 0.2183041\ttotal: 22.7s\tremaining: 13.3s\n",
      "631:\tlearn: 0.2181571\ttotal: 22.8s\tremaining: 13.3s\n",
      "632:\tlearn: 0.2179766\ttotal: 22.8s\tremaining: 13.2s\n",
      "633:\tlearn: 0.2178102\ttotal: 22.8s\tremaining: 13.2s\n",
      "634:\tlearn: 0.2176894\ttotal: 22.9s\tremaining: 13.1s\n",
      "635:\tlearn: 0.2173676\ttotal: 22.9s\tremaining: 13.1s\n",
      "636:\tlearn: 0.2171336\ttotal: 22.9s\tremaining: 13.1s\n",
      "637:\tlearn: 0.2168127\ttotal: 23s\tremaining: 13s\n",
      "638:\tlearn: 0.2166823\ttotal: 23s\tremaining: 13s\n",
      "639:\tlearn: 0.2165215\ttotal: 23s\tremaining: 13s\n",
      "640:\tlearn: 0.2163985\ttotal: 23.1s\tremaining: 12.9s\n",
      "641:\tlearn: 0.2161657\ttotal: 23.1s\tremaining: 12.9s\n",
      "642:\tlearn: 0.2159211\ttotal: 23.2s\tremaining: 12.9s\n",
      "643:\tlearn: 0.2157204\ttotal: 23.2s\tremaining: 12.8s\n",
      "644:\tlearn: 0.2155976\ttotal: 23.2s\tremaining: 12.8s\n",
      "645:\tlearn: 0.2154781\ttotal: 23.3s\tremaining: 12.7s\n",
      "646:\tlearn: 0.2153759\ttotal: 23.3s\tremaining: 12.7s\n",
      "647:\tlearn: 0.2150911\ttotal: 23.3s\tremaining: 12.7s\n",
      "648:\tlearn: 0.2150118\ttotal: 23.4s\tremaining: 12.6s\n",
      "649:\tlearn: 0.2149534\ttotal: 23.4s\tremaining: 12.6s\n",
      "650:\tlearn: 0.2147463\ttotal: 23.4s\tremaining: 12.6s\n",
      "651:\tlearn: 0.2146913\ttotal: 23.5s\tremaining: 12.5s\n",
      "652:\tlearn: 0.2146358\ttotal: 23.5s\tremaining: 12.5s\n",
      "653:\tlearn: 0.2144324\ttotal: 23.5s\tremaining: 12.5s\n",
      "654:\tlearn: 0.2143425\ttotal: 23.6s\tremaining: 12.4s\n",
      "655:\tlearn: 0.2141611\ttotal: 23.6s\tremaining: 12.4s\n",
      "656:\tlearn: 0.2140391\ttotal: 23.6s\tremaining: 12.3s\n",
      "657:\tlearn: 0.2138254\ttotal: 23.7s\tremaining: 12.3s\n",
      "658:\tlearn: 0.2135810\ttotal: 23.7s\tremaining: 12.3s\n",
      "659:\tlearn: 0.2134661\ttotal: 23.7s\tremaining: 12.2s\n",
      "660:\tlearn: 0.2133406\ttotal: 23.8s\tremaining: 12.2s\n",
      "661:\tlearn: 0.2132383\ttotal: 23.8s\tremaining: 12.2s\n",
      "662:\tlearn: 0.2130978\ttotal: 23.9s\tremaining: 12.1s\n",
      "663:\tlearn: 0.2128762\ttotal: 23.9s\tremaining: 12.1s\n",
      "664:\tlearn: 0.2127270\ttotal: 23.9s\tremaining: 12.1s\n",
      "665:\tlearn: 0.2125795\ttotal: 24s\tremaining: 12s\n",
      "666:\tlearn: 0.2123141\ttotal: 24s\tremaining: 12s\n",
      "667:\tlearn: 0.2122396\ttotal: 24s\tremaining: 12s\n",
      "668:\tlearn: 0.2121352\ttotal: 24.1s\tremaining: 11.9s\n",
      "669:\tlearn: 0.2120357\ttotal: 24.1s\tremaining: 11.9s\n",
      "670:\tlearn: 0.2119116\ttotal: 24.2s\tremaining: 11.8s\n",
      "671:\tlearn: 0.2117518\ttotal: 24.2s\tremaining: 11.8s\n",
      "672:\tlearn: 0.2117012\ttotal: 24.2s\tremaining: 11.8s\n",
      "673:\tlearn: 0.2116139\ttotal: 24.3s\tremaining: 11.7s\n",
      "674:\tlearn: 0.2115177\ttotal: 24.3s\tremaining: 11.7s\n",
      "675:\tlearn: 0.2111973\ttotal: 24.3s\tremaining: 11.7s\n",
      "676:\tlearn: 0.2110514\ttotal: 24.4s\tremaining: 11.6s\n",
      "677:\tlearn: 0.2110245\ttotal: 24.4s\tremaining: 11.6s\n",
      "678:\tlearn: 0.2109944\ttotal: 24.4s\tremaining: 11.6s\n",
      "679:\tlearn: 0.2109072\ttotal: 24.5s\tremaining: 11.5s\n",
      "680:\tlearn: 0.2105669\ttotal: 24.5s\tremaining: 11.5s\n",
      "681:\tlearn: 0.2104603\ttotal: 24.5s\tremaining: 11.4s\n",
      "682:\tlearn: 0.2101335\ttotal: 24.6s\tremaining: 11.4s\n",
      "683:\tlearn: 0.2100369\ttotal: 24.6s\tremaining: 11.4s\n",
      "684:\tlearn: 0.2098857\ttotal: 24.7s\tremaining: 11.3s\n",
      "685:\tlearn: 0.2098098\ttotal: 24.7s\tremaining: 11.3s\n",
      "686:\tlearn: 0.2096525\ttotal: 24.7s\tremaining: 11.3s\n",
      "687:\tlearn: 0.2094668\ttotal: 24.8s\tremaining: 11.2s\n",
      "688:\tlearn: 0.2093219\ttotal: 24.8s\tremaining: 11.2s\n",
      "689:\tlearn: 0.2092280\ttotal: 24.8s\tremaining: 11.2s\n",
      "690:\tlearn: 0.2091673\ttotal: 24.9s\tremaining: 11.1s\n",
      "691:\tlearn: 0.2090326\ttotal: 24.9s\tremaining: 11.1s\n",
      "692:\tlearn: 0.2088214\ttotal: 24.9s\tremaining: 11s\n",
      "693:\tlearn: 0.2087121\ttotal: 25s\tremaining: 11s\n",
      "694:\tlearn: 0.2086233\ttotal: 25s\tremaining: 11s\n",
      "695:\tlearn: 0.2084629\ttotal: 25.1s\tremaining: 10.9s\n",
      "696:\tlearn: 0.2082540\ttotal: 25.1s\tremaining: 10.9s\n",
      "697:\tlearn: 0.2080550\ttotal: 25.1s\tremaining: 10.9s\n",
      "698:\tlearn: 0.2079732\ttotal: 25.2s\tremaining: 10.8s\n",
      "699:\tlearn: 0.2077648\ttotal: 25.2s\tremaining: 10.8s\n",
      "700:\tlearn: 0.2075922\ttotal: 25.2s\tremaining: 10.8s\n",
      "701:\tlearn: 0.2074746\ttotal: 25.3s\tremaining: 10.7s\n",
      "702:\tlearn: 0.2074166\ttotal: 25.3s\tremaining: 10.7s\n",
      "703:\tlearn: 0.2072729\ttotal: 25.3s\tremaining: 10.7s\n",
      "704:\tlearn: 0.2070992\ttotal: 25.4s\tremaining: 10.6s\n",
      "705:\tlearn: 0.2070082\ttotal: 25.4s\tremaining: 10.6s\n",
      "706:\tlearn: 0.2069314\ttotal: 25.5s\tremaining: 10.6s\n",
      "707:\tlearn: 0.2066828\ttotal: 25.5s\tremaining: 10.5s\n",
      "708:\tlearn: 0.2065167\ttotal: 25.5s\tremaining: 10.5s\n",
      "709:\tlearn: 0.2063549\ttotal: 25.6s\tremaining: 10.4s\n",
      "710:\tlearn: 0.2062874\ttotal: 25.6s\tremaining: 10.4s\n",
      "711:\tlearn: 0.2062188\ttotal: 25.6s\tremaining: 10.4s\n",
      "712:\tlearn: 0.2060983\ttotal: 25.7s\tremaining: 10.3s\n",
      "713:\tlearn: 0.2060331\ttotal: 25.7s\tremaining: 10.3s\n",
      "714:\tlearn: 0.2059592\ttotal: 25.7s\tremaining: 10.3s\n",
      "715:\tlearn: 0.2058301\ttotal: 25.8s\tremaining: 10.2s\n",
      "716:\tlearn: 0.2056456\ttotal: 25.8s\tremaining: 10.2s\n",
      "717:\tlearn: 0.2055136\ttotal: 25.9s\tremaining: 10.2s\n",
      "718:\tlearn: 0.2053776\ttotal: 25.9s\tremaining: 10.1s\n",
      "719:\tlearn: 0.2051499\ttotal: 25.9s\tremaining: 10.1s\n",
      "720:\tlearn: 0.2050789\ttotal: 26s\tremaining: 10.1s\n",
      "721:\tlearn: 0.2049544\ttotal: 26s\tremaining: 10s\n",
      "722:\tlearn: 0.2048056\ttotal: 26.1s\tremaining: 9.99s\n",
      "723:\tlearn: 0.2047355\ttotal: 26.1s\tremaining: 9.95s\n",
      "724:\tlearn: 0.2046547\ttotal: 26.1s\tremaining: 9.91s\n",
      "725:\tlearn: 0.2044166\ttotal: 26.2s\tremaining: 9.87s\n",
      "726:\tlearn: 0.2043039\ttotal: 26.2s\tremaining: 9.84s\n",
      "727:\tlearn: 0.2042050\ttotal: 26.2s\tremaining: 9.8s\n",
      "728:\tlearn: 0.2041239\ttotal: 26.3s\tremaining: 9.76s\n",
      "729:\tlearn: 0.2040020\ttotal: 26.3s\tremaining: 9.73s\n",
      "730:\tlearn: 0.2038633\ttotal: 26.4s\tremaining: 9.7s\n",
      "731:\tlearn: 0.2037775\ttotal: 26.4s\tremaining: 9.66s\n",
      "732:\tlearn: 0.2035721\ttotal: 26.4s\tremaining: 9.63s\n",
      "733:\tlearn: 0.2034197\ttotal: 26.5s\tremaining: 9.6s\n",
      "734:\tlearn: 0.2032544\ttotal: 26.5s\tremaining: 9.56s\n",
      "735:\tlearn: 0.2030963\ttotal: 26.6s\tremaining: 9.52s\n",
      "736:\tlearn: 0.2030286\ttotal: 26.6s\tremaining: 9.49s\n",
      "737:\tlearn: 0.2028147\ttotal: 26.6s\tremaining: 9.45s\n",
      "738:\tlearn: 0.2025370\ttotal: 26.7s\tremaining: 9.41s\n",
      "739:\tlearn: 0.2024715\ttotal: 26.7s\tremaining: 9.38s\n",
      "740:\tlearn: 0.2024115\ttotal: 26.7s\tremaining: 9.34s\n",
      "741:\tlearn: 0.2022436\ttotal: 26.8s\tremaining: 9.31s\n",
      "742:\tlearn: 0.2021703\ttotal: 26.8s\tremaining: 9.28s\n",
      "743:\tlearn: 0.2020240\ttotal: 26.9s\tremaining: 9.24s\n",
      "744:\tlearn: 0.2017990\ttotal: 26.9s\tremaining: 9.21s\n",
      "745:\tlearn: 0.2017418\ttotal: 26.9s\tremaining: 9.17s\n",
      "746:\tlearn: 0.2015986\ttotal: 27s\tremaining: 9.14s\n",
      "747:\tlearn: 0.2013642\ttotal: 27s\tremaining: 9.1s\n",
      "748:\tlearn: 0.2012510\ttotal: 27s\tremaining: 9.06s\n",
      "749:\tlearn: 0.2011922\ttotal: 27.1s\tremaining: 9.03s\n",
      "750:\tlearn: 0.2010176\ttotal: 27.1s\tremaining: 8.99s\n",
      "751:\tlearn: 0.2009737\ttotal: 27.1s\tremaining: 8.95s\n",
      "752:\tlearn: 0.2008282\ttotal: 27.2s\tremaining: 8.91s\n",
      "753:\tlearn: 0.2005608\ttotal: 27.2s\tremaining: 8.88s\n",
      "754:\tlearn: 0.2004915\ttotal: 27.3s\tremaining: 8.85s\n",
      "755:\tlearn: 0.2003678\ttotal: 27.3s\tremaining: 8.81s\n",
      "756:\tlearn: 0.2002729\ttotal: 27.3s\tremaining: 8.77s\n",
      "757:\tlearn: 0.2001121\ttotal: 27.4s\tremaining: 8.74s\n",
      "758:\tlearn: 0.1999465\ttotal: 27.4s\tremaining: 8.7s\n",
      "759:\tlearn: 0.1997771\ttotal: 27.4s\tremaining: 8.66s\n",
      "760:\tlearn: 0.1996563\ttotal: 27.5s\tremaining: 8.63s\n",
      "761:\tlearn: 0.1995726\ttotal: 27.5s\tremaining: 8.59s\n",
      "762:\tlearn: 0.1993638\ttotal: 27.5s\tremaining: 8.55s\n",
      "763:\tlearn: 0.1992277\ttotal: 27.6s\tremaining: 8.52s\n",
      "764:\tlearn: 0.1989866\ttotal: 27.6s\tremaining: 8.48s\n",
      "765:\tlearn: 0.1988429\ttotal: 27.7s\tremaining: 8.45s\n",
      "766:\tlearn: 0.1986788\ttotal: 27.7s\tremaining: 8.41s\n",
      "767:\tlearn: 0.1985328\ttotal: 27.7s\tremaining: 8.38s\n",
      "768:\tlearn: 0.1984603\ttotal: 27.8s\tremaining: 8.34s\n",
      "769:\tlearn: 0.1983848\ttotal: 27.8s\tremaining: 8.3s\n",
      "770:\tlearn: 0.1983035\ttotal: 27.8s\tremaining: 8.27s\n",
      "771:\tlearn: 0.1981477\ttotal: 27.9s\tremaining: 8.23s\n",
      "772:\tlearn: 0.1980598\ttotal: 27.9s\tremaining: 8.19s\n",
      "773:\tlearn: 0.1979625\ttotal: 27.9s\tremaining: 8.16s\n",
      "774:\tlearn: 0.1978896\ttotal: 28s\tremaining: 8.13s\n",
      "775:\tlearn: 0.1978167\ttotal: 28s\tremaining: 8.09s\n",
      "776:\tlearn: 0.1977090\ttotal: 28.1s\tremaining: 8.05s\n",
      "777:\tlearn: 0.1975838\ttotal: 28.1s\tremaining: 8.02s\n",
      "778:\tlearn: 0.1974367\ttotal: 28.1s\tremaining: 7.98s\n",
      "779:\tlearn: 0.1973280\ttotal: 28.2s\tremaining: 7.94s\n",
      "780:\tlearn: 0.1971746\ttotal: 28.2s\tremaining: 7.91s\n",
      "781:\tlearn: 0.1969197\ttotal: 28.2s\tremaining: 7.87s\n",
      "782:\tlearn: 0.1968073\ttotal: 28.3s\tremaining: 7.83s\n",
      "783:\tlearn: 0.1966337\ttotal: 28.3s\tremaining: 7.8s\n",
      "784:\tlearn: 0.1965797\ttotal: 28.3s\tremaining: 7.76s\n",
      "785:\tlearn: 0.1964507\ttotal: 28.4s\tremaining: 7.73s\n",
      "786:\tlearn: 0.1962452\ttotal: 28.4s\tremaining: 7.69s\n",
      "787:\tlearn: 0.1960717\ttotal: 28.5s\tremaining: 7.66s\n",
      "788:\tlearn: 0.1957814\ttotal: 28.5s\tremaining: 7.62s\n",
      "789:\tlearn: 0.1955616\ttotal: 28.5s\tremaining: 7.58s\n",
      "790:\tlearn: 0.1953844\ttotal: 28.6s\tremaining: 7.54s\n",
      "791:\tlearn: 0.1953077\ttotal: 28.6s\tremaining: 7.51s\n",
      "792:\tlearn: 0.1952023\ttotal: 28.6s\tremaining: 7.47s\n",
      "793:\tlearn: 0.1950829\ttotal: 28.7s\tremaining: 7.43s\n",
      "794:\tlearn: 0.1949296\ttotal: 28.7s\tremaining: 7.4s\n",
      "795:\tlearn: 0.1948536\ttotal: 28.7s\tremaining: 7.37s\n",
      "796:\tlearn: 0.1946976\ttotal: 28.8s\tremaining: 7.33s\n",
      "797:\tlearn: 0.1946129\ttotal: 28.8s\tremaining: 7.3s\n",
      "798:\tlearn: 0.1944741\ttotal: 28.9s\tremaining: 7.26s\n",
      "799:\tlearn: 0.1943562\ttotal: 28.9s\tremaining: 7.22s\n",
      "800:\tlearn: 0.1941480\ttotal: 28.9s\tremaining: 7.19s\n",
      "801:\tlearn: 0.1939507\ttotal: 29s\tremaining: 7.15s\n",
      "802:\tlearn: 0.1938058\ttotal: 29s\tremaining: 7.12s\n",
      "803:\tlearn: 0.1936516\ttotal: 29s\tremaining: 7.08s\n",
      "804:\tlearn: 0.1934890\ttotal: 29.1s\tremaining: 7.04s\n",
      "805:\tlearn: 0.1933421\ttotal: 29.1s\tremaining: 7.01s\n",
      "806:\tlearn: 0.1932993\ttotal: 29.1s\tremaining: 6.97s\n",
      "807:\tlearn: 0.1932358\ttotal: 29.2s\tremaining: 6.93s\n",
      "808:\tlearn: 0.1930262\ttotal: 29.2s\tremaining: 6.9s\n",
      "809:\tlearn: 0.1929637\ttotal: 29.3s\tremaining: 6.87s\n",
      "810:\tlearn: 0.1927897\ttotal: 29.3s\tremaining: 6.83s\n",
      "811:\tlearn: 0.1926665\ttotal: 29.3s\tremaining: 6.79s\n",
      "812:\tlearn: 0.1925562\ttotal: 29.4s\tremaining: 6.76s\n",
      "813:\tlearn: 0.1923689\ttotal: 29.4s\tremaining: 6.72s\n",
      "814:\tlearn: 0.1922960\ttotal: 29.4s\tremaining: 6.68s\n",
      "815:\tlearn: 0.1921827\ttotal: 29.5s\tremaining: 6.65s\n",
      "816:\tlearn: 0.1920715\ttotal: 29.5s\tremaining: 6.61s\n",
      "817:\tlearn: 0.1918017\ttotal: 29.5s\tremaining: 6.57s\n",
      "818:\tlearn: 0.1916182\ttotal: 29.6s\tremaining: 6.54s\n",
      "819:\tlearn: 0.1914130\ttotal: 29.6s\tremaining: 6.5s\n",
      "820:\tlearn: 0.1913347\ttotal: 29.6s\tremaining: 6.46s\n",
      "821:\tlearn: 0.1911164\ttotal: 29.7s\tremaining: 6.43s\n",
      "822:\tlearn: 0.1909278\ttotal: 29.7s\tremaining: 6.39s\n",
      "823:\tlearn: 0.1908605\ttotal: 29.8s\tremaining: 6.36s\n",
      "824:\tlearn: 0.1908184\ttotal: 29.8s\tremaining: 6.32s\n",
      "825:\tlearn: 0.1907175\ttotal: 29.8s\tremaining: 6.28s\n",
      "826:\tlearn: 0.1905777\ttotal: 29.9s\tremaining: 6.25s\n",
      "827:\tlearn: 0.1904971\ttotal: 29.9s\tremaining: 6.21s\n",
      "828:\tlearn: 0.1904484\ttotal: 29.9s\tremaining: 6.17s\n",
      "829:\tlearn: 0.1902359\ttotal: 30s\tremaining: 6.14s\n",
      "830:\tlearn: 0.1901296\ttotal: 30s\tremaining: 6.1s\n",
      "831:\tlearn: 0.1900064\ttotal: 30.1s\tremaining: 6.07s\n",
      "832:\tlearn: 0.1898705\ttotal: 30.1s\tremaining: 6.03s\n",
      "833:\tlearn: 0.1897493\ttotal: 30.1s\tremaining: 6s\n",
      "834:\tlearn: 0.1896335\ttotal: 30.2s\tremaining: 5.96s\n",
      "835:\tlearn: 0.1894229\ttotal: 30.2s\tremaining: 5.92s\n",
      "836:\tlearn: 0.1892898\ttotal: 30.2s\tremaining: 5.89s\n",
      "837:\tlearn: 0.1891327\ttotal: 30.3s\tremaining: 5.85s\n",
      "838:\tlearn: 0.1890484\ttotal: 30.3s\tremaining: 5.82s\n",
      "839:\tlearn: 0.1889334\ttotal: 30.3s\tremaining: 5.78s\n",
      "840:\tlearn: 0.1888094\ttotal: 30.4s\tremaining: 5.74s\n",
      "841:\tlearn: 0.1887104\ttotal: 30.4s\tremaining: 5.71s\n",
      "842:\tlearn: 0.1885617\ttotal: 30.4s\tremaining: 5.67s\n",
      "843:\tlearn: 0.1884136\ttotal: 30.5s\tremaining: 5.64s\n",
      "844:\tlearn: 0.1882342\ttotal: 30.6s\tremaining: 5.6s\n",
      "845:\tlearn: 0.1881326\ttotal: 30.6s\tremaining: 5.57s\n",
      "846:\tlearn: 0.1879951\ttotal: 30.6s\tremaining: 5.53s\n",
      "847:\tlearn: 0.1877927\ttotal: 30.7s\tremaining: 5.49s\n",
      "848:\tlearn: 0.1877060\ttotal: 30.7s\tremaining: 5.46s\n",
      "849:\tlearn: 0.1876250\ttotal: 30.7s\tremaining: 5.42s\n",
      "850:\tlearn: 0.1875788\ttotal: 30.8s\tremaining: 5.39s\n",
      "851:\tlearn: 0.1875146\ttotal: 30.8s\tremaining: 5.35s\n",
      "852:\tlearn: 0.1873475\ttotal: 30.8s\tremaining: 5.31s\n",
      "853:\tlearn: 0.1872998\ttotal: 30.9s\tremaining: 5.28s\n",
      "854:\tlearn: 0.1871361\ttotal: 30.9s\tremaining: 5.24s\n",
      "855:\tlearn: 0.1870510\ttotal: 30.9s\tremaining: 5.21s\n",
      "856:\tlearn: 0.1869241\ttotal: 31s\tremaining: 5.17s\n",
      "857:\tlearn: 0.1868370\ttotal: 31s\tremaining: 5.14s\n",
      "858:\tlearn: 0.1866828\ttotal: 31.1s\tremaining: 5.1s\n",
      "859:\tlearn: 0.1866106\ttotal: 31.1s\tremaining: 5.06s\n",
      "860:\tlearn: 0.1864278\ttotal: 31.2s\tremaining: 5.03s\n",
      "861:\tlearn: 0.1863035\ttotal: 31.2s\tremaining: 4.99s\n",
      "862:\tlearn: 0.1861878\ttotal: 31.2s\tremaining: 4.96s\n",
      "863:\tlearn: 0.1860193\ttotal: 31.3s\tremaining: 4.92s\n",
      "864:\tlearn: 0.1859172\ttotal: 31.3s\tremaining: 4.88s\n",
      "865:\tlearn: 0.1857810\ttotal: 31.3s\tremaining: 4.85s\n",
      "866:\tlearn: 0.1856903\ttotal: 31.4s\tremaining: 4.81s\n",
      "867:\tlearn: 0.1855727\ttotal: 31.4s\tremaining: 4.78s\n",
      "868:\tlearn: 0.1854258\ttotal: 31.4s\tremaining: 4.74s\n",
      "869:\tlearn: 0.1852642\ttotal: 31.5s\tremaining: 4.71s\n",
      "870:\tlearn: 0.1850983\ttotal: 31.5s\tremaining: 4.67s\n",
      "871:\tlearn: 0.1850313\ttotal: 31.6s\tremaining: 4.63s\n",
      "872:\tlearn: 0.1849297\ttotal: 31.6s\tremaining: 4.6s\n",
      "873:\tlearn: 0.1848476\ttotal: 31.6s\tremaining: 4.56s\n",
      "874:\tlearn: 0.1846392\ttotal: 31.7s\tremaining: 4.52s\n",
      "875:\tlearn: 0.1845831\ttotal: 31.7s\tremaining: 4.49s\n",
      "876:\tlearn: 0.1844611\ttotal: 31.7s\tremaining: 4.45s\n",
      "877:\tlearn: 0.1843570\ttotal: 31.8s\tremaining: 4.41s\n",
      "878:\tlearn: 0.1842838\ttotal: 31.8s\tremaining: 4.38s\n",
      "879:\tlearn: 0.1841721\ttotal: 31.8s\tremaining: 4.34s\n",
      "880:\tlearn: 0.1841123\ttotal: 31.9s\tremaining: 4.31s\n",
      "881:\tlearn: 0.1840360\ttotal: 31.9s\tremaining: 4.27s\n",
      "882:\tlearn: 0.1839823\ttotal: 32s\tremaining: 4.24s\n",
      "883:\tlearn: 0.1837922\ttotal: 32s\tremaining: 4.2s\n",
      "884:\tlearn: 0.1836574\ttotal: 32.1s\tremaining: 4.17s\n",
      "885:\tlearn: 0.1835188\ttotal: 32.1s\tremaining: 4.13s\n",
      "886:\tlearn: 0.1834314\ttotal: 32.1s\tremaining: 4.09s\n",
      "887:\tlearn: 0.1832565\ttotal: 32.2s\tremaining: 4.06s\n",
      "888:\tlearn: 0.1831500\ttotal: 32.2s\tremaining: 4.02s\n",
      "889:\tlearn: 0.1829710\ttotal: 32.2s\tremaining: 3.98s\n",
      "890:\tlearn: 0.1828695\ttotal: 32.3s\tremaining: 3.95s\n",
      "891:\tlearn: 0.1827977\ttotal: 32.3s\tremaining: 3.91s\n",
      "892:\tlearn: 0.1826749\ttotal: 32.4s\tremaining: 3.88s\n",
      "893:\tlearn: 0.1825635\ttotal: 32.4s\tremaining: 3.84s\n",
      "894:\tlearn: 0.1824662\ttotal: 32.4s\tremaining: 3.8s\n",
      "895:\tlearn: 0.1822454\ttotal: 32.5s\tremaining: 3.77s\n",
      "896:\tlearn: 0.1820327\ttotal: 32.5s\tremaining: 3.73s\n",
      "897:\tlearn: 0.1819122\ttotal: 32.6s\tremaining: 3.7s\n",
      "898:\tlearn: 0.1817763\ttotal: 32.6s\tremaining: 3.66s\n",
      "899:\tlearn: 0.1815723\ttotal: 32.6s\tremaining: 3.63s\n",
      "900:\tlearn: 0.1814418\ttotal: 32.7s\tremaining: 3.59s\n",
      "901:\tlearn: 0.1813978\ttotal: 32.7s\tremaining: 3.55s\n",
      "902:\tlearn: 0.1811890\ttotal: 32.7s\tremaining: 3.52s\n",
      "903:\tlearn: 0.1811058\ttotal: 32.8s\tremaining: 3.48s\n",
      "904:\tlearn: 0.1809881\ttotal: 32.8s\tremaining: 3.44s\n",
      "905:\tlearn: 0.1809214\ttotal: 32.9s\tremaining: 3.41s\n",
      "906:\tlearn: 0.1808797\ttotal: 32.9s\tremaining: 3.37s\n",
      "907:\tlearn: 0.1808043\ttotal: 32.9s\tremaining: 3.34s\n",
      "908:\tlearn: 0.1806386\ttotal: 33s\tremaining: 3.3s\n",
      "909:\tlearn: 0.1805659\ttotal: 33s\tremaining: 3.27s\n",
      "910:\tlearn: 0.1804758\ttotal: 33.1s\tremaining: 3.23s\n",
      "911:\tlearn: 0.1803681\ttotal: 33.1s\tremaining: 3.19s\n",
      "912:\tlearn: 0.1802764\ttotal: 33.1s\tremaining: 3.15s\n",
      "913:\tlearn: 0.1801641\ttotal: 33.2s\tremaining: 3.12s\n",
      "914:\tlearn: 0.1800759\ttotal: 33.2s\tremaining: 3.08s\n",
      "915:\tlearn: 0.1799644\ttotal: 33.2s\tremaining: 3.05s\n",
      "916:\tlearn: 0.1798469\ttotal: 33.3s\tremaining: 3.01s\n",
      "917:\tlearn: 0.1798041\ttotal: 33.3s\tremaining: 2.98s\n",
      "918:\tlearn: 0.1796999\ttotal: 33.4s\tremaining: 2.94s\n",
      "919:\tlearn: 0.1796663\ttotal: 33.4s\tremaining: 2.9s\n",
      "920:\tlearn: 0.1795429\ttotal: 33.4s\tremaining: 2.87s\n",
      "921:\tlearn: 0.1794629\ttotal: 33.5s\tremaining: 2.83s\n",
      "922:\tlearn: 0.1793409\ttotal: 33.5s\tremaining: 2.79s\n",
      "923:\tlearn: 0.1791949\ttotal: 33.5s\tremaining: 2.76s\n",
      "924:\tlearn: 0.1790754\ttotal: 33.6s\tremaining: 2.72s\n",
      "925:\tlearn: 0.1790151\ttotal: 33.6s\tremaining: 2.69s\n",
      "926:\tlearn: 0.1788701\ttotal: 33.6s\tremaining: 2.65s\n",
      "927:\tlearn: 0.1787738\ttotal: 33.7s\tremaining: 2.61s\n",
      "928:\tlearn: 0.1786476\ttotal: 33.7s\tremaining: 2.58s\n",
      "929:\tlearn: 0.1785247\ttotal: 33.8s\tremaining: 2.54s\n",
      "930:\tlearn: 0.1784878\ttotal: 33.8s\tremaining: 2.5s\n",
      "931:\tlearn: 0.1783351\ttotal: 33.8s\tremaining: 2.47s\n",
      "932:\tlearn: 0.1782144\ttotal: 33.9s\tremaining: 2.43s\n",
      "933:\tlearn: 0.1781903\ttotal: 33.9s\tremaining: 2.4s\n",
      "934:\tlearn: 0.1780772\ttotal: 33.9s\tremaining: 2.36s\n",
      "935:\tlearn: 0.1780083\ttotal: 34s\tremaining: 2.32s\n",
      "936:\tlearn: 0.1778441\ttotal: 34s\tremaining: 2.29s\n",
      "937:\tlearn: 0.1777840\ttotal: 34s\tremaining: 2.25s\n",
      "938:\tlearn: 0.1776844\ttotal: 34.1s\tremaining: 2.21s\n",
      "939:\tlearn: 0.1775263\ttotal: 34.1s\tremaining: 2.18s\n",
      "940:\tlearn: 0.1774260\ttotal: 34.1s\tremaining: 2.14s\n",
      "941:\tlearn: 0.1772684\ttotal: 34.2s\tremaining: 2.1s\n",
      "942:\tlearn: 0.1771615\ttotal: 34.2s\tremaining: 2.07s\n",
      "943:\tlearn: 0.1771336\ttotal: 34.3s\tremaining: 2.03s\n",
      "944:\tlearn: 0.1770053\ttotal: 34.3s\tremaining: 2s\n",
      "945:\tlearn: 0.1769255\ttotal: 34.3s\tremaining: 1.96s\n",
      "946:\tlearn: 0.1768677\ttotal: 34.4s\tremaining: 1.92s\n",
      "947:\tlearn: 0.1768003\ttotal: 34.4s\tremaining: 1.89s\n",
      "948:\tlearn: 0.1766034\ttotal: 34.5s\tremaining: 1.85s\n",
      "949:\tlearn: 0.1764782\ttotal: 34.5s\tremaining: 1.81s\n",
      "950:\tlearn: 0.1763271\ttotal: 34.5s\tremaining: 1.78s\n",
      "951:\tlearn: 0.1761427\ttotal: 34.6s\tremaining: 1.74s\n",
      "952:\tlearn: 0.1760048\ttotal: 34.6s\tremaining: 1.71s\n",
      "953:\tlearn: 0.1758872\ttotal: 34.6s\tremaining: 1.67s\n",
      "954:\tlearn: 0.1757845\ttotal: 34.7s\tremaining: 1.63s\n",
      "955:\tlearn: 0.1756690\ttotal: 34.7s\tremaining: 1.6s\n",
      "956:\tlearn: 0.1755767\ttotal: 34.8s\tremaining: 1.56s\n",
      "957:\tlearn: 0.1754565\ttotal: 34.8s\tremaining: 1.52s\n",
      "958:\tlearn: 0.1753980\ttotal: 34.8s\tremaining: 1.49s\n",
      "959:\tlearn: 0.1752444\ttotal: 34.9s\tremaining: 1.45s\n",
      "960:\tlearn: 0.1751751\ttotal: 34.9s\tremaining: 1.42s\n",
      "961:\tlearn: 0.1751174\ttotal: 34.9s\tremaining: 1.38s\n",
      "962:\tlearn: 0.1750405\ttotal: 35s\tremaining: 1.34s\n",
      "963:\tlearn: 0.1749817\ttotal: 35s\tremaining: 1.31s\n",
      "964:\tlearn: 0.1749078\ttotal: 35s\tremaining: 1.27s\n",
      "965:\tlearn: 0.1748334\ttotal: 35.1s\tremaining: 1.23s\n",
      "966:\tlearn: 0.1747412\ttotal: 35.1s\tremaining: 1.2s\n",
      "967:\tlearn: 0.1746700\ttotal: 35.1s\tremaining: 1.16s\n",
      "968:\tlearn: 0.1745464\ttotal: 35.2s\tremaining: 1.12s\n",
      "969:\tlearn: 0.1744872\ttotal: 35.2s\tremaining: 1.09s\n",
      "970:\tlearn: 0.1744190\ttotal: 35.3s\tremaining: 1.05s\n",
      "971:\tlearn: 0.1743260\ttotal: 35.3s\tremaining: 1.02s\n",
      "972:\tlearn: 0.1742660\ttotal: 35.3s\tremaining: 980ms\n",
      "973:\tlearn: 0.1741054\ttotal: 35.4s\tremaining: 944ms\n",
      "974:\tlearn: 0.1740451\ttotal: 35.4s\tremaining: 907ms\n",
      "975:\tlearn: 0.1739789\ttotal: 35.4s\tremaining: 871ms\n",
      "976:\tlearn: 0.1739146\ttotal: 35.5s\tremaining: 835ms\n",
      "977:\tlearn: 0.1737299\ttotal: 35.5s\tremaining: 799ms\n",
      "978:\tlearn: 0.1736600\ttotal: 35.5s\tremaining: 762ms\n",
      "979:\tlearn: 0.1736183\ttotal: 35.6s\tremaining: 726ms\n",
      "980:\tlearn: 0.1735095\ttotal: 35.6s\tremaining: 690ms\n",
      "981:\tlearn: 0.1734298\ttotal: 35.6s\tremaining: 653ms\n",
      "982:\tlearn: 0.1732696\ttotal: 35.7s\tremaining: 617ms\n",
      "983:\tlearn: 0.1732370\ttotal: 35.7s\tremaining: 581ms\n",
      "984:\tlearn: 0.1731317\ttotal: 35.8s\tremaining: 545ms\n",
      "985:\tlearn: 0.1729726\ttotal: 35.8s\tremaining: 508ms\n",
      "986:\tlearn: 0.1728542\ttotal: 35.9s\tremaining: 472ms\n",
      "987:\tlearn: 0.1727434\ttotal: 35.9s\tremaining: 436ms\n",
      "988:\tlearn: 0.1726677\ttotal: 35.9s\tremaining: 400ms\n",
      "989:\tlearn: 0.1725682\ttotal: 36s\tremaining: 364ms\n",
      "990:\tlearn: 0.1725307\ttotal: 36s\tremaining: 327ms\n",
      "991:\tlearn: 0.1724808\ttotal: 36.1s\tremaining: 291ms\n",
      "992:\tlearn: 0.1724284\ttotal: 36.1s\tremaining: 254ms\n",
      "993:\tlearn: 0.1722663\ttotal: 36.1s\tremaining: 218ms\n",
      "994:\tlearn: 0.1721030\ttotal: 36.2s\tremaining: 182ms\n",
      "995:\tlearn: 0.1719329\ttotal: 36.2s\tremaining: 145ms\n",
      "996:\tlearn: 0.1718934\ttotal: 36.3s\tremaining: 109ms\n",
      "997:\tlearn: 0.1717328\ttotal: 36.3s\tremaining: 72.7ms\n",
      "998:\tlearn: 0.1716759\ttotal: 36.3s\tremaining: 36.4ms\n",
      "999:\tlearn: 0.1715804\ttotal: 36.4s\tremaining: 0us\n",
      "CatBoost with k-fold Cross-Validation Completed :)  \n",
      "******************************\n",
      "Epoch 1/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4357 - loss: 1.6561 - val_accuracy: 0.5644 - val_loss: 1.1730\n",
      "Epoch 2/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5814 - loss: 1.1224 - val_accuracy: 0.6001 - val_loss: 1.0634\n",
      "Epoch 3/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6157 - loss: 1.0473 - val_accuracy: 0.6260 - val_loss: 0.9911\n",
      "Epoch 4/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 0.9895 - val_accuracy: 0.6794 - val_loss: 0.9092\n",
      "Epoch 5/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6770 - loss: 0.8890 - val_accuracy: 0.6910 - val_loss: 0.8577\n",
      "Epoch 6/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7120 - loss: 0.8373 - val_accuracy: 0.7483 - val_loss: 0.7989\n",
      "Epoch 7/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.7856 - val_accuracy: 0.7375 - val_loss: 0.7657\n",
      "Epoch 8/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7480 - loss: 0.7570 - val_accuracy: 0.7565 - val_loss: 0.7449\n",
      "Epoch 9/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.7286 - val_accuracy: 0.7626 - val_loss: 0.7175\n",
      "Epoch 10/10\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7581 - loss: 0.7082 - val_accuracy: 0.7676 - val_loss: 0.7153\n",
      "\u001b[1m 37/148\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step   "
     ]
    }
   ],
   "source": [
    "n_splits_for_cv = 5 #Dont Change \n",
    "## **Importing Modules and Libraries**\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "start_time_1 = datetime.datetime.now()\n",
    "\n",
    "\n",
    "# Get the current time in the desired format\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(start_time_1)\n",
    "print(timestamp)\n",
    "# Generate the filename with the timestamp\n",
    "log_filename = f\"errors_{timestamp}.txt\"\n",
    "print(log_filename)\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename=log_filename, level=logging.ERROR, filemode='a')\n",
    "\n",
    "import os\n",
    "# Suppress TensorFlow GPU-related warnings\n",
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from os import path\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten , Activation, SimpleRNN, LSTM, GRU, Dropout, TimeDistributed, Reshape, Input, Lambda, Add\n",
    "from keras import Sequential\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "import sklearn.discriminant_analysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "import skfuzzy as fuzz\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, multilabel_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier, IsolationForest, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, PassiveAggressiveClassifier, RidgeClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier, BernoulliRBM\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import skfuzzy as fuzz\n",
    "from pgmpy.estimators import TreeSearch\n",
    "\n",
    "from hmmlearn import hmm\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Activation, SimpleRNN, LSTM, GRU, Dropout, TimeDistributed, Reshape, Input, Lambda, Add\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pgmpy.models import BayesianModel\n",
    "from pomegranate import *\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.models import JunctionTree\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from catboost import CatBoostClassifier\n",
    "import tensorflow as tf\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import ExpectationMaximization\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.datasets import make_classification\n",
    "from pgmpy.models import MarkovModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\"\"\"## **Importing Datasets**\"\"\"\n",
    "\n",
    "# dont change this\n",
    "method = \"UNSW_NB_15_TSA_Selected_SMOTE\"\n",
    "method = method + \"_k_fold_5_Metrics\"\n",
    "\n",
    "train_data = pd.read_csv('UNSW_NB_15_TSA_Selected_SMOTE.csv')\n",
    "test_data = pd.read_csv('UNSW_NB_15_TSA_test.csv')\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "# **MULTI-CLASS CLASSIFICATION**\n",
    "## **Data Splitting**\n",
    "X_train = train_data.drop(columns=['label'],axis=1)\n",
    "X_test = test_data.drop(columns=['label'],axis=1)\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "X_train = pd.concat([X_train, X_test], axis=0)\n",
    "y_train = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "fname = method + \"_output.csv\"\n",
    "outfile = open(fname, 'w')\n",
    "outfile.write(\"algo vs matrices,time to train(sec),time to predict(sec),accuracy_score,precision_score,recall_score,f1_score,fbeta_score,matthews_corrcoef,jaccard_score,cohen_kappa_score,hamming_loss,zero_one_loss,mean_absolute_error,mean_squared_error,mean_squared_error,balanced_accuracy_score,explained_variance_score\\n\")\n",
    "def format_decimal(number):\n",
    "    return f\"{number:.{3}f}\"\n",
    "def result(y_pred,y_test,algo,time_to_predict,time_to_train):\n",
    "    outfile.write(algo+\",\")\n",
    "    outfile.write(str(format_decimal(time_to_train))+\",\")\n",
    "    outfile.write(str(format_decimal(time_to_predict))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.accuracy_score(y_test,y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.precision_score(y_test, y_pred, average='weighted')))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.recall_score(y_test, y_pred, average='weighted')))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.f1_score(y_test, y_pred, average='weighted')))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.fbeta_score(y_test, y_pred,average='weighted', beta=0.5)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.matthews_corrcoef(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.jaccard_score(y_test, y_pred, average='weighted')))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.cohen_kappa_score(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.hamming_loss(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.zero_one_loss(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.mean_absolute_error(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.mean_squared_error(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.balanced_accuracy_score(y_test, y_pred)))+\",\")\n",
    "    outfile.write(str(format_decimal(metrics.explained_variance_score(y_test, y_pred)*100))+\"\\n\")\n",
    "\n",
    "#X_train,temp1,y_train,temp2 = train_test_split(X_train,y_train,train_size=0.1,random_state=7)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "# Initialize Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits= n_splits_for_cv, random_state=47, shuffle=True)\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "def separator(algo=\"temp\"):\n",
    "    with open(\"errors.txt\", \"a\") as file:\n",
    "        #file.write(datetime.now().strftime(\"%d %b %Y %H:%M\"))\n",
    "        file.write(\"\\n\\n*********\\n\\n\")\n",
    "    outfile.write(algo.strip()+ \" \" + \"erroralgo,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **1.Decision Tree**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test = []\n",
    "    all_y_pred = []\n",
    "    start_cv = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Decision Tree Classifier for this fold\n",
    "        dt_multi = DecisionTreeClassifier(random_state=24)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        dt_multi.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train - start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = dt_multi.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict +=  end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test.extend(y_test_fold)\n",
    "        all_y_pred.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = multilabel_confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix\")\n",
    "        i = str(fold_number)\n",
    "        pname = method + \"_fold_\"+ i + \"_Decision_Tree_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv = time.time()\n",
    "    result(all_y_pred, all_y_test, \"DT\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Decison Tree Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Decison Tree\")\n",
    "\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **2.Linear Regression**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lr = []\n",
    "    all_y_pred_lr = []\n",
    "    start_cv_lr = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Linear Regression model for this fold\n",
    "        lr_multi = LinearRegression()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        lr_multi.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train+=end_train - start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = lr_multi.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict +=  end_predict - start_predict\n",
    "        for i in range(len(y_pred_fold)):\n",
    "            y_pred_fold[i] = int(np.round_(y_pred_fold[i]))\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lr.extend(y_test_fold)\n",
    "        all_y_pred_lr.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Linear Regression\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_Linear_Regression_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lr = time.time()\n",
    "    result(all_y_pred_lr, all_y_test_lr, \"Linear Regression\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Linear Regression Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Linear Regression\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **3.Logistic Regression**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_logreg = []\n",
    "    all_y_pred_logreg = []\n",
    "    start_cv_logreg = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train  = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Logistic Regression model for this fold\n",
    "        logreg_multi =LogisticRegression(random_state=123, max_iter=5000,solver='newton-cg',multi_class='multinomial')\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        logreg_multi.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train - start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = logreg_multi.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict +=  end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_logreg.extend(y_test_fold)\n",
    "        all_y_pred_logreg.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Logistic Regression\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_Logistic_Regression_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_logreg = time.time()\n",
    "    result(all_y_pred_logreg, all_y_test_logreg, \"Logistic Regression\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"LogisticRegression Completed :) \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"LogisticRegression\")\n",
    "\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **4.K Nearest Neighbor Classifier**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_knn = []\n",
    "    all_y_pred_knn = []\n",
    "    start_cv_knn = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize KNN model for this fold\n",
    "        knn = KNeighborsClassifier(8)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        knn.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train - start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = knn.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_knn.extend(y_test_fold)\n",
    "        all_y_pred_knn.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - KNN\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_KNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_knn = time.time()\n",
    "    result(all_y_pred_knn, all_y_test_knn, \"KNN\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"KNN Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"KNN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **5.Random Forest Classifier**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_rf = []\n",
    "    all_y_pred_rf = []\n",
    "    start_cv_rf = time.time()\n",
    "    time_to_predict=0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Random Forest model for this fold\n",
    "        rf = RandomForestClassifier(random_state=24)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        rf.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = rf.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict += end_predict -start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_rf.extend(y_test_fold)\n",
    "        all_y_pred_rf.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Random Forest\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_Random_Forest_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_rf = time.time()\n",
    "    result(all_y_pred_rf, all_y_test_rf, \"Random Forest\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Random forest Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Random forest\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **6.Multi Layer Perceptron**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_mlp = []\n",
    "    all_y_pred_mlp = []\n",
    "    start_cv_mlp = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize MLP model for this fold\n",
    "        mlp = MLPClassifier(random_state=24)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fit the model\n",
    "        start_train = time.time()\n",
    "        mlp.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = mlp.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_mlp.extend(y_test_fold)\n",
    "        all_y_pred_mlp.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - MLP\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_MLP_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_mlp = time.time()\n",
    "    result(all_y_pred_mlp, all_y_test_mlp, \"MLP\", time_to_train, time_to_predict)\n",
    "\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"MLP Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"MLP\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **7.Bagging**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_bagging = []\n",
    "    all_y_pred_bagging = []\n",
    "    start_cv_bagging = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Create a base classifier (Decision Tree)\n",
    "        base_classifier = DecisionTreeClassifier(random_state=42)\n",
    "        # Create a bagging classifier\n",
    "        bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the bagging classifier\n",
    "        start_train = time.time()\n",
    "        bagging_classifier.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = bagging_classifier.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        time_to_predict += end_predict-start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_bagging.extend(y_test_fold)\n",
    "        all_y_pred_bagging.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize']=8,8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Bagging\")\n",
    "        pname = method + \"_fold_\"+ str(fold_number) + \"_Bagging_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_bagging = time.time()\n",
    "    result(all_y_pred_bagging, all_y_test_bagging, \"Bagging\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Bagging Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Bagging\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **8. J48 (C4.5)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_j48 = []\n",
    "    all_y_pred_j48 = []\n",
    "    start_cv_j48 = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize J48 (C4.5) classifier\n",
    "        classifier_j48 = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the J48 (C4.5) classifier\n",
    "        start_train = time.time()\n",
    "        classifier_j48.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = classifier_j48.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_j48.extend(y_test_fold)\n",
    "        all_y_pred_j48.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - J48 (C4.5)\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_J48_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_j48 = time.time()\n",
    "    result(all_y_pred_j48, all_y_test_j48, \"J48\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"J48 Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"J48\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **9. ANN**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ann = []\n",
    "    all_y_pred_ann = []\n",
    "    start_cv_ann = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize ANN model\n",
    "        multi_ann = Sequential()\n",
    "        # Adding the input layer and the first hidden layer\n",
    "        multi_ann.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "        # Adding the second hidden layer\n",
    "        multi_ann.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "        # Adding the output layer\n",
    "        multi_ann.add(Dense(units=10, kernel_initializer='uniform', activation='softmax'))\n",
    "        # Compiling the ANN\n",
    "        multi_ann.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fitting the ANN to the Training set\n",
    "        start_train = time.time()\n",
    "        history = multi_ann.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(multi_ann.predict(X_test_fold), axis=1)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ann.extend(y_test_fold)\n",
    "        all_y_pred_ann.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - ANN\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_ANN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ann = time.time()\n",
    "    result(all_y_pred_ann, all_y_test_ann, \"ANN\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"ANN Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"ANN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **10. DNN**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_dnn = []\n",
    "    all_y_pred_dnn = []\n",
    "    start_cv_dnn = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize DNN model\n",
    "        multi_dnn = Sequential()\n",
    "        # Adding the input layer and the first hidden layer\n",
    "        multi_dnn.add(Dense(units=19, kernel_initializer='uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "        # Adding the second hidden layer\n",
    "        multi_dnn.add(Dense(units=19, kernel_initializer='uniform', activation='relu'))\n",
    "        # Adding the third hidden layer\n",
    "        multi_dnn.add(Dense(units=19, kernel_initializer='uniform', activation='relu'))\n",
    "        # Adding the output layer\n",
    "        multi_dnn.add(Dense(units=10, kernel_initializer='uniform', activation='softmax'))\n",
    "        # Compiling the DNN\n",
    "        multi_dnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Fitting the DNN to the Training set\n",
    "        start_train = time.time()\n",
    "        history = multi_dnn.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(multi_dnn.predict(X_test_fold), axis=1)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_dnn.extend(y_test_fold)\n",
    "        all_y_pred_dnn.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DNN\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_dnn = time.time()\n",
    "    result(all_y_pred_dnn, all_y_test_dnn, \"DNN\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"DNN Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DNN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **12. Gradient Boosting Classifier with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gb = []\n",
    "    all_y_pred_gb = []\n",
    "    start_cv_gb = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Gradient Boosting Classifier\n",
    "        multi_gb = GradientBoostingClassifier()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        multi_gb.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = multi_gb.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gb.extend(y_test_fold)\n",
    "        all_y_pred_gb.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Gradient Boosting\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_GradientBoostingClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gb = time.time()\n",
    "    result(all_y_pred_gb, all_y_test_gb, \"Gradient Boosting\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GradientBoostingClassifier Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GradientBoostingClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## ** 13 XGBoost Classifier**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_xgb = []\n",
    "    all_y_pred_xgb = []\n",
    "    start_cv_xgb = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize XGBoost Classifier\n",
    "        xgb_model = XGBClassifier()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        xgb_model.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = xgb_model.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_xgb.extend(y_test_fold)\n",
    "        all_y_pred_xgb.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - XGBoost\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_XGBClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_xgb = time.time()\n",
    "    result(all_y_pred_xgb, all_y_test_xgb, \"XGBoost\", time_to_train, time_to_predict)\n",
    "\n",
    "    #plt.show()\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"XGBClassifier Completed :) \")\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"XGBClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **14. Gaussian Naive Bayes**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_nb = []\n",
    "    all_y_pred_nb = []\n",
    "    start_cv_nb = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Gaussian Naive Bayes model\n",
    "        NB_model = GaussianNB()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        NB_model.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = NB_model.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_nb.extend(y_test_fold)\n",
    "        all_y_pred_nb.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Gaussian Naive Bayes\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_Gaussian_Naive_Bayes_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_nb = time.time()\n",
    "    result(all_y_pred_nb, all_y_test_nb, \"Gaussian Naive Bayes\", time_to_train, time_to_predict)\n",
    "    #plt.show()\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Gaussian_Naive_Bayes Completed :) \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Gaussian_Naive_Bayes\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **15. Adaptive Gradient Boosting**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ab = []\n",
    "    all_y_pred_ab = []\n",
    "    start_cv_ab = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Adaptive Gradient Boosting model\n",
    "        weak_learner = DecisionTreeClassifier(max_leaf_nodes=8)\n",
    "        n_estimators = 300\n",
    "        AB_model = AdaBoostClassifier(\n",
    "            estimator=weak_learner,\n",
    "            n_estimators=n_estimators,\n",
    "            algorithm=\"SAMME\",\n",
    "            random_state=42,\n",
    "        )\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        AB_model.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = AB_model.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ab.extend(y_test_fold)\n",
    "        all_y_pred_ab.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Adaptive Gradient Boosting\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_Adaptive_Gradient_Boosting_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ab = time.time()\n",
    "    result(all_y_pred_ab, all_y_test_ab, \"Adaptive Gradient Boosting\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Adaptive Gradient Boosting Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Adaptive Gradient Boosting\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **16. Quadratic Discriminant Analysis (QDA)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_qda = []\n",
    "    all_y_pred_qda = []\n",
    "    start_cv_qda = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Initialize Quadratic Discriminant Analysis (QDA) model\n",
    "        qda_multi = QuadraticDiscriminantAnalysis()\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        qda_multi.fit(X_train_fold, y_train_fold)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = qda_multi.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_qda.extend(y_test_fold)\n",
    "        all_y_pred_qda.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Quadratic Discriminant Analysis (QDA)\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_QDA_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_qda = time.time()\n",
    "    result(all_y_pred_qda, all_y_test_qda, \"QDA\", time_to_train, time_to_predict)\n",
    "    #plt.show()\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"QDA Completed :) \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"QDA\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **17. Shallow Neural Network (SNN)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_snn = []\n",
    "    all_y_pred_snn = []\n",
    "    start_cv_snn = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        num_classes =  len(np.unique(y_train))\n",
    "        # Initialize Shallow Neural Network (SNN) model\n",
    "        snn_multi = Sequential()\n",
    "        snn_multi.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "        snn_multi.add(Dense(32, activation='relu'))\n",
    "        snn_multi.add(Dense(20, activation='relu'))\n",
    "        snn_multi.add(Dense(num_classes, activation='softmax'))\n",
    "        snn_multi.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        history = snn_multi.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(snn_multi.predict(X_test_fold), axis=1)\n",
    "        end_predict = time.time()\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "        # Append metrics to lists\n",
    "        all_y_test_snn.extend(y_test_fold)\n",
    "        all_y_pred_snn.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Shallow Neural Network (SNN)\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_SNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_snn = time.time()\n",
    "    result(all_y_pred_snn, all_y_test_snn, \"SNN\", time_to_train, time_to_predict)\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"SNN Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"snn\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **18. Restricted Boltzmann Machine (RBM)**\n",
    "    # Define the RBM class\n",
    "    class RBM(tf.keras.layers.Layer):\n",
    "        def __init__(self, hidden_dim, name=\"rbm\", **kwargs):\n",
    "            super(RBM, self).__init__(name=name, **kwargs)\n",
    "            self.hidden_dim = hidden_dim\n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(shape=(input_shape[-1], self.hidden_dim), initializer='uniform', trainable=True, name='weights')\n",
    "            self.h_bias = self.add_weight(shape=(self.hidden_dim,), initializer='zeros', trainable=True, name='h_bias')\n",
    "            self.v_bias = self.add_weight(shape=(input_shape[-1],), initializer='zeros', trainable=True, name='v_bias')\n",
    "        def call(self, inputs):\n",
    "            hidden_prob = tf.nn.sigmoid(tf.matmul(inputs, self.W) + self.h_bias)\n",
    "            hidden_state = self._sample_prob(hidden_prob)\n",
    "            visible_prob = tf.nn.sigmoid(tf.matmul(hidden_state, tf.transpose(self.W)) + self.v_bias)\n",
    "            return visible_prob, hidden_state\n",
    "        def _sample_prob(self, probs):\n",
    "            return tf.nn.relu(tf.sign(probs - tf.random.uniform(tf.shape(probs))))\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_rbm = []\n",
    "    all_y_pred_rbm = []\n",
    "    start_cv_rbm = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        num_classes = len(np.unique(y_train))\n",
    "        input_data = Input(shape=(X_train.shape[1],))\n",
    "        rbm1_visible, rbm1_hidden = RBM(hidden_dim=128, name=f\"rbm1_fold_{fold_number}\")(input_data)\n",
    "        rbm2_visible, rbm2_hidden = RBM(hidden_dim=64, name=f\"rbm2_fold_{fold_number}\")(rbm1_hidden)\n",
    "        rbm3_visible, rbm3_hidden = RBM(hidden_dim=32, name=f\"rbm3_fold_{fold_number}\")(rbm2_hidden)\n",
    "        rbm6_visible, rbm6_hidden = RBM(hidden_dim=64, name=f\"rbm6_fold_{fold_number}\")(rbm3_hidden)\n",
    "        classifier_output = Dense(num_classes, activation='softmax', name=f'classifier_fold_{fold_number}')(rbm6_hidden)\n",
    "        model = tf.keras.Model(inputs=input_data, outputs=classifier_output)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(model.predict(X_test_fold), axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_rbm.extend(y_test_fold)\n",
    "        all_y_pred_rbm.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Restricted Boltzmann Machine (RBM)\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_RBM_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_rbm = time.time()\n",
    "    result(all_y_pred_rbm, all_y_test_rbm, \"RBM\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"RBM Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"RBM\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **19. LSTM**\n",
    "\n",
    "    # reloading as many transformations on X,Y causing errors for lstm code\n",
    "\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lstm = []\n",
    "    all_y_pred_lstm = []\n",
    "    start_cv_lstm = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        num_classes = len(np.unique(y_train))\n",
    "\n",
    "        # Convert DataFrame to NumPy array and reshape input data for LSTM\n",
    "        X_train_array_multi = X_train.iloc[train_index].to_numpy()\n",
    "        X_test_array_multi = X_train.iloc[test_index].to_numpy()\n",
    "        X_train_reshaped_multi = X_train_array_multi.reshape((X_train_array_multi.shape[0], X_train_array_multi.shape[1], 1))\n",
    "        X_test_reshaped_multi = X_test_array_multi.reshape((X_test_array_multi.shape[0], X_test_array_multi.shape[1], 1))\n",
    "\n",
    "        # Define the LSTM model\n",
    "        rnn_multi = Sequential()\n",
    "        rnn_multi.add(LSTM(128, input_shape=(X_train_reshaped_multi.shape[1], X_train_reshaped_multi.shape[2])))\n",
    "        rnn_multi.add(Dense(32, activation='relu'))\n",
    "        rnn_multi.add(Dense(num_classes, activation='softmax'))\n",
    "        rnn_multi.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the LSTM model\n",
    "        start_train = time.time()\n",
    "        rnn_multi.fit(X_train_reshaped_multi, y_train.iloc[train_index], validation_data=(X_test_reshaped_multi, y_train.iloc[test_index]), epochs=10, batch_size=50, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(rnn_multi.predict(X_test_reshaped_multi), axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lstm.extend(y_train.iloc[test_index])\n",
    "        all_y_pred_lstm.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_train.iloc[test_index], y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - LSTM\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_LSTM_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lstm = time.time()\n",
    "    result(all_y_pred_lstm, all_y_test_lstm, \"LSTM\",time_to_train , time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"lstm Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"lstm\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **20. Reconstruction Neural Networks**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_recon = []\n",
    "    all_y_pred_recon = []\n",
    "    start_cv_recon = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        num_classes = len(np.unique(y_train))\n",
    "\n",
    "        # Assuming y_train_multi is one-hot encoded\n",
    "        y_train_multi_onehot = tf.keras.utils.to_categorical(y_train.iloc[train_index], num_classes=num_classes)\n",
    "        y_test_multi_onehot = tf.keras.utils.to_categorical(y_train.iloc[test_index], num_classes=num_classes)\n",
    "\n",
    "        # Define model architecture\n",
    "        input_dim = X_train.shape[1]\n",
    "        encoding_dim = 32  # Choose appropriate dimensionality\n",
    "        latent_dim = 2  # Dimensionality of the latent space\n",
    "\n",
    "        # Encoder\n",
    "        input_layer = tf.keras.layers.Input(shape=(input_dim,))\n",
    "        hidden = tf.keras.layers.Dense(64, activation='relu')(input_layer)\n",
    "        z_mean = tf.keras.layers.Dense(latent_dim)(hidden)\n",
    "        z_log_var = tf.keras.layers.Dense(latent_dim)(hidden)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        def sampling(args):\n",
    "            z_mean, z_log_var = args\n",
    "            epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
    "            return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "        z = tf.keras.layers.Lambda(sampling,output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "        # Decoder\n",
    "        decoder_hidden = tf.keras.layers.Dense(64, activation='relu')(z)\n",
    "        output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')(decoder_hidden)\n",
    "\n",
    "        # Define VAE model\n",
    "        vae = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile model\n",
    "        vae.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the VAE model\n",
    "        start_train = time.time()\n",
    "        vae.fit(X_train.iloc[train_index], y_train_multi_onehot, epochs=10, batch_size=50, shuffle=True, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = np.argmax(vae.predict(X_train.iloc[test_index]), axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_recon.extend(y_train.iloc[test_index])\n",
    "        all_y_pred_recon.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_train.iloc[test_index], y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Reconstruction Neural Network\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_reconstruction_NN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_recon = time.time()\n",
    "    result(all_y_pred_recon, all_y_test_recon, \"reconstruction_NN\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"reconstruction neural networks, Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"reconstruction neural networks\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **22. DANN with k-fold Cross-Validation**\n",
    "\n",
    "    def build_dann_model(input_shape, num_classes, lambda_val=1e-3):\n",
    "        input_layer = Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "        # Feature extractor\n",
    "        shared_layer = Dense(128, activation='relu')(input_layer)\n",
    "        shared_layer = Dropout(0.5)(shared_layer)\n",
    "\n",
    "        # Source classifier\n",
    "        source_classifier = Dense(num_classes, activation='softmax', name='source_classifier')(shared_layer)\n",
    "\n",
    "        # Domain classifier\n",
    "        domain_classifier = Dense(1, activation='sigmoid', name='domain_classifier')(shared_layer)\n",
    "\n",
    "        # Combined model\n",
    "        model = Model(inputs=input_layer, outputs=[source_classifier, domain_classifier])\n",
    "\n",
    "        # Domain adversarial loss\n",
    "        def domain_adversarial_loss(y_true, y_pred):\n",
    "            return K.mean(K.binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                    loss={'source_classifier': 'categorical_crossentropy', 'domain_classifier': domain_adversarial_loss},\n",
    "                    loss_weights={'source_classifier': 1.0, 'domain_classifier': lambda_val},\n",
    "                    metrics={'source_classifier': 'accuracy'})\n",
    "\n",
    "        return model\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_dann = []\n",
    "    all_y_pred_dann = []\n",
    "    start_cv_dann = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Convert class vectors to binary class matrices\n",
    "        num_classes = len(np.unique(y_train))\n",
    "        y_train_categorical = tf.keras.utils.to_categorical(y_train.iloc[train_index], num_classes)\n",
    "        y_test_categorical = tf.keras.utils.to_categorical(y_train.iloc[test_index], num_classes)\n",
    "\n",
    "        # Build and train DANN model for each fold\n",
    "        input_shape = (X_train.shape[1],)\n",
    "        lambda_val = 1e-3  # Trade-off parameter for domain adversarial loss\n",
    "        dann_model = build_dann_model(input_shape, num_classes, lambda_val)\n",
    "\n",
    "        # Training phase\n",
    "        start_train = time.time()\n",
    "        dann_model.fit(X_train.iloc[train_index],\n",
    "                    {'source_classifier': y_train_categorical, 'domain_classifier': np.zeros((len(train_index), 1))},\n",
    "                    epochs=10, batch_size=64,\n",
    "                    validation_data=(X_train.iloc[test_index],\n",
    "                                        {'source_classifier': y_test_categorical,\n",
    "                                        'domain_classifier': np.ones((len(test_index), 1))}))\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Prediction phase\n",
    "        X_test_fold = X_train.iloc[test_index]  # Use iloc to access test fold\n",
    "        start_predict = time.time()\n",
    "        predictions = dann_model.predict(X_test_fold)\n",
    "        source_classifier_predictions = predictions[0]\n",
    "        y_pred_fold = np.argmax(source_classifier_predictions, axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        y_test = y_train.iloc[test_index]\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_dann.extend(y_test)\n",
    "        all_y_pred_dann.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DANN\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DANN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_dann = time.time()\n",
    "    result(all_y_pred_dann, all_y_test_dann, \"DANN\", time_to_train, time_to_predict)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"DANN Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DANN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **23.Deep brief networks (DBNs)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_dbn = []\n",
    "    all_y_pred_dbn = []\n",
    "    start_cv_dbn = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Number of classes\n",
    "        num_classes = len(np.unique(y_train))\n",
    "\n",
    "        # Create a pipeline with BernoulliRBM and MLPClassifier\n",
    "        rbm = BernoulliRBM(n_components=64, learning_rate=0.01, n_iter=20, random_state=42, verbose=True)\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(128,), max_iter=10, random_state=52)\n",
    "        dbn_model = Pipeline(steps=[('rbm', rbm), ('mlp', mlp)])\n",
    "\n",
    "        # Training phase\n",
    "        start_train = time.time()\n",
    "        dbn_model.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Prediction phase\n",
    "        X_test_fold = X_train.iloc[test_index]\n",
    "        y_test_fold = y_train.iloc[test_index]\n",
    "        start_predict = time.time()\n",
    "        y_pred_fold = dbn_model.predict(X_test_fold)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_dbn.extend(y_test_fold)\n",
    "        all_y_pred_dbn.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DBN\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DBN_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_dbn = time.time()\n",
    "    result(all_y_pred_dbn, all_y_test_dbn, \"DBN\", time_to_train, time_to_predict)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DBNs\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **24. Deep Boltzmann Machines (DBMs)** with k-fold Cross-Validation\n",
    "    # Build a simple Restricted Boltzmann Machine (RBM) using TensorFlow\n",
    "    class RBM(tf.Module):\n",
    "        def __init__(self, visible_dim, hidden_dim, learning_rate=0.01):\n",
    "            self.visible_dim = visible_dim\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.learning_rate = learning_rate\n",
    "\n",
    "            # Initialize weights and biases\n",
    "            self.W = tf.Variable(tf.random.normal([visible_dim, hidden_dim], stddev=0.01, dtype=tf.float32))\n",
    "            self.b_visible = tf.Variable(tf.zeros([visible_dim], dtype=tf.float32))\n",
    "            self.b_hidden = tf.Variable(tf.zeros([hidden_dim], dtype=tf.float32))\n",
    "\n",
    "        def _softmax(self, x):\n",
    "            exp_x = tf.exp(x)\n",
    "            return exp_x / tf.reduce_sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "        def sample_hidden(self, visible_prob):\n",
    "            hidden_prob = self._softmax(tf.matmul(visible_prob, self.W) + self.b_hidden)\n",
    "            return tf.nn.relu(tf.sign(hidden_prob - tf.random.uniform(tf.shape(hidden_prob))))\n",
    "\n",
    "        def sample_visible(self, hidden_prob):\n",
    "            visible_prob = self._softmax(tf.matmul(hidden_prob, tf.transpose(self.W)) + self.b_visible)\n",
    "            return tf.nn.relu(tf.sign(visible_prob - tf.random.uniform(tf.shape(visible_prob))))\n",
    "\n",
    "        def contrastive_divergence(self, x, k=1):\n",
    "            visible = x\n",
    "            for _ in range(k):\n",
    "                hidden = self.sample_hidden(visible)\n",
    "                visible = self.sample_visible(hidden)\n",
    "\n",
    "            positive_hidden = self._softmax(tf.matmul(x, self.W) + self.b_hidden)\n",
    "            negative_hidden = self._softmax(tf.matmul(visible, self.W) + self.b_hidden)\n",
    "\n",
    "            # Update weights and biases\n",
    "            self.W.assign_add(self.learning_rate * (tf.matmul(tf.transpose(x), positive_hidden) -\n",
    "                                                    tf.matmul(tf.transpose(visible), negative_hidden)))\n",
    "            self.b_visible.assign_add(self.learning_rate * tf.reduce_mean(x - visible, axis=0))\n",
    "            self.b_hidden.assign_add(self.learning_rate * tf.reduce_mean(positive_hidden - negative_hidden, axis=0))\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_dbm = []\n",
    "    all_y_pred_dbm = []\n",
    "    start_cv_dbm = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index].values, X_train.iloc[test_index].values\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index].values, y_train.iloc[test_index].values\n",
    "\n",
    "        # Number of visible and hidden units\n",
    "        visible_dim = X_train_fold.shape[1]\n",
    "        hidden_dim1 = 64\n",
    "        hidden_dim2 = 32\n",
    "\n",
    "        # Create RBMs for each layer\n",
    "        rbm1 = RBM(visible_dim, hidden_dim1)\n",
    "        rbm2 = RBM(hidden_dim1, hidden_dim2)\n",
    "\n",
    "        # Training RBMs\n",
    "        num_epochs = 5\n",
    "        batch_size = 32\n",
    "        start = time.time()\n",
    "        # Training first RBM\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(0, len(X_train_fold), batch_size):\n",
    "                batch_data = X_train_fold[i:i+batch_size]\n",
    "                rbm1.contrastive_divergence(tf.cast(batch_data, dtype=tf.float32))\n",
    "\n",
    "        # Getting hidden layer representation from the first RBM\n",
    "        hidden1_representation = tf.nn.relu(tf.sign(rbm1.sample_hidden(tf.cast(X_train_fold, dtype=tf.float32))))\n",
    "\n",
    "        # Training second RBM using the hidden layer representation from the first RBM\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(0, len(hidden1_representation), batch_size):\n",
    "                batch_data = hidden1_representation[i:i+batch_size]\n",
    "                rbm2.contrastive_divergence(batch_data)\n",
    "\n",
    "        # Getting hidden layer representation from the second RBM\n",
    "        hidden2_representation = tf.nn.relu(tf.sign(rbm2.sample_hidden(hidden1_representation)))\n",
    "\n",
    "        # Fine-tuning for classification\n",
    "        num_classes = len(np.unique(y_train_fold))\n",
    "        dbm_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(hidden_dim1, activation='relu'),\n",
    "            tf.keras.layers.Dense(hidden_dim2, activation='relu'),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        dbm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        start_train = time.time()\n",
    "        dbm_model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, shuffle=True, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "\n",
    "        # Predict on the test set\n",
    "        start_predict = time.time()\n",
    "        y_pred_probabilities = dbm_model.predict(X_test_fold)\n",
    "        y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_dbm.extend(y_test_fold)\n",
    "        all_y_pred_dbm.extend(y_pred)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DBM\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DBM_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_dbm = time.time()\n",
    "    result(all_y_pred_dbm, all_y_test_dbm, \"DBM\", time_to_train, time_to_predict)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DBMs\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **25.DEEP AUTO ENCODERS(DA)**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_da = []\n",
    "    all_y_pred_da = []\n",
    "    start_cv_da = time.time()\n",
    "    time_to_predict = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Define the autoencoder model\n",
    "        autoencoder = Sequential()\n",
    "\n",
    "        # Encoder\n",
    "        autoencoder.add(Dense(128, activation='relu', input_shape=(X_train_fold.shape[1],)))\n",
    "        autoencoder.add(Dense(64, activation='relu'))\n",
    "        autoencoder.add(Dense(32, activation='relu'))\n",
    "\n",
    "        # Decoder\n",
    "        autoencoder.add(Dense(64, activation='relu'))\n",
    "        autoencoder.add(Dense(128, activation='relu'))\n",
    "        autoencoder.add(Dense(X_train_fold.shape[1], activation='linear'))\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Train the autoencoder\n",
    "        autoencoder.fit(X_train_fold, X_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "\n",
    "        # Add a classification head on top of the trained autoencoder\n",
    "        da_model = Sequential()\n",
    "        da_model.add(autoencoder.layers[0])  # Add encoder layers\n",
    "        da_model.add(autoencoder.layers[1])\n",
    "        da_model.add(autoencoder.layers[2])\n",
    "        da_model.add(Dense(num_classes, activation='softmax'))  # Adjust output layer for multiple classes\n",
    "\n",
    "        # Compile the classification model\n",
    "        da_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Convert labels to one-hot encoding\n",
    "        y_train_fold_onehot = to_categorical(y_train_fold, num_classes=num_classes)\n",
    "        y_test_fold_onehot = to_categorical(y_test_fold, num_classes=num_classes)\n",
    "\n",
    "        # Train the classification model using the encoded representations\n",
    "        start_train = time.time()\n",
    "        history = da_model.fit(X_train_fold, y_train_fold_onehot, epochs=10, batch_size=32, shuffle=True, verbose=0)\n",
    "        end_train = time.time()\n",
    "        time_to_train += end_train -start_train\n",
    "        # Predict on the test set\n",
    "        start_predict = time.time()\n",
    "        y_pred_probabilities = da_model.predict(X_test_fold)\n",
    "        y_pred_fold = np.argmax(y_pred_probabilities, axis=1)\n",
    "        end_predict = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict += end_predict - start_predict\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_da.extend(y_test_fold)\n",
    "        all_y_pred_da.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - DA\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_DA_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_da = time.time()\n",
    "    result(all_y_pred_da, all_y_test_da, \"DA\", time_to_train, time_to_predict)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"DEEP AUTO ENCODERS\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **26. PassiveAggressiveClassifier with k-fold Cross-Validation**\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_passive = []\n",
    "    all_y_pred_passive = []\n",
    "\n",
    "    start_cv_passive = time.time()\n",
    "    time_to_predict_passive = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_passive, X_test_fold_passive = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_passive, y_test_fold_passive = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Initialize PassiveAggressiveClassifier for each fold\n",
    "        model_passive = PassiveAggressiveClassifier(max_iter=1000, random_state=0, tol=1e-3)\n",
    "\n",
    "        # Train the model\n",
    "        start_train_passive = time.time()\n",
    "        model_passive.fit(X_train_fold_passive, y_train_fold_passive)\n",
    "        end_train_passive = time.time()\n",
    "        time_to_train += end_train_passive -start_train_passive\n",
    "        # Predict on the test set\n",
    "        start_predict_passive = time.time()\n",
    "        y_pred_passive = model_passive.predict(X_test_fold_passive)\n",
    "        end_predict_passive = time.time()\n",
    "        time_to_predict_passive += end_predict_passive - start_predict_passive\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_passive.extend(y_test_fold_passive)\n",
    "        all_y_pred_passive.extend(y_pred_passive)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm_passive = confusion_matrix(y_test_fold_passive, y_pred_passive)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_passive = ConfusionMatrixDisplay(confusion_matrix=cm_passive)\n",
    "        disp_passive.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - PassiveAggressiveClassifier\")\n",
    "        pname_passive = method + \"_fold_\" + str(fold_number) + \"_PassiveAggressiveClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_passive)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_passive = time.time()\n",
    "    result(all_y_pred_passive, all_y_test_passive, \"PassiveAggressiveClassifier\", time_to_train, time_to_predict_passive)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"PassiveAggressiveClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **27. RidgeClassifier with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ridge = []\n",
    "    all_y_pred_ridge = []\n",
    "    start_cv_ridge = time.time()\n",
    "    time_to_predict_ridge = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train.values, y_train.values), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_ridge, X_test_fold_ridge = X_train.values[train_index], X_train.values[test_index]\n",
    "        y_train_fold_ridge, y_test_fold_ridge = y_train.values[train_index], y_train.values[test_index]\n",
    "\n",
    "        # Initialize RidgeClassifier for each fold\n",
    "        model_ridge = RidgeClassifier()\n",
    "\n",
    "        # Train the model\n",
    "        start_train_ridge = time.time()\n",
    "        model_ridge.fit(X_train_fold_ridge, y_train_fold_ridge)\n",
    "        end_train_ridge = time.time()\n",
    "        time_to_train += end_train_ridge -start_train_ridge\n",
    "        # Predict    on the test set\n",
    "        start_predict_ridge = time.time()\n",
    "        y_pred_ridge = model_ridge.predict(X_test_fold_ridge)\n",
    "        end_predict_ridge = time.time()\n",
    "\n",
    "        time_to_predict_ridge += end_predict_ridge - start_predict_ridge\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ridge.extend(y_test_fold_ridge)\n",
    "        all_y_pred_ridge.extend(y_pred_ridge)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm_ridge = confusion_matrix(y_test_fold_ridge, y_pred_ridge)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_ridge = ConfusionMatrixDisplay(confusion_matrix=cm_ridge)\n",
    "        disp_ridge.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - RidgeClassifier\")\n",
    "        pname_ridge = method +\"_fold_\"+ str(fold_number) + \"_RidgeClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_ridge)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ridge = time.time()\n",
    "    result(all_y_pred_ridge, all_y_test_ridge, \"RidgeClassifier\", time_to_train, time_to_predict_ridge)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"RidgeClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **28. NearestCentroid with k-fold Cross-Validation, Time to Predict, and Confusion Matrix**\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_nc = []\n",
    "    all_y_pred_nc = []\n",
    "    start_cv_nc = time.time()\n",
    "    total_time_to_predict_nc = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_nc, X_test_fold_nc = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_nc, y_test_fold_nc = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Initialize NearestCentroid model for each fold\n",
    "        model_nc = NearestCentroid()\n",
    "\n",
    "        # Start time for training\n",
    "        start_train_nc = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model_nc.fit(X_train_fold_nc, y_train_fold_nc)\n",
    "\n",
    "        # End time for training\n",
    "        end_train_nc = time.time()\n",
    "        time_to_train += end_train_nc - start_train_nc\n",
    "        # Start time for prediction\n",
    "        start_predict_nc = time.time()\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_fold_nc = model_nc.predict(X_test_fold_nc)\n",
    "\n",
    "        # End time for prediction\n",
    "        end_predict_nc = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction\n",
    "        time_to_predict_nc = end_predict_nc - start_predict_nc\n",
    "        total_time_to_predict_nc += time_to_predict_nc\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_nc.extend(y_test_fold_nc)\n",
    "        all_y_pred_nc.extend(y_pred_fold_nc)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm_nc = confusion_matrix(y_test_fold_nc, y_pred_fold_nc)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_nc = ConfusionMatrixDisplay(confusion_matrix=cm_nc)\n",
    "        disp_nc.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - NearestCentroid\")\n",
    "        pname_nc = method+\"_fold_\" + str(fold_number) + \"_NearestCentroid_confusion_matrix.png\"\n",
    "        plt.savefig(pname_nc)\n",
    "        #plt.show()\n",
    "\n",
    "    # End time for k-fold cross-validation\n",
    "    end_cv_nc = time.time()\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_nc, all_y_test_nc, \"NearestCentroid\", time_to_train, total_time_to_predict_nc)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"NearestCentroid\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **29. Cost Sensitive Logistic Regression (CSLR) with k-fold Cross-Validation and Time to Predict**\n",
    "\n",
    "    def get_sample_weight(cost_matrix, y_tru):\n",
    "        y_true = np.array(y_tru)\n",
    "        num_samples = len(y_true)\n",
    "        sample_weights = np.zeros(num_samples)\n",
    "        for i in range(num_samples):\n",
    "            true_class = y_true[i]\n",
    "            for j in range(len(cost_matrix)):\n",
    "                if j != true_class:\n",
    "                    sample_weights[i] += cost_matrix[true_class, j]\n",
    "        return sample_weights\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_cslr = []\n",
    "    all_y_pred_cslr = []\n",
    "    # Define cost matrix for CSLR\n",
    "    cost_matrix = np.array([[0, 1, 2, 3, 4, 5, 6, 7, 8],    # Costs for misclassifying class 0\n",
    "                            [1, 0, 1, 2, 3, 4, 5, 6, 7],    # Costs for misclassifying class 1\n",
    "                            [2, 1, 0, 1, 2, 3, 4, 5, 6],    # Costs for misclassifying class 2\n",
    "                            [3, 2, 1, 0, 1, 2, 3, 4, 5],    # Costs for misclassifying class 3\n",
    "                            [4, 3, 2, 1, 0, 1, 2, 3, 4],    # Costs for misclassifying class 4\n",
    "                            [5, 4, 3, 2, 1, 0, 1, 2, 3],    # Costs for misclassifying class 5\n",
    "                            [6, 5, 4, 3, 2, 1, 0, 1, 2],    # Costs for misclassifying class 6\n",
    "                            [7, 6, 5, 4, 3, 2, 1, 0, 1],    # Costs for misclassifying class 7\n",
    "                            [8, 7, 6, 5, 4, 3, 2, 1, 0]])   # Costs for misclassifying class 8\n",
    "\n",
    "    start_cv_cslr = time.time()\n",
    "    total_time_to_predict_fold_cslr = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_cslr, X_test_fold_cslr = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_cslr, y_test_fold_cslr = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Get sample weights for cost-sensitive learning\n",
    "        sample_weights_fold_cslr = get_sample_weight(cost_matrix, y_train_fold_cslr)\n",
    "\n",
    "        # Initialize Logistic Regression model for each fold\n",
    "        model_cslr = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "        # Start time for training\n",
    "        start_train_fold_cslr = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model_cslr.fit(X_train_fold_cslr, y_train_fold_cslr, sample_weight=sample_weights_fold_cslr)\n",
    "\n",
    "        # End time for training\n",
    "        end_train_fold_cslr = time.time()\n",
    "\n",
    "        time_to_train +=  end_train_fold_cslr - start_train_fold_cslr\n",
    "        # Start time for prediction\n",
    "        start_predict_fold_cslr = time.time()\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_fold_cslr = model_cslr.predict(X_test_fold_cslr)\n",
    "\n",
    "        # End time for prediction\n",
    "        end_predict_fold_cslr = time.time()\n",
    "\n",
    "        # Calculate time taken for prediction in this fold\n",
    "        time_to_predict_fold_cslr = end_predict_fold_cslr - start_predict_fold_cslr\n",
    "        total_time_to_predict_fold_cslr += time_to_predict_fold_cslr\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_cslr.extend(y_test_fold_cslr)\n",
    "        all_y_pred_cslr.extend(y_pred_fold_cslr)\n",
    "\n",
    "        # Generate confusion matrix and display\n",
    "        cm_cslr = confusion_matrix(y_test_fold_cslr, y_pred_fold_cslr)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_cslr = ConfusionMatrixDisplay(confusion_matrix=cm_cslr)\n",
    "        disp_cslr.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - CSLR\")\n",
    "        pname_cslr = method +\"_fold_\" + str(fold_number) + \"_CSLR__confusion_matrix.png\"\n",
    "        plt.savefig(pname_cslr)\n",
    "        #plt.show()\n",
    "\n",
    "    # End time for k-fold cross-validation\n",
    "    end_cv_cslr = time.time()\n",
    "    result(all_y_pred_cslr, all_y_test_cslr, \"CSLR\", time_to_train, total_time_to_predict_fold_cslr)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"CSLR\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **30. Cost-sensitive Bagging Classifier (CSBC) with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_csbc = []\n",
    "    all_y_pred_csbc = []\n",
    "    start_cv_csbc = time.time()\n",
    "    time_to_predict_fold_csbc = 0\n",
    "    time_to_train = 0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_csbc, X_test_fold_csbc = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_csbc, y_test_fold_csbc = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Step 1: Compute class weights for the fold\n",
    "        class_weights_fold = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_fold_csbc), y=y_train_fold_csbc)\n",
    "\n",
    "        # Step 2: Initialize the base estimator and BaggingClassifier for the fold\n",
    "        base_estimator = DecisionTreeClassifier(max_depth=5)\n",
    "        bagging_model = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "        # Step 3: Train the model on the fold\n",
    "        start_train_fold_csbc = time.time()\n",
    "        bagging_model.fit(X_train_fold_csbc, y_train_fold_csbc)\n",
    "        end_train_fold_csbc = time.time()\n",
    "        time_to_train += end_train_fold_csbc - start_train_fold_csbc\n",
    "        # Step 4: Predict on the test set for the fold\n",
    "        start_predict_fold_csbc = time.time()\n",
    "        y_pred_fold_csbc = bagging_model.predict(X_test_fold_csbc)\n",
    "        end_predict_fold_csbc = time.time()\n",
    "\n",
    "        time_to_predict_fold_csbc += end_predict_fold_csbc - start_predict_fold_csbc\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_csbc.extend(y_test_fold_csbc)\n",
    "        all_y_pred_csbc.extend(y_pred_fold_csbc)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_csbc = confusion_matrix(y_test_fold_csbc, y_pred_fold_csbc)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_csbc = ConfusionMatrixDisplay(confusion_matrix=cm_csbc)\n",
    "        disp_csbc.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - CSBC\")\n",
    "        pname_csbc = method + \"_fold_\" + str(fold_number) + \"_CSBC_confusion_matrix.png\"\n",
    "        plt.savefig(pname_csbc)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_csbc = time.time()\n",
    "    result(all_y_pred_csbc, all_y_test_csbc, \"CSBC\", time_to_train, time_to_predict_fold_csbc)\n",
    "\n",
    "    from lightgbm import LGBMClassifier\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"CSBC\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **31. LightGBM with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lgbm = []\n",
    "    all_y_pred_lgbm = []\n",
    "    start_cv_lgbm = time.time()\n",
    "    time_to_predict_fold_lgbm = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_lgbm, X_test_fold_lgbm = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_lgbm, y_test_fold_lgbm = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Initialize LightGBM Classifier\n",
    "        lgbm = LGBMClassifier()\n",
    "\n",
    "        # Train the model on the fold\n",
    "        start_train_fold_lgbm = time.time()\n",
    "        lgbm.fit(X_train_fold_lgbm, y_train_fold_lgbm)\n",
    "        end_train_fold_lgbm = time.time()\n",
    "        time_to_train += end_train_fold_lgbm  - start_train_fold_lgbm\n",
    "        # Predict on the test set for the fold\n",
    "        start_predict_fold_lgbm = time.time()\n",
    "        y_pred_fold_lgbm = lgbm.predict(X_test_fold_lgbm)\n",
    "        end_predict_fold_lgbm = time.time()\n",
    "\n",
    "        time_to_predict_fold_lgbm += end_predict_fold_lgbm - start_predict_fold_lgbm\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lgbm.extend(y_test_fold_lgbm)\n",
    "        all_y_pred_lgbm.extend(y_pred_fold_lgbm)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_lgbm = confusion_matrix(y_test_fold_lgbm, y_pred_fold_lgbm)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_lgbm = ConfusionMatrixDisplay(confusion_matrix=cm_lgbm)\n",
    "        disp_lgbm.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - LightGBM\")\n",
    "        pname_lgbm = method + \"_fold_\" + str(fold_number) + \"_LightGBM_confusion_matrix.png\"\n",
    "        plt.savefig(pname_lgbm)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lgbm = time.time()\n",
    "    result(all_y_pred_lgbm, all_y_test_lgbm, \"LightGBM\", time_to_train, time_to_predict_fold_lgbm)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"LightGBM\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **32. LinearDiscriminantAnalysis (LDA) with k-fold Cross-Validation\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lda = []\n",
    "    all_y_pred_lda = []\n",
    "    start_cv_lda = time.time()\n",
    "    time_to_predict_fold_lda = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets\n",
    "        X_train_fold_lda, X_test_fold_lda = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_lda, y_test_fold_lda = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Apply Linear Discriminant Analysis (LDA) for dimensionality reduction\n",
    "        lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "        X_train_fold_lda = lda.fit_transform(X_train_fold_lda, y_train_fold_lda)\n",
    "        X_test_fold_lda = lda.transform(X_test_fold_lda)\n",
    "\n",
    "        # Train Random Forest Classifier on the transformed features\n",
    "        classifier_lda = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "        # Train the model on the fold\n",
    "        start_train_fold_lda = time.time()\n",
    "        classifier_lda.fit(X_train_fold_lda, y_train_fold_lda)\n",
    "        end_train_fold_lda = time.time()\n",
    "        time_to_train += end_train_fold_lda -start_train_fold_lda\n",
    "        # Predict on the test set for the fold\n",
    "        start_predict_fold_lda = time.time()\n",
    "        y_pred_fold_lda = classifier_lda.predict(X_test_fold_lda)\n",
    "        end_predict_fold_lda = time.time()\n",
    "\n",
    "        time_to_predict_fold_lda += end_predict_fold_lda - start_predict_fold_lda\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lda.extend(y_test_fold_lda)\n",
    "        all_y_pred_lda.extend(y_pred_fold_lda)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_lda = confusion_matrix(y_test_fold_lda, y_pred_fold_lda)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_lda = ConfusionMatrixDisplay(confusion_matrix=cm_lda)\n",
    "        disp_lda.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - LDA\")\n",
    "        pname_lda = method + \"_fold_\" + str(fold_number) + \"_LDA_confusion_matrix.png\"\n",
    "        plt.savefig(pname_lda)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lda = time.time()\n",
    "    result(all_y_pred_lda, all_y_test_lda, \"LDA\", time_to_train, time_to_predict_fold_lda)\n",
    "\n",
    "    # **MULTI-CLASS CLASSIFICATION**\n",
    "    # **Data Splitting**\n",
    "    # reloading as many transformations on X,Y causing errors for gru code\n",
    "    X_train = train_data.drop(columns=['label'],axis=1)\n",
    "    X_test = test_data.drop(columns=['label'],axis=1)\n",
    "    y_train = train_data['label']\n",
    "    y_test = test_data['label']\n",
    "    X_train = pd.concat([X_train, X_test], axis=0)\n",
    "    y_train = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "    # # 10 DATA COL EACH CLASS\n",
    "    # # Get unique classes\n",
    "    X_train,temp1,y_train,temp2 = train_test_split(X_train,y_train,train_size=0.1, random_state=7)\n",
    "\n",
    "    # Reset indices of X_train and y_train\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"LDA\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **33. GRU with k-fold Cross-Validation**\n",
    "    num_classes =  len(np.unique(y_train))\n",
    "    X_train_array_multi = X_train.to_numpy()\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gru = []\n",
    "    all_y_pred_gru = []\n",
    "    start_cv_gru = time.time()\n",
    "    time_to_predict_fold = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Convert fold data to numpy arrays and reshape for GRU input\n",
    "        X_train_fold_array = X_train_fold.to_numpy().reshape((X_train_fold.shape[0], X_train_fold.shape[1], 1))\n",
    "        X_test_fold_array = X_test_fold.to_numpy().reshape((X_test_fold.shape[0], X_test_fold.shape[1], 1))\n",
    "\n",
    "        # Define and compile the GRU model\n",
    "        rnn_fold = Sequential([\n",
    "            GRU(128, input_shape=(X_train_fold_array.shape[1], X_train_fold_array.shape[2])),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        rnn_fold.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model on the fold\n",
    "        start_train_fold = time.time()\n",
    "        rnn_fold.fit(X_train_fold_array, y_train_fold, epochs=10, batch_size=50, verbose=0)\n",
    "        end_train_fold = time.time()\n",
    "        time_to_train += end_train_fold -start_train_fold\n",
    "        # Predict on the test set for the fold\n",
    "        start_predict_fold = time.time()\n",
    "        y_pred_fold = np.argmax(rnn_fold.predict(X_test_fold_array), axis=1)\n",
    "        end_predict_fold = time.time()\n",
    "\n",
    "        time_to_predict_fold += end_predict_fold - start_predict_fold\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gru.extend(y_test_fold)\n",
    "        all_y_pred_gru.extend(y_pred_fold)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GRU\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_GRU_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gru = time.time()\n",
    "    val_accuracy_gru = accuracy_score(all_y_test_gru, all_y_pred_gru)\n",
    "    result(all_y_pred_gru, all_y_test_gru, \"GRU\", time_to_train, time_to_predict_fold)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GRU\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **34. Stochastic Gradient with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_sgd = []\n",
    "    all_y_pred_sgd = []\n",
    "    start_cv_sgd = time.time()\n",
    "    time_to_predict_fold = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        # Define the SGD classifier pipeline with standard scaler\n",
    "        sgd_fold = make_pipeline(StandardScaler(), SGDClassifier(random_state=24))\n",
    "        # Measure time to train on the fold\n",
    "        start_train_fold = time.time()\n",
    "        sgd_fold.fit(X_train_fold, y_train_fold)\n",
    "        end_train_fold = time.time()\n",
    "        time_to_train += end_train_fold -start_train_fold\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold = time.time()\n",
    "        y_pred_fold = sgd_fold.predict(X_test_fold)\n",
    "        end_predict_fold = time.time()\n",
    "        time_to_predict_fold += end_predict_fold - start_predict_fold\n",
    "        # Append metrics to lists\n",
    "        all_y_test_sgd.extend(y_test_fold)\n",
    "        all_y_pred_sgd.extend(y_pred_fold)\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Stochastic Gradient\")\n",
    "        pname = method + \"_fold_\" + str(fold_number) + \"_Stochastic_gradient_confusion_matrix.png\"\n",
    "        plt.savefig(pname)\n",
    "        #plt.show()\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_sgd = time.time()\n",
    "    result(all_y_pred_sgd, all_y_test_sgd, \"Stochastic_gradient\", time_to_train, time_to_predict_fold)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Stochastic_gradient\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **36. Extra Trees Classifier with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_extra_trees = []\n",
    "    all_y_pred_extra_trees = []\n",
    "    start_cv_extra_trees = time.time()\n",
    "    time_to_predict_fold_extra_trees = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Define the Extra Trees classifier\n",
    "        extra_trees_fold = ExtraTreesClassifier()\n",
    "\n",
    "        # Measure time to train on the fold\n",
    "        start_train_fold_extra_trees = time.time()\n",
    "        extra_trees_fold.fit(X_train_fold, y_train_fold)\n",
    "        end_train_fold_extra_trees = time.time()\n",
    "        time_to_train += end_train_fold_extra_trees -start_train_fold_extra_trees\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold_extra_trees = time.time()\n",
    "        y_pred_fold_extra_trees = extra_trees_fold.predict(X_test_fold)\n",
    "        end_predict_fold_extra_trees = time.time()\n",
    "\n",
    "        time_to_predict_fold_extra_trees += end_predict_fold_extra_trees - start_predict_fold_extra_trees\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_extra_trees.extend(y_test_fold)\n",
    "        all_y_pred_extra_trees.extend(y_pred_fold_extra_trees)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_extra_trees = confusion_matrix(y_test_fold, y_pred_fold_extra_trees)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_extra_trees = ConfusionMatrixDisplay(confusion_matrix=cm_extra_trees)\n",
    "        disp_extra_trees.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Extra Trees Classifier\")\n",
    "        pname_extra_trees = method + \"_fold_\" + str(fold_number) + \"_ExtraTreesClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_extra_trees)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_extra_trees = time.time()\n",
    "    result(all_y_pred_extra_trees, all_y_test_extra_trees, \"Extra Trees Classifier\", time_to_train, time_to_predict_fold_extra_trees)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Extra Trees Classifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **37. Feed Forward Neural Networks with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ffnn = []\n",
    "    all_y_pred_ffnn = []\n",
    "    start_cv_ffnn = time.time()\n",
    "    time_to_predict_fold_ffnn = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Define the neural network architecture\n",
    "        model_ffnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_fold.shape[1],)),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(len(np.unique(y_train_fold)), activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model_ffnn.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        # Measure time to train on the fold\n",
    "        start_train_fold_ffnn = time.time()\n",
    "        history_ffnn = model_ffnn.fit(X_train_fold, y_train_fold, epochs=10, batch_size=50, verbose=1)\n",
    "        end_train_fold_ffnn = time.time()\n",
    "        time_to_train += end_train_fold_ffnn -start_train_fold_ffnn\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold_ffnn = time.time()\n",
    "        y_pred_fold_ffnn_prob = model_ffnn.predict(X_test_fold)\n",
    "        y_pred_fold_ffnn = np.argmax(y_pred_fold_ffnn_prob, axis=1)\n",
    "        end_predict_fold_ffnn = time.time()\n",
    "\n",
    "        time_to_predict_fold_ffnn += end_predict_fold_ffnn - start_predict_fold_ffnn\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ffnn.extend(y_test_fold)\n",
    "        all_y_pred_ffnn.extend(y_pred_fold_ffnn)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_ffnn = confusion_matrix(y_test_fold, y_pred_fold_ffnn)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_ffnn = ConfusionMatrixDisplay(confusion_matrix=cm_ffnn)\n",
    "        disp_ffnn.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Feed Forward Neural Networks\")\n",
    "        pname_ffnn = method + \"_fold_\" + str(fold_number) + \"_FFNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname_ffnn)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ffnn = time.time()\n",
    "    result(all_y_pred_ffnn, all_y_test_ffnn, \"Feed Forward Neural Networks\", time_to_train, time_to_predict_fold_ffnn)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Feed Forward Neural Networks\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **38. Fuzzy with k-fold Cross-Validation**\n",
    "\n",
    "    all_y_test_fuzzy = []\n",
    "    all_y_pred_fuzzy = []\n",
    "    start_cv_fuzzy = time.time()\n",
    "    time_to_predict_fold_fuzzy = 0\n",
    "    time_to_train=0\n",
    "    # Generate fuzzy c-means clusters\n",
    "    n_clusters = 10  # Number of classes\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        start_train_fold_fuzzy = time.time()\n",
    "        # Generate fuzzy c-means clusters for training data of the fold\n",
    "        centers, u_train_fold, _, _, _, _, _ = fuzz.cluster.cmeans(\n",
    "            X_train_fold.T, n_clusters, 2, error=0.005, maxiter=1000\n",
    "        )\n",
    "\n",
    "        # Measure time to train on the fold\n",
    "        end_train_fold_fuzzy = time.time()\n",
    "        time_to_train  += end_train_fold_fuzzy - start_train_fold_fuzzy\n",
    "        # Predict cluster membership for test data of the fold\n",
    "        start_predict_fold_fuzzy = time.time()\n",
    "        u_test_fold, _, _, _, _, _ = fuzz.cluster.cmeans_predict(\n",
    "            X_test_fold.T, centers, 2, error=0.005, maxiter=1000\n",
    "        )\n",
    "        end_predict_fold_fuzzy = time.time()\n",
    "\n",
    "        time_to_predict_fold_fuzzy += end_predict_fold_fuzzy - start_predict_fold_fuzzy\n",
    "\n",
    "        # Assign class labels based on cluster membership\n",
    "        y_pred_fold_fuzzy = np.argmax(u_test_fold, axis=0)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_fuzzy.extend(y_test_fold)\n",
    "        all_y_pred_fuzzy.extend(y_pred_fold_fuzzy)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_fuzzy = confusion_matrix(y_test_fold, y_pred_fold_fuzzy)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_fuzzy = ConfusionMatrixDisplay(confusion_matrix=cm_fuzzy)\n",
    "        disp_fuzzy.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Fuzzy\")\n",
    "        pname_fuzzy = method + \"_fold_\" + str(fold_number) + \"_Fuzzy_confusion_matrix.png\"\n",
    "        plt.savefig(pname_fuzzy)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_fuzzy = time.time()\n",
    "    result(all_y_pred_fuzzy, all_y_test_fuzzy, \"Fuzzy\", time_to_train, time_to_predict_fold_fuzzy)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Fuzzy\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **39. Ensemble of Deep Learning Networks (EDLNs) with k-fold Cross-Validation**\n",
    "    # Define the architecture of your neural network (example architecture)\n",
    "    def create_model(input_shape, num_classes):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "            keras.layers.Dense(64, activation='relu'),\n",
    "            keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_EDLN = []\n",
    "    all_y_pred_EDLN = []\n",
    "    start_cv_EDLN = time.time()\n",
    "    time_to_predict_fold_EDLN = 0\n",
    "    time_to_train=0\n",
    "    # Define hyperparameters\n",
    "    num_networks = 5\n",
    "    epochs = 10\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index, test_index) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_EDLN, X_test_fold_EDLN = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold_EDLN, y_test_fold_EDLN = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Train multiple neural networks\n",
    "        start = time.time()\n",
    "        models_fold_EDLN = []\n",
    "        for i in range(num_networks):\n",
    "            model_fold_EDLN = create_model(input_shape=X_train_fold_EDLN.shape[1:], num_classes=num_classes)\n",
    "            model_fold_EDLN.fit(X_train_fold_EDLN, y_train_fold_EDLN, epochs=epochs, verbose=0)\n",
    "            models_fold_EDLN.append(model_fold_EDLN)\n",
    "        end = time.time()\n",
    "        time_to_train += end - start\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold_EDLN = time.time()\n",
    "        # Make predictions on test data using each model\n",
    "        predictions_fold_EDLN = np.array([model_fold_EDLN.predict(X_test_fold_EDLN) for model_fold_EDLN in models_fold_EDLN])\n",
    "        end_predict_fold_EDLN = time.time()\n",
    "\n",
    "        time_to_predict_fold_EDLN += end_predict_fold_EDLN - start_predict_fold_EDLN\n",
    "\n",
    "        # Aggregate predictions by averaging\n",
    "        y_pred_fold_EDLN = np.argmax(np.mean(predictions_fold_EDLN, axis=0), axis=1)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_EDLN.extend(y_test_fold_EDLN)\n",
    "        all_y_pred_EDLN.extend(y_pred_fold_EDLN)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_EDLN = confusion_matrix(y_test_fold_EDLN, y_pred_fold_EDLN)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_EDLN = ConfusionMatrixDisplay(confusion_matrix=cm_EDLN)\n",
    "        disp_EDLN.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - EDLNs\")\n",
    "        pname_EDLN = method + \"_fold_\" + str(fold_number) + \"_EDLNs_confusion_matrix.png\"\n",
    "        plt.savefig(pname_EDLN)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_EDLN = time.time()\n",
    "    result(all_y_pred_EDLN, all_y_test_EDLN, \"EDLNs\", time_to_train, time_to_predict_fold_EDLN)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"EDLNs\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    ## **40. Gaussian Mixture Model (GMM) with k-fold Cross-Validation**\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gmm = []\n",
    "    all_y_pred_gmm = []\n",
    "    start_cv_gmm = time.time()\n",
    "    time_to_predict_fold_gmm = 0\n",
    "    time_to_train=0\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gmm, test_index_gmm) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gmm, X_test_fold_gmm = X_train.iloc[train_index_gmm], X_train.iloc[test_index_gmm]\n",
    "        y_train_fold_gmm, y_test_fold_gmm = y_train.iloc[train_index_gmm], y_train.iloc[test_index_gmm]\n",
    "\n",
    "        # Number of classes\n",
    "        n_classes_gmm = len(set(y_train_fold_gmm))\n",
    "\n",
    "        # Dictionary to store GMMs for each class\n",
    "        gmm_models_fold_gmm = {}\n",
    "\n",
    "        # Train GMMs for each class\n",
    "        start_train_fold_gmm = time.time()\n",
    "        for i in range(n_classes_gmm):\n",
    "            # Filter data for the current class\n",
    "            X_class_gmm = X_train_fold_gmm[y_train_fold_gmm == i]\n",
    "            # Fit Gaussian Mixture Model\n",
    "            gmm_fold_gmm = GaussianMixture(n_components=2)  # You can adjust n_components as needed\n",
    "            gmm_fold_gmm.fit(X_class_gmm)\n",
    "            # Store the trained GMM\n",
    "            gmm_models_fold_gmm[i] = gmm_fold_gmm\n",
    "        end_train_fold_gmm = time.time()\n",
    "        time_to_train += end_train_fold_gmm - start_train_fold_gmm\n",
    "        # Measure time to predict on the fold\n",
    "        start_predict_fold_gmm = time.time()\n",
    "        y_pred_fold_gmm = []\n",
    "        for x_gmm in X_test_fold_gmm.values:  # Convert DataFrame to numpy array for iteration\n",
    "            class_likelihoods_gmm = []\n",
    "            # Reshape x to have the appropriate dimensions\n",
    "            x_reshaped_gmm = x_gmm.reshape(1, -1)\n",
    "            # Calculate likelihood for each class\n",
    "            for i in range(n_classes_gmm):\n",
    "                class_likelihood_gmm = gmm_models_fold_gmm[i].score_samples(x_reshaped_gmm)\n",
    "                class_likelihoods_gmm.append(class_likelihood_gmm)\n",
    "            # Assign the class with the highest likelihood\n",
    "            predicted_class_gmm = max(zip(class_likelihoods_gmm, range(n_classes_gmm)))[1]\n",
    "            y_pred_fold_gmm.append(predicted_class_gmm)\n",
    "        end_predict_fold_gmm = time.time()\n",
    "\n",
    "        time_to_predict_fold_gmm += end_predict_fold_gmm - start_predict_fold_gmm\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gmm.extend(y_test_fold_gmm)\n",
    "        all_y_pred_gmm.extend(y_pred_fold_gmm)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_gmm = confusion_matrix(y_test_fold_gmm, y_pred_fold_gmm)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gmm = ConfusionMatrixDisplay(confusion_matrix=cm_gmm)\n",
    "        disp_gmm.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GMM\")\n",
    "        pname_gmm = method + \"_fold_\" + str(fold_number) + \"_GMM_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gmm)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gmm = time.time()\n",
    "    result(all_y_pred_gmm, all_y_test_gmm, \"GMM\", time_to_train, time_to_predict_fold_gmm)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GMM Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GMM\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## **41. Bernoulli Naive Bayes with k-fold Cross-Validation**\"\"\"\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_bnb = []\n",
    "    all_y_pred_bnb = []\n",
    "    start_cv_bnb = time.time()\n",
    "    time_to_predict_fold_bnb = 0\n",
    "    time_to_train=0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_bnb, test_index_bnb) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_bnb, X_test_fold_bnb = X_train.iloc[train_index_bnb], X_train.iloc[test_index_bnb]\n",
    "        y_train_fold_bnb, y_test_fold_bnb = y_train.iloc[train_index_bnb], y_train.iloc[test_index_bnb]\n",
    "\n",
    "        # Create a Bernoulli Naive Bayes classifier\n",
    "        bnb_fold_bnb = BernoulliNB()\n",
    "\n",
    "        # Train the classifier\n",
    "        start_train_fold_bnb = time.time()\n",
    "        bnb_fold_bnb.fit(X_train_fold_bnb, y_train_fold_bnb)\n",
    "        end_train_fold_bnb = time.time()\n",
    "        time_to_train += end_train_fold_bnb - start_train_fold_bnb\n",
    "\n",
    "        # Predict using the trained model\n",
    "        start_predict_fold_bnb = time.time()\n",
    "        y_pred_fold_bnb = bnb_fold_bnb.predict(X_test_fold_bnb)\n",
    "        end_predict_fold_bnb = time.time()\n",
    "        time_to_predict_fold_bnb += end_predict_fold_bnb - start_predict_fold_bnb\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_bnb.extend(y_test_fold_bnb)\n",
    "        all_y_pred_bnb.extend(y_pred_fold_bnb)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_bnb = confusion_matrix(y_test_fold_bnb, y_pred_fold_bnb)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_bnb = ConfusionMatrixDisplay(confusion_matrix=cm_bnb)\n",
    "        disp_bnb.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Bernoulli Naive Bayes\")\n",
    "        pname_bnb = method + \"_fold_\" + str(fold_number) + \"_Bernoulli_Naive_Bayes_confusion_matrix.png\"\n",
    "        plt.savefig(pname_bnb)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_bnb = time.time()\n",
    "    result(all_y_pred_bnb, all_y_test_bnb, \"Bernoulli Naive Bayes\", time_to_train, time_to_predict_fold_bnb)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Bernoulli Naive Bayes with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Bernoulli Naive Bayes\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## **42. CatBoost with k-fold Cross-Validation**\"\"\"\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_catboost = []\n",
    "    all_y_pred_catboost = []\n",
    "    start_cv_catboost = time.time()\n",
    "    time_to_predict_fold_catboost = 0\n",
    "    time_to_train=0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_catboost, test_index_catboost) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_catboost, X_test_fold_catboost = X_train.iloc[train_index_catboost], X_train.iloc[test_index_catboost]\n",
    "        y_train_fold_catboost, y_test_fold_catboost = y_train.iloc[train_index_catboost], y_train.iloc[test_index_catboost]\n",
    "\n",
    "        # Create and train the CatBoost model\n",
    "        start_train_fold_catboost = time.time()\n",
    "        catboost_model_fold_catboost = CatBoostClassifier(random_state=42)\n",
    "        catboost_model_fold_catboost.fit(X_train_fold_catboost, y_train_fold_catboost)\n",
    "        end_train_fold_catboost = time.time()\n",
    "        time_to_train += end_train_fold_catboost - start_train_fold_catboost\n",
    "\n",
    "        # Predict using the trained model\n",
    "        start_predict_fold_catboost = time.time()\n",
    "        y_pred_fold_catboost = catboost_model_fold_catboost.predict(X_test_fold_catboost)\n",
    "        end_predict_fold_catboost = time.time()\n",
    "        time_to_predict_fold_catboost += end_predict_fold_catboost - start_predict_fold_catboost\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_catboost.extend(y_test_fold_catboost)\n",
    "        all_y_pred_catboost.extend(y_pred_fold_catboost)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_catboost = confusion_matrix(y_test_fold_catboost, y_pred_fold_catboost)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_catboost = ConfusionMatrixDisplay(confusion_matrix=cm_catboost)\n",
    "        disp_catboost.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - CatBoost\")\n",
    "        pname_catboost = method + \"_fold_\" + str(fold_number) + \"_CatBoost_confusion_matrix.png\"\n",
    "        plt.savefig(pname_catboost)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_catboost = time.time()\n",
    "    result(all_y_pred_catboost, all_y_test_catboost, \"CatBoost\", time_to_train, time_to_predict_fold_catboost)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"CatBoost with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"CatBoost\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## **43. Centralised blending with k-fold Cross-Validation**\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_blend = []\n",
    "    all_y_pred_blend = []\n",
    "    start_cv_blend = time.time()\n",
    "    time_to_predict_fold_blend = 0\n",
    "    time_to_train = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_blend, test_index_blend) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_blend, X_test_fold_blend = X_train.iloc[train_index_blend], X_train.iloc[test_index_blend]\n",
    "        y_train_fold_blend, y_test_fold_blend = y_train.iloc[train_index_blend], y_train.iloc[test_index_blend]\n",
    "\n",
    "        # Define base models\n",
    "        base_model1 = DecisionTreeClassifier(random_state=24)\n",
    "        base_model2 = RandomForestClassifier(random_state=24)\n",
    "        base_model3 = LogisticRegression(random_state=24)\n",
    "\n",
    "        # Train base models\n",
    "        start_train_fold_blend = time.time()\n",
    "        base_model1.fit(X_train_fold_blend, y_train_fold_blend)\n",
    "        base_model2.fit(X_train_fold_blend, y_train_fold_blend)\n",
    "        base_model3.fit(X_train_fold_blend, y_train_fold_blend)\n",
    "        end_train_fold_blend = time.time()\n",
    "        time_to_train += end_train_fold_blend - start_train_fold_blend\n",
    "\n",
    "        # Make predictions on validation data\n",
    "        preds_val_base_model1 = base_model1.predict(X_test_fold_blend)\n",
    "        preds_val_base_model2 = base_model2.predict(X_test_fold_blend)\n",
    "        preds_val_base_model3 = base_model3.predict(X_test_fold_blend)\n",
    "\n",
    "        # Combine predictions from base models into a feature matrix for meta-model\n",
    "        X_val_meta_blend = np.column_stack((preds_val_base_model1, preds_val_base_model2, preds_val_base_model3))\n",
    "\n",
    "        # Train meta-model (blender)\n",
    "        blender_blend = LogisticRegression(random_state=24)\n",
    "        blender_blend.fit(X_val_meta_blend, y_test_fold_blend)\n",
    "\n",
    "        # Make predictions on test data using base models\n",
    "        preds_test_base_model1 = base_model1.predict(X_test_fold_blend)\n",
    "        preds_test_base_model2 = base_model2.predict(X_test_fold_blend)\n",
    "        preds_test_base_model3 = base_model3.predict(X_test_fold_blend)\n",
    "\n",
    "        # Combine predictions from base models into a feature matrix for meta-model\n",
    "        X_test_meta_blend = np.column_stack((preds_test_base_model1, preds_test_base_model2, preds_test_base_model3))\n",
    "\n",
    "        # Make predictions on test data using meta-model\n",
    "        preds_test_meta_blend = blender_blend.predict(X_test_meta_blend)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_blend.extend(y_test_fold_blend)\n",
    "        all_y_pred_blend.extend(preds_test_meta_blend)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_blend = confusion_matrix(y_test_fold_blend, preds_test_meta_blend)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_blend = ConfusionMatrixDisplay(confusion_matrix=cm_blend)\n",
    "        disp_blend.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Centralised Blending\")\n",
    "        pname_blend = method + \"_fold_\" + str(fold_number) + \"_Centralised_Blending_confusion_matrix.png\"\n",
    "        plt.savefig(pname_blend)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_blend = time.time()\n",
    "    result(all_y_pred_blend, all_y_test_blend, \"Centralised Blending\", time_to_train, time_to_predict_fold_blend)\n",
    "\n",
    "    \"\"\"44.## Binary Logical Circular Neural Network (BLoCNet) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_blocnet = []\n",
    "    all_y_pred_blocnet = []\n",
    "    start_cv_blocnet = time.time()\n",
    "    time_to_predict_fold_blocnet = 0\n",
    "    time_to_train = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_blocnet, test_index_blocnet) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_blocnet, X_test_fold_blocnet = X_train.iloc[train_index_blocnet], X_train.iloc[test_index_blocnet]\n",
    "        y_train_fold_blocnet, y_test_fold_blocnet = y_train.iloc[train_index_blocnet], y_train.iloc[test_index_blocnet]\n",
    "\n",
    "        # Define the architecture of the BLoCNet\n",
    "        model_blocnet = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_fold_blocnet.shape[1],)),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(9, activation='softmax')  # Multi-class classification, so softmax activation\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model_blocnet.compile(optimizer='adam',\n",
    "                            loss='sparse_categorical_crossentropy',  # Multi-class classification, so sparse categorical crossentropy loss\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        start_train_fold_blocnet = time.time()\n",
    "        history_blocnet = model_blocnet.fit(X_train_fold_blocnet, y_train_fold_blocnet, epochs=10, batch_size=32, validation_split=0.2)\n",
    "        end_train_fold_blocnet = time.time()\n",
    "        time_to_train += end_train_fold_blocnet - start_train_fold_blocnet\n",
    "\n",
    "        # Evaluate the model\n",
    "        start_predict_fold_blocnet = time.time()\n",
    "        y_pred_fold_blocnet = model_blocnet.predict(X_test_fold_blocnet)\n",
    "        y_pred_fold_blocnet = np.argmax(y_pred_fold_blocnet, axis=1)\n",
    "        end_predict_fold_blocnet = time.time()\n",
    "        time_to_predict_fold_blocnet += end_predict_fold_blocnet - start_predict_fold_blocnet\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_blocnet.extend(y_test_fold_blocnet)\n",
    "        all_y_pred_blocnet.extend(y_pred_fold_blocnet)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_blocnet = confusion_matrix(y_test_fold_blocnet, y_pred_fold_blocnet)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_blocnet = ConfusionMatrixDisplay(confusion_matrix=cm_blocnet)\n",
    "        disp_blocnet.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - BLoCNet\")\n",
    "        pname_blocnet = method + \"_fold_\" + str(fold_number) + \"_BLoCNet_confusion_matrix.png\"\n",
    "        plt.savefig(pname_blocnet)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_blocnet = time.time()\n",
    "    result(all_y_pred_blocnet, all_y_test_blocnet, \"BLoCNet\", time_to_train, time_to_predict_fold_blocnet)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"BLoCNet with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"BLoCNet\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 45.constructive_learning with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_constructive_learning = []\n",
    "    all_y_pred_constructive_learning = []\n",
    "    start_cv_constructive_learning = time.time()\n",
    "    time_to_predict_fold_constructive_learning = 0\n",
    "    time_to_train = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_constructive_learning, test_index_constructive_learning) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_constructive_learning, X_test_fold_constructive_learning = X_train.iloc[train_index_constructive_learning], X_train.iloc[test_index_constructive_learning]\n",
    "        y_train_fold_constructive_learning, y_test_fold_constructive_learning = y_train.iloc[train_index_constructive_learning], y_train.iloc[test_index_constructive_learning]\n",
    "\n",
    "        # Create a basic Decision Tree model for this fold\n",
    "        base_model_fold_constructive_learning = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        # Train the base model for this fold\n",
    "        start_train_fold_constructive_learning = time.time()\n",
    "        base_model_fold_constructive_learning.fit(X_train_fold_constructive_learning, y_train_fold_constructive_learning)\n",
    "        end_train_fold_constructive_learning = time.time()\n",
    "        time_to_train += end_train_fold_constructive_learning - start_train_fold_constructive_learning\n",
    "\n",
    "        # Evaluate the base model for this fold\n",
    "        start_predict_fold_constructive_learning = time.time()\n",
    "        y_pred_fold_constructive_learning = base_model_fold_constructive_learning.predict(X_test_fold_constructive_learning)\n",
    "        end_predict_fold_constructive_learning = time.time()\n",
    "        time_to_predict_fold_constructive_learning += end_predict_fold_constructive_learning - start_predict_fold_constructive_learning\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_constructive_learning.extend(y_test_fold_constructive_learning)\n",
    "        all_y_pred_constructive_learning.extend(y_pred_fold_constructive_learning)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_constructive_learning = confusion_matrix(y_test_fold_constructive_learning, y_pred_fold_constructive_learning)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_constructive_learning = ConfusionMatrixDisplay(confusion_matrix=cm_constructive_learning)\n",
    "        disp_constructive_learning.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - constructive_learning\")\n",
    "        pname_constructive_learning = method + \"_fold_\" + str(fold_number) + \"_constructive_learning_confusion_matrix.png\"\n",
    "        plt.savefig(pname_constructive_learning)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_constructive_learning = time.time()\n",
    "    result(all_y_pred_constructive_learning, all_y_test_constructive_learning, \"constructive_learning\", time_to_train, time_to_predict_fold_constructive_learning)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"constructive_learning with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"constructive_learning\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 46. Artificial Immune System (AIS) with k-fold Cross-Validation\"\"\"\n",
    "    class AISModel:\n",
    "        def __init__(self, base_model):\n",
    "            self.base_model = base_model\n",
    "\n",
    "        def fit(self, X_train, y_train):\n",
    "            # AIS training algorithm\n",
    "            self.base_model.fit(X_train, y_train)\n",
    "\n",
    "        def predict(self, X_test):\n",
    "            # AIS prediction algorithm\n",
    "            y_pred = self.base_model.predict(X_test)\n",
    "            return y_pred\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ais = []\n",
    "    all_y_pred_ais = []\n",
    "    start_cv_ais = time.time()\n",
    "    time_to_predict_fold_ais = 0\n",
    "    time_to_train = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_ais, test_index_ais) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_ais, X_test_fold_ais = X_train.iloc[train_index_ais], X_train.iloc[test_index_ais]\n",
    "        y_train_fold_ais, y_test_fold_ais = y_train.iloc[train_index_ais], y_train.iloc[test_index_ais]\n",
    "\n",
    "        # Create an instance of RandomForestClassifier as the base learner for this fold\n",
    "        base_model_fold_ais = RandomForestClassifier(random_state=24)\n",
    "\n",
    "        # Create an instance of AISModel with the base learner for this fold\n",
    "        ais_model_fold_ais = AISModel(base_model_fold_ais)\n",
    "\n",
    "        # Train the AIS model for this fold\n",
    "        start_train_fold_ais = time.time()\n",
    "        ais_model_fold_ais.fit(X_train_fold_ais, y_train_fold_ais)\n",
    "        end_train_fold_ais = time.time()\n",
    "        time_to_train += end_train_fold_ais - start_train_fold_ais\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_ais = time.time()\n",
    "        y_pred_fold_ais = ais_model_fold_ais.predict(X_test_fold_ais)\n",
    "        end_predict_fold_ais = time.time()\n",
    "        time_to_predict_fold_ais += end_predict_fold_ais - start_predict_fold_ais\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ais.extend(y_test_fold_ais)\n",
    "        all_y_pred_ais.extend(y_pred_fold_ais)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_ais = confusion_matrix(y_test_fold_ais, y_pred_fold_ais)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_ais = ConfusionMatrixDisplay(confusion_matrix=cm_ais)\n",
    "        disp_ais.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - AIS\")\n",
    "        pname_ais = method + \"_fold_\" + str(fold_number) + \"_AIS_confusion_matrix.png\"\n",
    "        plt.savefig(pname_ais)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ais = time.time()\n",
    "    result(all_y_pred_ais, all_y_test_ais, \"AIS\", time_to_train, time_to_predict_fold_ais)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"AIS with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"AIS\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 48. GBBK Algorithm with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gbkk = []\n",
    "    all_y_pred_gbkk = []\n",
    "    start_cv_gbkk = time.time()\n",
    "    time_to_predict_fold_gbkk = 0\n",
    "    time_to_train_gbkk = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gbkk, test_index_gbkk) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gbkk, X_test_fold_gbkk = X_train.iloc[train_index_gbkk], X_train.iloc[test_index_gbkk]\n",
    "        y_train_fold_gbkk, y_test_fold_gbkk = y_train.iloc[train_index_gbkk], y_train.iloc[test_index_gbkk]\n",
    "\n",
    "        # Initialize Gaussian Naive Bayes (GBBK) model for this fold\n",
    "        gbbk_model_fold_gbkk = GaussianNB()\n",
    "\n",
    "        # Train the GBBK model for this fold\n",
    "        start_train_fold_gbkk = time.time()\n",
    "        gbbk_model_fold_gbkk.fit(X_train_fold_gbkk, y_train_fold_gbkk)\n",
    "        end_train_fold_gbkk = time.time()\n",
    "        time_to_train_gbkk += end_train_fold_gbkk - start_train_fold_gbkk\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_gbkk = time.time()\n",
    "        y_pred_fold_gbkk = gbbk_model_fold_gbkk.predict(X_test_fold_gbkk)\n",
    "        end_predict_fold_gbkk = time.time()\n",
    "        time_to_predict_fold_gbkk += end_predict_fold_gbkk - start_predict_fold_gbkk\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gbkk.extend(y_test_fold_gbkk)\n",
    "        all_y_pred_gbkk.extend(y_pred_fold_gbkk)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_gbkk = confusion_matrix(y_test_fold_gbkk, y_pred_fold_gbkk)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gbkk = ConfusionMatrixDisplay(confusion_matrix=cm_gbkk)\n",
    "        disp_gbkk.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GBBK\")\n",
    "        pname_gbkk = method + \"_fold_\" + str(fold_number) + \"_GBBK_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gbkk)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gbkk = time.time()\n",
    "    result(all_y_pred_gbkk, all_y_test_gbkk, \"GBBK\", time_to_train_gbkk, time_to_predict_fold_gbkk)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GBBK with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GBBK\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 48. GE SVM Algorithm with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gbkk = []\n",
    "    all_y_pred_gbkk = []\n",
    "    start_cv_gbkk = time.time()\n",
    "    time_to_predict_fold_gbkk = 0\n",
    "    time_to_train_gbkk = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gbkk, test_index_gbkk) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gbkk, X_test_fold_gbkk = X_train.iloc[train_index_gbkk], X_train.iloc[test_index_gbkk]\n",
    "        y_train_fold_gbkk, y_test_fold_gbkk = y_train.iloc[train_index_gbkk], y_train.iloc[test_index_gbkk]\n",
    "\n",
    "        # Initialize Gaussian Naive Bayes (GBBK) model for this fold\n",
    "        gbbk_model_fold_gbkk = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "\n",
    "        # Train the GBBK model for this fold\n",
    "        start_train_fold_gbkk = time.time()\n",
    "        gbbk_model_fold_gbkk.fit(X_train_fold_gbkk, y_train_fold_gbkk)\n",
    "        end_train_fold_gbkk = time.time()\n",
    "        time_to_train_gbkk += end_train_fold_gbkk - start_train_fold_gbkk\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_gbkk = time.time()\n",
    "        y_pred_fold_gbkk = gbbk_model_fold_gbkk.predict(X_test_fold_gbkk)\n",
    "        end_predict_fold_gbkk = time.time()\n",
    "        time_to_predict_fold_gbkk += end_predict_fold_gbkk - start_predict_fold_gbkk\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gbkk.extend(y_test_fold_gbkk)\n",
    "        all_y_pred_gbkk.extend(y_pred_fold_gbkk)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_gbkk = confusion_matrix(y_test_fold_gbkk, y_pred_fold_gbkk)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gbkk = ConfusionMatrixDisplay(confusion_matrix=cm_gbkk)\n",
    "        disp_gbkk.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GE SVM\")\n",
    "        pname_gbkk = method + \"_fold_\" + str(fold_number) + \"_GE_SVM_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gbkk)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gbkk = time.time()\n",
    "    result(all_y_pred_gbkk, all_y_test_gbkk, \"GE SVM\", time_to_train_gbkk, time_to_predict_fold_gbkk)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GE SVM with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GE SVM\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 51. Hidden Naive Bayes (HNB) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_hnb = []\n",
    "    all_y_pred_hnb = []\n",
    "    start_cv_hnb = time.time()\n",
    "    time_to_predict_fold_hnb = 0\n",
    "    time_to_train_hnb = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_hnb, test_index_hnb) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_hnb, X_test_fold_hnb = X_train.iloc[train_index_hnb], X_train.iloc[test_index_hnb]\n",
    "        y_train_fold_hnb, y_test_fold_hnb = y_train.iloc[train_index_hnb], y_train.iloc[test_index_hnb]\n",
    "\n",
    "        # Train the HNB model for this fold\n",
    "        hnb_model_fold = GaussianNB()\n",
    "        start_train_fold_hnb = time.time()\n",
    "        hnb_model_fold.fit(pd.DataFrame(X_train_fold_hnb), pd.DataFrame(y_train_fold_hnb))\n",
    "        end_train_fold_hnb = time.time()\n",
    "        time_to_train_hnb += end_train_fold_hnb - start_train_fold_hnb\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_hnb = time.time()\n",
    "        y_pred_fold_hnb = hnb_model_fold.predict(X_test_fold_hnb.values)\n",
    "        end_predict_fold_hnb = time.time()\n",
    "        time_to_predict_fold_hnb += end_predict_fold_hnb - start_predict_fold_hnb\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_hnb.extend(y_test_fold_hnb)\n",
    "        all_y_pred_hnb.extend(y_pred_fold_hnb)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_hnb = confusion_matrix(y_test_fold_hnb, y_pred_fold_hnb)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_hnb = ConfusionMatrixDisplay(confusion_matrix=cm_hnb)\n",
    "        disp_hnb.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - HNB\")\n",
    "        pname_hnb = method + \"_fold_\" + str(fold_number) + \"_HNB_confusion_matrix.png\"\n",
    "        plt.savefig(pname_hnb)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_hnb = time.time()\n",
    "    result(all_y_pred_hnb, all_y_test_hnb, \"Hidden Naive Bayes (HNB)\", time_to_train_hnb, time_to_predict_fold_hnb)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"HNB with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Hidden Naive Bayes\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 52. HistGradientBoostingClassifier with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_hgb = []\n",
    "    all_y_pred_hgb = []\n",
    "    start_cv_hgb = time.time()\n",
    "    time_to_predict_fold_hgb = 0\n",
    "    time_to_train_hgb = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_hgb, test_index_hgb) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_hgb, X_test_fold_hgb = X_train.iloc[train_index_hgb], X_train.iloc[test_index_hgb]\n",
    "        y_train_fold_hgb, y_test_fold_hgb = y_train.iloc[train_index_hgb], y_train.iloc[test_index_hgb]\n",
    "\n",
    "        # Train the HistGradientBoostingClassifier model for this fold\n",
    "        hgb_model_fold = HistGradientBoostingClassifier(random_state=24)\n",
    "        start_train_fold_hgb = time.time()\n",
    "        hgb_model_fold.fit(X_train_fold_hgb, y_train_fold_hgb)\n",
    "        end_train_fold_hgb = time.time()\n",
    "        time_to_train_hgb += end_train_fold_hgb - start_train_fold_hgb\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_hgb = time.time()\n",
    "        y_pred_fold_hgb = hgb_model_fold.predict(X_test_fold_hgb)\n",
    "        end_predict_fold_hgb = time.time()\n",
    "        time_to_predict_fold_hgb += end_predict_fold_hgb - start_predict_fold_hgb\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_hgb.extend(y_test_fold_hgb)\n",
    "        all_y_pred_hgb.extend(y_pred_fold_hgb)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_hgb = confusion_matrix(y_test_fold_hgb, y_pred_fold_hgb)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_hgb = ConfusionMatrixDisplay(confusion_matrix=cm_hgb)\n",
    "        disp_hgb.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - HistGradientBoostingClassifier\")\n",
    "        pname_hgb = method + \"_fold_\" + str(fold_number) + \"_HistGradientBoostingClassifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_hgb)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_hgb = time.time()\n",
    "    result(all_y_pred_hgb, all_y_test_hgb, \"HistGradientBoostingClassifier\", time_to_train_hgb, time_to_predict_fold_hgb)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"HistGradientBoostingClassifier with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"HistGradientBoostingClassifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## IGRF-RFE with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize Decision Tree Classifier\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=24)\n",
    "\n",
    "    # Initialize RFE (Recursive Feature Elimination) with Decision Tree Classifier as estimator\n",
    "    rfe = RFE(estimator=dt_classifier)\n",
    "\n",
    "    # Initialize k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits= n_splits_for_cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_igrf_rfe = []\n",
    "    all_y_pred_igrf_rfe = []\n",
    "    start_cv_igrf_rfe = time.time()\n",
    "    time_to_predict_fold_igrf_rfe = 0\n",
    "    time_to_train_igrf_rfe = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_igrf_rfe, test_index_igrf_rfe) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_igrf_rfe, X_test_fold_igrf_rfe = X_train.iloc[train_index_igrf_rfe], X_train.iloc[test_index_igrf_rfe]\n",
    "        y_train_fold_igrf_rfe, y_test_fold_igrf_rfe = y_train.iloc[train_index_igrf_rfe], y_train.iloc[test_index_igrf_rfe]\n",
    "\n",
    "        # Fit RFE on training data for this fold\n",
    "        start_feature_selection_fold_igrf_rfe = time.time()\n",
    "        rfe.fit(X_train_fold_igrf_rfe, y_train_fold_igrf_rfe)\n",
    "        end_feature_selection_fold_igrf_rfe = time.time()\n",
    "\n",
    "        # Select features based on RFE ranking\n",
    "        X_train_rfe_fold_igrf_rfe = rfe.transform(X_train_fold_igrf_rfe)\n",
    "        X_test_rfe_fold_igrf_rfe = rfe.transform(X_test_fold_igrf_rfe)\n",
    "\n",
    "        # Train Decision Tree Classifier using selected features for this fold\n",
    "        start_train_fold_igrf_rfe = time.time()\n",
    "        dt_classifier.fit(X_train_rfe_fold_igrf_rfe, y_train_fold_igrf_rfe)\n",
    "        end_train_fold_igrf_rfe = time.time()\n",
    "        time_to_train_igrf_rfe += end_train_fold_igrf_rfe - start_train_fold_igrf_rfe\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_igrf_rfe = time.time()\n",
    "        y_pred_fold_igrf_rfe = dt_classifier.predict(X_test_rfe_fold_igrf_rfe)\n",
    "        end_predict_fold_igrf_rfe = time.time()\n",
    "        time_to_predict_fold_igrf_rfe += end_predict_fold_igrf_rfe - start_predict_fold_igrf_rfe\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_igrf_rfe.extend(y_test_fold_igrf_rfe)\n",
    "        all_y_pred_igrf_rfe.extend(y_pred_fold_igrf_rfe)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_igrf_rfe = confusion_matrix(y_test_fold_igrf_rfe, y_pred_fold_igrf_rfe)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_igrf_rfe = ConfusionMatrixDisplay(confusion_matrix=cm_igrf_rfe)\n",
    "        disp_igrf_rfe.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - IGRF-RFE\")\n",
    "        pname_igrf_rfe = method + \"_fold_\" + str(fold_number) + \"_IGRF_RFE_confusion_matrix.png\"\n",
    "        plt.savefig(pname_igrf_rfe)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_igrf_rfe = time.time()\n",
    "    result(all_y_pred_igrf_rfe, all_y_test_igrf_rfe, \"IGRF-RFE with k-fold Cross-Validation\", time_to_train_igrf_rfe, time_to_predict_fold_igrf_rfe)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"IGRF-RFE with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"IGRF-RFE\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 55. Independent Component Analysis (ICA) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_ica = []\n",
    "    all_y_pred_ica = []\n",
    "    start_cv_ica = time.time()\n",
    "    time_to_predict_fold_ica = 0\n",
    "    time_to_train_ica = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_ica, test_index_ica) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_ica, X_test_fold_ica = X_train.iloc[train_index_ica], X_train.iloc[test_index_ica]\n",
    "        y_train_fold_ica, y_test_fold_ica = y_train.iloc[train_index_ica], y_train.iloc[test_index_ica]\n",
    "\n",
    "        # Perform Independent Component Analysis (ICA) for dimensionality reduction\n",
    "        ica_fold = FastICA(n_components=10, random_state=42)\n",
    "        X_train_ica_fold = ica_fold.fit_transform(X_train_fold_ica)\n",
    "        X_test_ica_fold = ica_fold.transform(X_test_fold_ica)\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler_fold = StandardScaler()\n",
    "        X_train_ica_fold = scaler_fold.fit_transform(X_train_ica_fold)\n",
    "        X_test_ica_fold = scaler_fold.transform(X_test_ica_fold)\n",
    "\n",
    "        # Train a RandomForestClassifier on the transformed data for this fold\n",
    "        rf_model_fold_ica = RandomForestClassifier(random_state=24)\n",
    "        start_train_fold_ica = time.time()\n",
    "        rf_model_fold_ica.fit(X_train_ica_fold, y_train_fold_ica)\n",
    "        end_train_fold_ica = time.time()\n",
    "        time_to_train_ica += end_train_fold_ica - start_train_fold_ica\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_ica = time.time()\n",
    "        y_pred_fold_ica = rf_model_fold_ica.predict(X_test_ica_fold)\n",
    "        end_predict_fold_ica = time.time()\n",
    "        time_to_predict_fold_ica += end_predict_fold_ica - start_predict_fold_ica\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_ica.extend(y_test_fold_ica)\n",
    "        all_y_pred_ica.extend(y_pred_fold_ica)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_ica = confusion_matrix(y_test_fold_ica, y_pred_fold_ica)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_ica = ConfusionMatrixDisplay(confusion_matrix=cm_ica)\n",
    "        disp_ica.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - ICA\")\n",
    "        pname_ica = method + \"_fold_\" + str(fold_number) + \"_ICA_confusion_matrix.png\"\n",
    "        plt.savefig(pname_ica)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_ica = time.time()\n",
    "    result(all_y_pred_ica, all_y_test_ica, \"ICA\", time_to_train_ica, time_to_predict_fold_ica)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"ICA with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"ICA\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 56. Lasso Regression with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_lasso = []\n",
    "    all_y_pred_lasso = []\n",
    "    start_cv_lasso = time.time()\n",
    "    time_to_predict_fold_lasso = 0\n",
    "    time_to_train_lasso = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_lasso, test_index_lasso) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_lasso, X_test_fold_lasso = X_train.iloc[train_index_lasso], X_train.iloc[test_index_lasso]\n",
    "        y_train_fold_lasso, y_test_fold_lasso = y_train.iloc[train_index_lasso], y_train.iloc[test_index_lasso]\n",
    "\n",
    "        # Initialize Lasso Regression model\n",
    "        lasso_model_fold = LogisticRegression(penalty='l1', solver='saga', random_state=24, max_iter=1000)\n",
    "\n",
    "        # Train the Lasso Regression model for this fold\n",
    "        start_train_fold_lasso = time.time()\n",
    "        lasso_model_fold.fit(X_train_fold_lasso, y_train_fold_lasso)\n",
    "        end_train_fold_lasso = time.time()\n",
    "        time_to_train_lasso += end_train_fold_lasso - start_train_fold_lasso\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_lasso = time.time()\n",
    "        y_pred_fold_lasso = lasso_model_fold.predict(X_test_fold_lasso)\n",
    "        end_predict_fold_lasso = time.time()\n",
    "        time_to_predict_fold_lasso += end_predict_fold_lasso - start_predict_fold_lasso\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_lasso.extend(y_test_fold_lasso)\n",
    "        all_y_pred_lasso.extend(y_pred_fold_lasso)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_lasso = confusion_matrix(y_test_fold_lasso, y_pred_fold_lasso)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_lasso = ConfusionMatrixDisplay(confusion_matrix=cm_lasso)\n",
    "        disp_lasso.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Lasso Regression\")\n",
    "        pname_lasso = method + \"_fold_\" + str(fold_number) + \"_Lasso_Regression_confusion_matrix.png\"\n",
    "        plt.savefig(pname_lasso)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_lasso = time.time()\n",
    "    result(all_y_pred_lasso, all_y_test_lasso, \"Lasso Regression\", time_to_train_lasso, time_to_predict_fold_lasso)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Lasso Regression with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Lasso\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 57. Meta (KNN) with Neighbors (K) and k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_meta_knn = []\n",
    "    all_y_pred_meta_knn = []\n",
    "    start_cv_meta_knn = time.time()\n",
    "    time_to_predict_fold_meta_knn = 0\n",
    "    time_to_train_meta_knn = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_meta_knn, test_index_meta_knn) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_meta_knn, X_test_fold_meta_knn = X_train.iloc[train_index_meta_knn], X_train.iloc[test_index_meta_knn]\n",
    "        y_train_fold_meta_knn, y_test_fold_meta_knn = y_train.iloc[train_index_meta_knn], y_train.iloc[test_index_meta_knn]\n",
    "\n",
    "        # Initialize base classifier (KNN) for meta-learning\n",
    "        k = 5\n",
    "        base_classifier_meta_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "        # Initialize BaggingClassifier for meta-learning with KNN base classifier\n",
    "        meta_knn_model_fold = BaggingClassifier(base_classifier_meta_knn, n_estimators=10, random_state=42)\n",
    "\n",
    "        # Train the meta KNN model for this fold\n",
    "        start_train_fold_meta_knn = time.time()\n",
    "        meta_knn_model_fold.fit(X_train_fold_meta_knn, y_train_fold_meta_knn)\n",
    "        end_train_fold_meta_knn = time.time()\n",
    "        time_to_train_meta_knn += end_train_fold_meta_knn - start_train_fold_meta_knn\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_meta_knn = time.time()\n",
    "        y_pred_fold_meta_knn = meta_knn_model_fold.predict(X_test_fold_meta_knn)\n",
    "        end_predict_fold_meta_knn = time.time()\n",
    "        time_to_predict_fold_meta_knn += end_predict_fold_meta_knn - start_predict_fold_meta_knn\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_meta_knn.extend(y_test_fold_meta_knn)\n",
    "        all_y_pred_meta_knn.extend(y_pred_fold_meta_knn)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_meta_knn = confusion_matrix(y_test_fold_meta_knn, y_pred_fold_meta_knn)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_meta_knn = ConfusionMatrixDisplay(confusion_matrix=cm_meta_knn)\n",
    "        disp_meta_knn.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Meta (KNN)\")\n",
    "        pname_meta_knn = method + \"_fold_\" + str(fold_number) + \"_Meta_KNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname_meta_knn)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_meta_knn = time.time()\n",
    "    result(all_y_pred_meta_knn, all_y_test_meta_knn, \"Meta (KNN)\", time_to_train_meta_knn, time_to_predict_fold_meta_knn)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Meta (KNN) with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"KNN\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## T-SNE Random Forest (T-SNERF) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize T-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "    # Initialize Random Forest Classifier\n",
    "    rf_model = RandomForestClassifier(random_state=24)\n",
    "\n",
    "    # Initialize k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits= n_splits_for_cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_tsnerf = []\n",
    "    all_y_pred_tsnerf = []\n",
    "    start_cv_tsnerf = time.time()\n",
    "    time_to_predict_fold_tsnerf = 0\n",
    "    time_to_train_tsnerf = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_tsnerf, test_index_tsnerf) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_tsnerf, X_test_fold_tsnerf = X_train.iloc[train_index_tsnerf], X_train.iloc[test_index_tsnerf]\n",
    "        y_train_fold_tsnerf, y_test_fold_tsnerf = y_train.iloc[train_index_tsnerf], y_train.iloc[test_index_tsnerf]\n",
    "\n",
    "        # Train T-SNE on the training data for this fold\n",
    "        start_train_fold_tsnerf = time.time()\n",
    "        X_train_tsne_fold_tsnerf = tsne.fit_transform(X_train_fold_tsnerf)\n",
    "        end_train_fold_tsnerf = time.time()\n",
    "        time_to_train_tsnerf += end_train_fold_tsnerf - start_train_fold_tsnerf\n",
    "\n",
    "        # Train Random Forest on the T-SNE transformed data for this fold\n",
    "        start_rf_fold_tsnerf = time.time()\n",
    "        rf_model.fit(X_train_tsne_fold_tsnerf, y_train_fold_tsnerf)\n",
    "        end_rf_fold_tsnerf = time.time()\n",
    "\n",
    "        # Transform the test data using the trained T-SNE model for this fold\n",
    "        start_transform_fold_tsnerf = time.time()\n",
    "        X_test_tsne_fold_tsnerf = tsne.fit_transform(X_test_fold_tsnerf)\n",
    "        end_transform_fold_tsnerf = time.time()\n",
    "\n",
    "        # Predict using the trained Random Forest model for this fold\n",
    "        start_predict_fold_tsnerf = time.time()\n",
    "        y_pred_fold_tsnerf = rf_model.predict(X_test_tsne_fold_tsnerf)\n",
    "        end_predict_fold_tsnerf = time.time()\n",
    "        time_to_predict_fold_tsnerf += end_predict_fold_tsnerf - start_predict_fold_tsnerf\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_tsnerf.extend(y_test_fold_tsnerf)\n",
    "        all_y_pred_tsnerf.extend(y_pred_fold_tsnerf)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_tsnerf = confusion_matrix(y_test_fold_tsnerf, y_pred_fold_tsnerf)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_tsnerf = ConfusionMatrixDisplay(confusion_matrix=cm_tsnerf)\n",
    "        disp_tsnerf.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - T-SNE Random Forest (T-SNERF)\")\n",
    "        pname_tsnerf = method + \"_fold_\" + str(fold_number) + \"_TSNE_confusion_matrix.png\"\n",
    "        plt.savefig(pname_tsnerf)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_tsnerf = time.time()\n",
    "    result(all_y_pred_tsnerf, all_y_test_tsnerf, \"T-SNE Random Forest (T-SNERF) with k-fold Cross-Validation\", time_to_train_tsnerf, time_to_predict_fold_tsnerf)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"T-SNE Random Forest (T-SNERF) with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"T-SNE Random Forest\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 60. Projected Gradient Descent (PGD) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_pgd = []\n",
    "    all_y_pred_pgd = []\n",
    "    start_cv_pgd = time.time()\n",
    "    time_to_predict_fold_pgd = 0\n",
    "    time_to_train_pgd = 0\n",
    "\n",
    "    # Define a simple neural network model\n",
    "    class SimpleNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SimpleNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(X_train.shape[1], 128)\n",
    "            self.fc2 = nn.Linear(128, len(np.unique(y_train)))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_pgd, test_index_pgd) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_pgd, X_test_fold_pgd = X_train.iloc[train_index_pgd], X_train.iloc[test_index_pgd]\n",
    "        y_train_fold_pgd, y_test_fold_pgd = y_train.iloc[train_index_pgd], y_train.iloc[test_index_pgd]\n",
    "\n",
    "        # Convert pandas DataFrame to PyTorch tensors for this fold\n",
    "        X_train_tensor_pgd = torch.tensor(X_train_fold_pgd.values, dtype=torch.float32)\n",
    "        y_train_tensor_pgd = torch.tensor(y_train_fold_pgd.values, dtype=torch.long)\n",
    "        X_test_tensor_pgd = torch.tensor(X_test_fold_pgd.values, dtype=torch.float32)\n",
    "\n",
    "        # Create a DataLoader for training for this fold\n",
    "        train_dataset_pgd = TensorDataset(X_train_tensor_pgd, y_train_tensor_pgd)\n",
    "        train_loader_pgd = DataLoader(train_dataset_pgd, batch_size=64, shuffle=True)\n",
    "\n",
    "        # Define model, loss function, and optimizer for this fold\n",
    "        model_pgd = SimpleNN()\n",
    "        criterion_pgd = nn.CrossEntropyLoss()\n",
    "        optimizer_pgd = optim.Adam(model_pgd.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model for this fold\n",
    "        start_train_fold_pgd = time.time()\n",
    "        for epoch in range(10):\n",
    "            for inputs, labels in train_loader_pgd:\n",
    "                optimizer_pgd.zero_grad()\n",
    "                outputs = model_pgd(inputs)\n",
    "                loss = criterion_pgd(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer_pgd.step()\n",
    "        end_train_fold_pgd = time.time()\n",
    "        time_to_train_pgd += end_train_fold_pgd - start_train_fold_pgd\n",
    "\n",
    "        # Evaluate the model for this fold\n",
    "        model_pgd.eval()\n",
    "        start_predict_fold_pgd = time.time()\n",
    "        with torch.no_grad():\n",
    "            y_pred_fold_pgd = model_pgd(X_test_tensor_pgd).argmax(dim=1).detach().numpy()\n",
    "        end_predict_fold_pgd = time.time()\n",
    "        time_to_predict_fold_pgd += end_predict_fold_pgd - start_predict_fold_pgd\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_pgd.extend(y_test_fold_pgd)\n",
    "        all_y_pred_pgd.extend(y_pred_fold_pgd)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_pgd = confusion_matrix(y_test_fold_pgd, y_pred_fold_pgd)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_pgd = ConfusionMatrixDisplay(confusion_matrix=cm_pgd)\n",
    "        disp_pgd.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Projected Gradient Descent (PGD)\")\n",
    "        pname_pgd = method + \"_fold_\" + str(fold_number) + \"_PGD_confusion_matrix.png\"\n",
    "        plt.savefig(pname_pgd)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_pgd = time.time()\n",
    "    result(all_y_pred_pgd, all_y_test_pgd, \"Projected Gradient Descent (PGD)\", time_to_train_pgd, time_to_predict_fold_pgd)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Projected Gradient Descent (PGD) with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Projected Gradient Descent\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 61. Principal Component Analysis (PCA) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_pca = []\n",
    "    all_y_pred_pca = []\n",
    "    start_cv_pca = time.time()\n",
    "    time_to_predict_fold_pca = 0\n",
    "    time_to_train_pca = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_pca, test_index_pca) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_pca, X_test_fold_pca = X_train.iloc[train_index_pca], X_train.iloc[test_index_pca]\n",
    "        y_train_fold_pca, y_test_fold_pca = y_train.iloc[train_index_pca], y_train.iloc[test_index_pca]\n",
    "\n",
    "        # Convert y_test_fold_pca to integer labels if it's not already\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_test_encoded_fold_pca = label_encoder.fit_transform(y_test_fold_pca)\n",
    "\n",
    "        # Apply PCA to reduce dimensionality for this fold\n",
    "        pca_fold_pca = PCA(n_components=0.95, random_state=42)  # Retain 95% of variance\n",
    "        X_train_fold_pca = pca_fold_pca.fit_transform(X_train_fold_pca)\n",
    "        X_test_fold_pca = pca_fold_pca.transform(X_test_fold_pca)\n",
    "\n",
    "        # Train the classifier on the reduced dimensionality data for this fold\n",
    "        dt_multi_fold_pca = DecisionTreeClassifier(random_state=24)\n",
    "        start_train_fold_pca = time.time()\n",
    "        dt_multi_fold_pca.fit(X_train_fold_pca, y_train_fold_pca)\n",
    "        end_train_fold_pca = time.time()\n",
    "        time_to_train_pca += end_train_fold_pca - start_train_fold_pca\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_pca = time.time()\n",
    "        y_pred_fold_pca = dt_multi_fold_pca.predict(X_test_fold_pca)\n",
    "        end_predict_fold_pca = time.time()\n",
    "        time_to_predict_fold_pca += end_predict_fold_pca - start_predict_fold_pca\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_pca.extend(y_test_encoded_fold_pca)\n",
    "        all_y_pred_pca.extend(y_pred_fold_pca)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_pca = confusion_matrix(y_test_encoded_fold_pca, y_pred_fold_pca)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_pca = ConfusionMatrixDisplay(confusion_matrix=cm_pca)\n",
    "        disp_pca.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - PCA\")\n",
    "        pname_pca = method + \"_fold_\" + str(fold_number) + \"_PCA_confusion_matrix.png\"\n",
    "        plt.savefig(pname_pca)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_pca = time.time()\n",
    "    result(all_y_pred_pca, all_y_test_pca, \"PCA\", time_to_train_pca, time_to_predict_fold_pca)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"PCA with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"PCA\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 48. RBF SVM Algorithm with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gbkk = []\n",
    "    all_y_pred_gbkk = []\n",
    "    start_cv_gbkk = time.time()\n",
    "    time_to_predict_fold_gbkk = 0\n",
    "    time_to_train_gbkk = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gbkk, test_index_gbkk) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gbkk, X_test_fold_gbkk = X_train.iloc[train_index_gbkk], X_train.iloc[test_index_gbkk]\n",
    "        y_train_fold_gbkk, y_test_fold_gbkk = y_train.iloc[train_index_gbkk], y_train.iloc[test_index_gbkk]\n",
    "\n",
    "        # Initialize Gaussian Naive Bayes (GBBK) model for this fold\n",
    "        gbbk_model_fold_gbkk = SVC(kernel='rbf', random_state=24)\n",
    "\n",
    "        # Train the GBBK model for this fold\n",
    "        start_train_fold_gbkk = time.time()\n",
    "        gbbk_model_fold_gbkk.fit(X_train_fold_gbkk, y_train_fold_gbkk)\n",
    "        end_train_fold_gbkk = time.time()\n",
    "        time_to_train_gbkk += end_train_fold_gbkk - start_train_fold_gbkk\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_gbkk = time.time()\n",
    "        y_pred_fold_gbkk = gbbk_model_fold_gbkk.predict(X_test_fold_gbkk)\n",
    "        end_predict_fold_gbkk = time.time()\n",
    "        time_to_predict_fold_gbkk += end_predict_fold_gbkk - start_predict_fold_gbkk\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gbkk.extend(y_test_fold_gbkk)\n",
    "        all_y_pred_gbkk.extend(y_pred_fold_gbkk)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_gbkk = confusion_matrix(y_test_fold_gbkk, y_pred_fold_gbkk)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gbkk = ConfusionMatrixDisplay(confusion_matrix=cm_gbkk)\n",
    "        disp_gbkk.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - RBF SVM\")\n",
    "        pname_gbkk = method + \"_fold_\" + str(fold_number) + \"_RBF_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gbkk)\n",
    "        #plt.show()\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_gbkk = time.time()\n",
    "    result(all_y_pred_gbkk, all_y_test_gbkk, \"RBF\", time_to_train_gbkk, time_to_predict_fold_gbkk)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"RBF  with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"RBF\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## Stacked Convolutional Neural Networks with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Convert DataFrame to NumPy array\n",
    "    X = X_train.to_numpy()\n",
    "    y = y_train.to_numpy()\n",
    "\n",
    "    # Reshape the input data for Conv1D layer\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "    # Define the CNN model\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')  # Adjust the number of units based on the number of classes in your dataset\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Initialize k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits= n_splits_for_cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_cnn = []\n",
    "    all_y_pred_cnn = []\n",
    "    start_cv_cnn = time.time()\n",
    "    time_to_predict_fold_cnn = 0\n",
    "    time_to_train_cnn = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_cnn, test_index_cnn) in enumerate(skf.split(X, y), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_cnn, X_test_fold_cnn = X[train_index_cnn], X[test_index_cnn]\n",
    "        y_train_fold_cnn, y_test_fold_cnn = y[train_index_cnn], y[test_index_cnn]\n",
    "\n",
    "        # Train the model for this fold\n",
    "        start_train_fold_cnn = time.time()\n",
    "        history = model.fit(X_train_fold_cnn, y_train_fold_cnn, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
    "        end_train_fold_cnn = time.time()\n",
    "        time_to_train_cnn += end_train_fold_cnn - start_train_fold_cnn\n",
    "\n",
    "        # Evaluate the model for this fold\n",
    "        start_predict_fold_cnn = time.time()\n",
    "        y_pred_fold_cnn = model.predict(X_test_fold_cnn)\n",
    "        y_pred_fold_cnn = np.argmax(y_pred_fold_cnn, axis=1)\n",
    "        end_predict_fold_cnn = time.time()\n",
    "        time_to_predict_fold_cnn += end_predict_fold_cnn - start_predict_fold_cnn\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_cnn.extend(y_test_fold_cnn)\n",
    "        all_y_pred_cnn.extend(y_pred_fold_cnn)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_cnn = confusion_matrix(y_test_fold_cnn, y_pred_fold_cnn)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_cnn = ConfusionMatrixDisplay(confusion_matrix=cm_cnn)\n",
    "        disp_cnn.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Stacked Convolutional Neural Networks\")\n",
    "        pname_cnn = method + \"_fold_\" + str(fold_number) + \"_Stacked_Convolutional_Neural_Networks_confusion_matrix.png\"\n",
    "        plt.savefig(pname_cnn)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_cnn = time.time()\n",
    "    result(all_y_pred_cnn, all_y_test_cnn, \"Stacked Convolutional Neural Networks with k-fold Cross-Validation\", time_to_train_cnn, time_to_predict_fold_cnn)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Stacked Convolutional Neural Networks with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Stacked Convolutional Neural Networks\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 64. Simulated Annealing (SA) with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Define the objective function for optimization\n",
    "\n",
    "    # Convert X_train and y_train to NumPy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # Convert X_test to NumPy array if it's not already\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    # Reshape the input data if needed\n",
    "    if X_train.ndim > 2:\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    if X_test.ndim > 2:\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    def objective_function(params):\n",
    "        max_depth, min_samples_split, min_samples_leaf = params\n",
    "\n",
    "        # Create and train the Decision Tree model with given hyperparameters\n",
    "        dt_model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, random_state=24)\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict using the trained model\n",
    "        y_pred = dt_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model - Example: using accuracy\n",
    "        accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "        # Return the negative of the accuracy (since we want to minimize)\n",
    "        return -accuracy\n",
    "    # Simulated Annealing hyperparameter optimization\n",
    "    def simulated_annealing(objective_function, space, n_calls=50, initial_temperature=100.0, cooling_rate=0.95):\n",
    "        best_params = None\n",
    "        best_score = float('-inf')\n",
    "        temperature = initial_temperature\n",
    "\n",
    "        current_params = [np.random.randint(low, high + 1) for low, high in space]\n",
    "\n",
    "        for _ in range(n_calls):\n",
    "            next_params = [np.random.randint(low, high + 1) for low, high in space]\n",
    "\n",
    "            current_score = objective_function(current_params)\n",
    "            next_score = objective_function(next_params)\n",
    "\n",
    "            if next_score > current_score or np.random.rand() < np.exp((next_score - current_score) / temperature):\n",
    "                current_params = next_params\n",
    "                current_score = next_score\n",
    "\n",
    "            if current_score > best_score:\n",
    "                best_params = current_params\n",
    "                best_score = current_score\n",
    "\n",
    "            temperature *= cooling_rate\n",
    "\n",
    "        return best_params\n",
    "    # Define the search space for hyperparameters\n",
    "    space = [(1, 20),  # max_depth\n",
    "            (2, 20),  # min_samples_split\n",
    "            (1, 20)]  # min_samples_leaf\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_sa = []\n",
    "    all_y_pred_sa = []\n",
    "    start_cv_sa = time.time()\n",
    "    time_to_predict_fold_sa = 0\n",
    "    time_to_train_sa = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_sa, test_index_sa) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_sa, X_test_fold_sa = X_train[train_index_sa], X_train[test_index_sa]\n",
    "        y_train_fold_sa, y_test_fold_sa = y_train[train_index_sa], y_train[test_index_sa]\n",
    "\n",
    "        # Run the optimization using Simulated Annealing for this fold\n",
    "        start_train_fold_sa = time.time()\n",
    "        best_params = simulated_annealing(objective_function, space)\n",
    "        end_train_fold_sa = time.time()\n",
    "\n",
    "        # Train the final model with the best hyperparameters for this fold\n",
    "        dt_model_final_fold_sa = DecisionTreeClassifier(max_depth=best_params[0], min_samples_split=best_params[1], min_samples_leaf=best_params[2], random_state=24)\n",
    "        dt_model_final_fold_sa.fit(X_train_fold_sa, y_train_fold_sa)\n",
    "\n",
    "        # Predict using the final model for this fold\n",
    "        start_predict_fold_sa = time.time()\n",
    "        y_pred_fold_sa = dt_model_final_fold_sa.predict(X_test_fold_sa)\n",
    "        end_predict_fold_sa = time.time()\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_sa.extend(y_test_fold_sa)\n",
    "        all_y_pred_sa.extend(y_pred_fold_sa)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_sa = confusion_matrix(y_test_fold_sa, y_pred_fold_sa)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_sa = ConfusionMatrixDisplay(confusion_matrix=cm_sa)\n",
    "        disp_sa.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - SA\")\n",
    "        pname_sa = method + \"_fold_\" + str(fold_number) + \"_SA_confusion_matrix.png\"\n",
    "        plt.savefig(pname_sa)\n",
    "        #plt.show()\n",
    "\n",
    "        # Calculate time metrics\n",
    "        time_to_train_fold_sa = end_train_fold_sa - start_train_fold_sa\n",
    "        time_to_predict_fold_sa = end_predict_fold_sa - start_predict_fold_sa\n",
    "\n",
    "        # Update overall time metrics\n",
    "        time_to_train_sa += time_to_train_fold_sa\n",
    "        time_to_predict_fold_sa += time_to_predict_fold_sa\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_sa = time.time()\n",
    "    result(all_y_pred_sa, all_y_test_sa, \"Simulated Annealing (SA)\", time_to_train_sa, time_to_predict_fold_sa)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"SA with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Simulated Annealing\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## SVM with Optimization and k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Reshape input data to have two dimensions\n",
    "    X_flattened = X.reshape(X.shape[0], -1)\n",
    "\n",
    "    # Initialize k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits= n_splits_for_cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_svm = []\n",
    "    all_y_pred_svm = []\n",
    "    start_cv_svm = time.time()\n",
    "    time_to_predict_fold_svm = 0\n",
    "    time_to_train_svm = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_svm, test_index_svm) in enumerate(skf.split(X_flattened, y), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_svm, X_test_fold_svm = X_flattened[train_index_svm], X_flattened[test_index_svm]\n",
    "        y_train_fold_svm, y_test_fold_svm = y[train_index_svm], y[test_index_svm]\n",
    "\n",
    "        # Create and train the SVM model with optimization for this fold\n",
    "        start_train_fold_svm = time.time()\n",
    "        svm_model_fold = SVC(kernel='linear', C=1.0)  # Example hyperparameters, adjust as needed\n",
    "        svm_model_fold.fit(X_train_fold_svm, y_train_fold_svm)\n",
    "        end_train_fold_svm = time.time()\n",
    "        time_to_train_svm += end_train_fold_svm - start_train_fold_svm\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_svm = time.time()\n",
    "        y_pred_fold_svm = svm_model_fold.predict(X_test_fold_svm)\n",
    "        end_predict_fold_svm = time.time()\n",
    "        time_to_predict_fold_svm += end_predict_fold_svm - start_predict_fold_svm\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_svm.extend(y_test_fold_svm)\n",
    "        all_y_pred_svm.extend(y_pred_fold_svm)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_svm = confusion_matrix(y_test_fold_svm, y_pred_fold_svm)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_svm = ConfusionMatrixDisplay(confusion_matrix=cm_svm)\n",
    "        disp_svm.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - SVM with Optimization\")\n",
    "        pname_svm = method + \"_fold_\" + str(fold_number) + \"_SVM_with_Optimization_confusion_matrix.png\"\n",
    "        plt.savefig(pname_svm)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_svm = time.time()\n",
    "    result(all_y_pred_svm, all_y_test_svm, \"SVM with Optimization and k-fold Cross-Validation\", time_to_train_svm, time_to_predict_fold_svm)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"SVM with Optimization and k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"SVM\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 66 Stacking Classifier with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Define base classifiers\n",
    "    base_classifiers = [\n",
    "        ('dt', DecisionTreeClassifier(random_state=24)),\n",
    "        ('rf', RandomForestClassifier(random_state=24)),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ]\n",
    "\n",
    "    # Initialize Stacking Classifier with base classifiers\n",
    "    stacking_classifier = StackingClassifier(estimators=base_classifiers, final_estimator=DecisionTreeClassifier())\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_stacking = []\n",
    "    all_y_pred_stacking = []\n",
    "    start_cv_stacking = time.time()\n",
    "    time_to_predict_fold_stacking = 0\n",
    "    time_to_train_stacking = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_stacking, test_index_stacking) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_stacking, X_test_fold_stacking = X_train[train_index_stacking], X_train[test_index_stacking]\n",
    "        y_train_fold_stacking, y_test_fold_stacking = y_train[train_index_stacking], y_train[test_index_stacking]\n",
    "\n",
    "        # Train the Stacking Classifier for this fold\n",
    "        start_train_fold_stacking = time.time()\n",
    "        stacking_classifier.fit(X_train_fold_stacking, y_train_fold_stacking)\n",
    "        end_train_fold_stacking = time.time()\n",
    "        time_to_train_stacking += end_train_fold_stacking - start_train_fold_stacking\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_stacking = time.time()\n",
    "        y_pred_fold_stacking = stacking_classifier.predict(X_test_fold_stacking)\n",
    "        end_predict_fold_stacking = time.time()\n",
    "        time_to_predict_fold_stacking += end_predict_fold_stacking - start_predict_fold_stacking\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_stacking.extend(y_test_fold_stacking)\n",
    "        all_y_pred_stacking.extend(y_pred_fold_stacking)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_stacking = confusion_matrix(y_test_fold_stacking, y_pred_fold_stacking)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_stacking = ConfusionMatrixDisplay(confusion_matrix=cm_stacking)\n",
    "        disp_stacking.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Stacking Classifier\")\n",
    "        pname_stacking = method + \"_fold_\" + str(fold_number) + \"_Stacking_Classifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_stacking)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    end_cv_stacking = time.time()\n",
    "\n",
    "\n",
    "    result(all_y_pred_stacking, all_y_test_stacking, \"Stacking Classifier\",  time_to_train_stacking, time_to_predict_fold_stacking)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Stacking Classifier with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Stacking Classifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 67 Stacking Dilated Convolutional Autoencoders with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # You may replace this with your DCAE model\n",
    "    base_model = make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=24))\n",
    "\n",
    "    # Define the stacking classifier\n",
    "    stacking_model = StackingClassifier(estimators=[('dt', base_model)], final_estimator=DecisionTreeClassifier())\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_stacking_dcae = []\n",
    "    all_y_pred_stacking_dcae = []\n",
    "    time_to_predict_fold_stacking_dcae = 0\n",
    "    time_to_train_stacking_dcae = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_stacking_dcae, test_index_stacking_dcae) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_stacking_dcae, X_test_fold_stacking_dcae = X_train[train_index_stacking_dcae], X_train[test_index_stacking_dcae]\n",
    "        y_train_fold_stacking_dcae, y_test_fold_stacking_dcae = y_train[train_index_stacking_dcae], y_train[test_index_stacking_dcae]\n",
    "\n",
    "        # Training the stacking model for this fold\n",
    "        start_train_fold_stacking_dcae = time.time()\n",
    "        stacking_model.fit(X_train_fold_stacking_dcae, y_train_fold_stacking_dcae)\n",
    "        end_train_fold_stacking_dcae = time.time()\n",
    "        time_to_train_stacking_dcae += end_train_fold_stacking_dcae - start_train_fold_stacking_dcae\n",
    "\n",
    "        # Predict using the trained stacking model for this fold\n",
    "        start_predict_fold_stacking_dcae = time.time()\n",
    "        y_pred_fold_stacking_dcae = stacking_model.predict(X_test_fold_stacking_dcae)\n",
    "        end_predict_fold_stacking_dcae = time.time()\n",
    "        time_to_predict_fold_stacking_dcae += end_predict_fold_stacking_dcae - start_predict_fold_stacking_dcae\n",
    "\n",
    "        # Generate confusion matrix for this fold\n",
    "        cm_stacking_dcae = confusion_matrix(y_test_fold_stacking_dcae, y_pred_fold_stacking_dcae)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_stacking_dcae = ConfusionMatrixDisplay(confusion_matrix=cm_stacking_dcae)\n",
    "        disp_stacking_dcae.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Stacking DCAE\")\n",
    "        pname_stacking_dcae = method + \"_fold_\" + str(fold_number) + \"_Stacking_DCAE_confusion_matrix.png\"\n",
    "        plt.savefig(pname_stacking_dcae)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_stacking_dcae.extend(y_test_fold_stacking_dcae)\n",
    "        all_y_pred_stacking_dcae.extend(y_pred_fold_stacking_dcae)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_stacking_dcae, all_y_test_stacking_dcae, \"Stacking Dilated Convolutional Autoencoders\", time_to_train_stacking_dcae, time_to_predict_fold_stacking_dcae)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Stacking Dilated Convolutional Autoencoders with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Stacking Dilated Convolutional\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 68 Temporal Deep Feedforward Neural Network with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Define the structure of the Temporal DNN model\n",
    "    y_train = pd.Series(y_train)\n",
    "    num_classes = y_train.nunique()\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  # Assuming len(y_train.unique()) is the number of classes\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_temporal_dnn = []\n",
    "    all_y_pred_temporal_dnn = []\n",
    "    time_to_predict_fold_temporal_dnn = 0\n",
    "    time_to_train_temporal_dnn = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_temporal_dnn, test_index_temporal_dnn) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_temporal_dnn, X_test_fold_temporal_dnn = X_train[train_index_temporal_dnn], X_train[test_index_temporal_dnn]\n",
    "        y_train_fold_temporal_dnn, y_test_fold_temporal_dnn = y_train[train_index_temporal_dnn], y_train[test_index_temporal_dnn]\n",
    "\n",
    "        # Define the Temporal DNN model for this fold\n",
    "        model_fold_temporal_dnn = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            Dropout(0.5),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Compile the model\n",
    "        model_fold_temporal_dnn.compile(optimizer=Adam(),\n",
    "                                        loss='sparse_categorical_crossentropy',\n",
    "                                        metrics=['accuracy'])\n",
    "\n",
    "        # Training the Temporal DNN model for this fold\n",
    "        start_train_fold_temporal_dnn = time.time()\n",
    "        history = model_fold_temporal_dnn.fit(X_train_fold_temporal_dnn, y_train_fold_temporal_dnn, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "        end_train_fold_temporal_dnn = time.time()\n",
    "        time_to_train_temporal_dnn += end_train_fold_temporal_dnn - start_train_fold_temporal_dnn\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_temporal_dnn = time.time()\n",
    "        y_pred_probs_fold_temporal_dnn = model_fold_temporal_dnn.predict(X_test_fold_temporal_dnn)\n",
    "        y_pred_fold_temporal_dnn = np.argmax(y_pred_probs_fold_temporal_dnn, axis=1)\n",
    "        end_predict_fold_temporal_dnn = time.time()\n",
    "        time_to_predict_fold_temporal_dnn += end_predict_fold_temporal_dnn - start_predict_fold_temporal_dnn\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_temporal_dnn.extend(y_test_fold_temporal_dnn)\n",
    "        all_y_pred_temporal_dnn.extend(y_pred_fold_temporal_dnn)\n",
    "\n",
    "        # Generate confusion matrix for this fold\n",
    "        cm_temporal_dnn = confusion_matrix(y_test_fold_temporal_dnn, y_pred_fold_temporal_dnn)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_temporal_dnn = ConfusionMatrixDisplay(confusion_matrix=cm_temporal_dnn)\n",
    "        disp_temporal_dnn.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Temporal DNN\")\n",
    "        pname_temporal_dnn = method + \"_fold_\" + str(fold_number) + \"_Temporal_DNN_confusion_matrix.png\"\n",
    "        plt.savefig(pname_temporal_dnn)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_temporal_dnn, all_y_test_temporal_dnn, \"Temporal Deep Feedforward Neural Network\", time_to_train_temporal_dnn, time_to_predict_fold_temporal_dnn)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Temporal Deep Feedforward Neural Network with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Temporal Deep Feedforward Neural\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 69 Voting Classifier with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize individual classifiers\n",
    "    dt1 = DecisionTreeClassifier(random_state=24)\n",
    "    dt2 = DecisionTreeClassifier(random_state=42)\n",
    "    # Add more classifiers if needed\n",
    "\n",
    "    # Create the Voting Classifier\n",
    "    voting_clf = VotingClassifier(estimators=[\n",
    "        ('dt1', dt1),\n",
    "        ('dt2', dt2),\n",
    "        # Add more classifiers here if needed\n",
    "    ], voting='hard')  # You can use 'soft' voting if your classifiers support probability prediction\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_voting = []\n",
    "    all_y_pred_voting = []\n",
    "    time_to_predict_fold_voting = 0\n",
    "    time_to_train_voting = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_voting, test_index_voting) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_voting, X_test_fold_voting = X_train[train_index_voting], X_train[test_index_voting]\n",
    "        y_train_fold_voting, y_test_fold_voting = y_train[train_index_voting], y_train[test_index_voting]\n",
    "\n",
    "        # Train the Voting Classifier for this fold\n",
    "        start_train_fold_voting = time.time()\n",
    "        voting_clf.fit(X_train_fold_voting, y_train_fold_voting)\n",
    "        end_train_fold_voting = time.time()\n",
    "        time_to_train_voting += end_train_fold_voting - start_train_fold_voting\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_voting = time.time()\n",
    "        y_pred_fold_voting = voting_clf.predict(X_test_fold_voting)\n",
    "        end_predict_fold_voting = time.time()\n",
    "        time_to_predict_fold_voting += end_predict_fold_voting - start_predict_fold_voting\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_voting.extend(y_test_fold_voting)\n",
    "        all_y_pred_voting.extend(y_pred_fold_voting)\n",
    "\n",
    "        # Generate confusion matrix for this fold\n",
    "        cm_voting = confusion_matrix(y_test_fold_voting, y_pred_fold_voting)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_voting = ConfusionMatrixDisplay(confusion_matrix=cm_voting)\n",
    "        disp_voting.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - Voting Classifier\")\n",
    "        pname_voting = method + \"_fold_\" + str(fold_number) + \"_Voting_Classifier_confusion_matrix.png\"\n",
    "        plt.savefig(pname_voting)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_voting, all_y_test_voting, \"Voting Classifier\", time_to_train_voting, time_to_predict_fold_voting)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"Voting Classifier with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"Voting Classifier\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 70 GBT with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    # Initialize the GBT classifier\n",
    "    gbt_model = GradientBoostingClassifier(random_state=24)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_gbt = []\n",
    "    all_y_pred_gbt = []\n",
    "    time_to_predict_fold_gbt = 0\n",
    "    time_to_train_gbt = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_gbt, test_index_gbt) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_gbt, X_test_fold_gbt = X_train[train_index_gbt], X_train[test_index_gbt]\n",
    "        y_train_fold_gbt, y_test_fold_gbt = y_train[train_index_gbt], y_train[test_index_gbt]\n",
    "\n",
    "        # Train the GBT model for this fold\n",
    "        start_train_fold_gbt = time.time()\n",
    "        gbt_model.fit(X_train_fold_gbt, y_train_fold_gbt)\n",
    "        end_train_fold_gbt = time.time()\n",
    "        time_to_train_gbt += end_train_fold_gbt - start_train_fold_gbt\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_gbt = time.time()\n",
    "        y_pred_fold_gbt = gbt_model.predict(X_test_fold_gbt)\n",
    "        end_predict_fold_gbt = time.time()\n",
    "        time_to_predict_fold_gbt += end_predict_fold_gbt - start_predict_fold_gbt\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_gbt.extend(y_test_fold_gbt)\n",
    "        all_y_pred_gbt.extend(y_pred_fold_gbt)\n",
    "\n",
    "        # Generate confusion matrix for this fold\n",
    "        cm_gbt = confusion_matrix(y_test_fold_gbt, y_pred_fold_gbt)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_gbt = ConfusionMatrixDisplay(confusion_matrix=cm_gbt)\n",
    "        disp_gbt.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - GBT\")\n",
    "        pname_gbt = method + \"_fold_\" + str(fold_number) + \"_GBT_confusion_matrix.png\"\n",
    "        plt.savefig(pname_gbt)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_gbt, all_y_test_gbt, \"GBT\", time_to_train_gbt, time_to_predict_fold_gbt)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"GBT with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"GBT\")\n",
    "\n",
    "print(\"*\"*30)\n",
    "\n",
    "try:\n",
    "    \"\"\"## 71 CART with k-fold Cross-Validation\"\"\"\n",
    "\n",
    "    class Node:\n",
    "        def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "            self.feature_index = feature_index  # Index of feature to split on\n",
    "            self.threshold = threshold  # Threshold value to split on\n",
    "            self.left = left  # Left subtree\n",
    "            self.right = right  # Right subtree\n",
    "            self.value = value  # Class label (for leaf nodes)\n",
    "\n",
    "    class CART:\n",
    "        def __init__(self, max_depth=None):\n",
    "            self.max_depth = max_depth\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            self.n_classes = len(set(y))\n",
    "            self.n_features = X.shape[1]\n",
    "            self.tree = self._build_tree(X, y)\n",
    "\n",
    "        def _build_tree(self, X, y, depth=0):\n",
    "            n_samples, n_features = X.shape\n",
    "            n_labels = len(set(y))\n",
    "\n",
    "            # Stop conditions\n",
    "            if depth == self.max_depth or n_labels == 1:\n",
    "                value = max(set(y), key=list(y).count)\n",
    "                return Node(value=value)\n",
    "\n",
    "            # Find best split\n",
    "            best_gini = float('inf')\n",
    "            best_feature_index = None\n",
    "            best_threshold = None\n",
    "\n",
    "            for feature_index in range(n_features):\n",
    "                thresholds = sorted(set(X[:, feature_index]))\n",
    "                for threshold in thresholds:\n",
    "                    left_indices = (X[:, feature_index] <= threshold)\n",
    "                    right_indices = (X[:, feature_index] > threshold)\n",
    "\n",
    "                    left_gini = self._gini(y[left_indices])\n",
    "                    right_gini = self._gini(y[right_indices])\n",
    "\n",
    "                    gini = (len(left_indices) * left_gini + len(right_indices) * right_gini) / n_samples\n",
    "\n",
    "                    if gini < best_gini:\n",
    "                        best_gini = gini\n",
    "                        best_feature_index = feature_index\n",
    "                        best_threshold = threshold\n",
    "\n",
    "            # Split data\n",
    "            left_indices = (X[:, best_feature_index] <= best_threshold)\n",
    "            right_indices = (X[:, best_feature_index] > best_threshold)\n",
    "\n",
    "            left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "            right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "            return Node(best_feature_index, best_threshold, left_subtree, right_subtree)\n",
    "\n",
    "        def _gini(self, y):\n",
    "            n_samples = len(y)\n",
    "            gini = 1.0\n",
    "            for label in set(y):\n",
    "                proportion = (y == label).sum() / n_samples\n",
    "                gini -= proportion ** 2\n",
    "            return gini\n",
    "\n",
    "        def predict(self, X):\n",
    "            return [self._predict_one(sample, self.tree) for sample in X]\n",
    "\n",
    "        def _predict_one(self, sample, node):\n",
    "            if node.value is not None:\n",
    "                return node.value\n",
    "\n",
    "            if sample[node.feature_index] <= node.threshold:\n",
    "                return self._predict_one(sample, node.left)\n",
    "            else:\n",
    "                return self._predict_one(sample, node.right)\n",
    "\n",
    "    # Initialize lists to store metrics\n",
    "    all_y_test_cart = []\n",
    "    all_y_pred_cart = []\n",
    "    time_to_predict_fold_cart = 0\n",
    "    time_to_train_cart = 0\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold_number, (train_index_cart, test_index_cart) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # Split data into train and test sets for the fold\n",
    "        X_train_fold_cart, X_test_fold_cart = X_train[train_index_cart], X_train[test_index_cart]\n",
    "        y_train_fold_cart, y_test_fold_cart = y_train[train_index_cart], y_train[test_index_cart]\n",
    "\n",
    "        # Create and train the CART model for this fold\n",
    "        cart_model_fold = CART(max_depth=1)\n",
    "        start_train_fold_cart = time.time()\n",
    "        cart_model_fold.fit(X_train_fold_cart, y_train_fold_cart)\n",
    "        end_train_fold_cart = time.time()\n",
    "        time_to_train_cart += end_train_fold_cart - start_train_fold_cart\n",
    "\n",
    "        # Predict using the trained model for this fold\n",
    "        start_predict_fold_cart = time.time()\n",
    "        y_pred_fold_cart = cart_model_fold.predict(X_test_fold_cart)\n",
    "        end_predict_fold_cart = time.time()\n",
    "        time_to_predict_fold_cart += end_predict_fold_cart - start_predict_fold_cart\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_y_test_cart.extend(y_test_fold_cart)\n",
    "        all_y_pred_cart.extend(y_pred_fold_cart)\n",
    "\n",
    "        # Generate confusion matrix and display for the fold\n",
    "        cm_cart = confusion_matrix(y_test_fold_cart, y_pred_fold_cart)\n",
    "        plt.rcParams['figure.figsize'] = 8, 8\n",
    "        sns.set_style(\"white\")\n",
    "        disp_cart = ConfusionMatrixDisplay(confusion_matrix=cm_cart)\n",
    "        disp_cart.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Fold {fold_number} Confusion Matrix - CART\")\n",
    "        pname_cart = method + \"_fold_\" + str(fold_number) + \"_CART_confusion_matrix.png\"\n",
    "        plt.savefig(pname_cart)\n",
    "\n",
    "    # Calculate overall performance metrics\n",
    "    result(all_y_pred_cart, all_y_test_cart, \"CART\", time_to_train_cart, time_to_predict_fold_cart)\n",
    "\n",
    "    outfile.close()\n",
    "    outfile = open(fname, 'a')\n",
    "    print(\"CART with k-fold Cross-Validation Completed :)  \")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.exception(str(e))\n",
    "    separator(\"CART\")\n",
    "\n",
    "## **Closing the outfile**\n",
    "outfile.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the path to your directory\n",
    "directory_path = '.'\n",
    "\n",
    "# Patterns to look for in filenames\n",
    "patterns = ['Metrics_fold_1', 'Metrics_fold_2', 'Metrics_fold_3', 'Metrics_fold_4']\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file is a PNG and contains any of the patterns\n",
    "    if filename.endswith('.png') and any(pattern in filename for pattern in patterns):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        try:\n",
    "            # Delete the file\n",
    "            os.remove(file_path)\n",
    "            print(f'Deleted: {file_path}')\n",
    "        except Exception as e:\n",
    "            print(f'Error deleting {file_path}: {e}')\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "# Your code goes here...\n",
    "\n",
    "# Get the ending time\n",
    "end_time_1 = datetime.datetime.now()\n",
    "\n",
    "# Calculate the total time required for execution\n",
    "total_time = end_time_1 - start_time_1\n",
    "\n",
    "# Format the start time, end time, and total time\n",
    "start_time_str = start_time_1.strftime(\"%d-%m-%Y %H:%M\")\n",
    "end_time_str = end_time_1.strftime(\"%d-%m-%Y %H:%M\")\n",
    "total_time_str = str(total_time)\n",
    "\n",
    "# Write the start time, end time, and total time to the file\n",
    "with open(\"time.txt\", \"a\") as file:\n",
    "    file.write(f\"Start time: {start_time_str}\\n\")\n",
    "    file.write(f\"End time: {end_time_str}\\n\")\n",
    "    file.write(f\"Total time: {total_time_str}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac98b2-775c-410c-a529-2deff4f79f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
